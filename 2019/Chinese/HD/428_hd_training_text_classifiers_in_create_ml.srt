1
00:00:00,506 --> 00:00:04,500
[音乐]


2
00:00:07,516 --> 00:00:14,026
[掌声]


3
00:00:14,526 --> 00:00:15,626
>> 嗨 大家


4
00:00:15,836 --> 00:00:16,516
大家下午好


5
00:00:17,316 --> 00:00:18,456
欢迎大家来到这次会议


6
00:00:19,796 --> 00:00:20,836
我是 Tao


7
00:00:21,246 --> 00:00:22,446
我来自 Core ML 团队


8
00:00:23,276 --> 00:00:25,016
今天我们十分激动


9
00:00:25,016 --> 00:00:26,916
能够来讨论我们今年


10
00:00:26,916 --> 00:00:28,676
在 Create ML 中添加的一些新功能


11
00:00:29,016 --> 00:00:30,136
在机器学习讨论会的


12
00:00:30,136 --> 00:00:31,536
新内容中 你们了解了


13
00:00:31,536 --> 00:00:34,986
全新的 Create ML App


14
00:00:34,986 --> 00:00:36,336
这是 Apple 设计的


15
00:00:36,336 --> 00:00:38,226
一款出色的新工具


16
00:00:38,226 --> 00:00:40,146
它可指导你完成


17
00:00:40,146 --> 00:00:41,206
机器学习模型培训的基本步骤


18
00:00:42,226 --> 00:00:43,806
我们相信这会使


19
00:00:43,806 --> 00:00:46,016
你们的机器学习工作流程


20
00:00:46,016 --> 00:00:46,756
变得简单易用


21
00:00:48,206 --> 00:00:49,366
现在 让我们


22
00:00:49,366 --> 00:00:49,976
从文本分类开始


23
00:00:52,546 --> 00:00:53,956
什么是文本分类


24
00:00:54,536 --> 00:00:55,966
这是一个机器学习的任务


25
00:00:56,346 --> 00:00:58,796
它将文本分类为


26
00:00:58,886 --> 00:01:00,446
一组预定义标签


27
00:01:03,136 --> 00:01:04,566
你可以将其用于情感分析


28
00:01:04,566 --> 00:01:07,626
例如将文本分类为


29
00:01:07,626 --> 00:01:09,936
正面或负面


30
00:01:11,396 --> 00:01:12,756
或者做垃圾邮件检测


31
00:01:12,756 --> 00:01:16,096
或者更复杂的事情


32
00:01:16,386 --> 00:01:18,596
如主题分析 将文本分类为


33
00:01:18,596 --> 00:01:21,786
食物类 政治类或科学类


34
00:01:23,146 --> 00:01:24,556
好 自去年以来


35
00:01:24,556 --> 00:01:25,976
文本分类一直被推崇


36
00:01:26,516 --> 00:01:28,296
但我们今年正在增加


37
00:01:28,296 --> 00:01:30,776
对艺术迁移学习状态的支持


38
00:01:31,636 --> 00:01:33,156
今天 我将向你们


39
00:01:33,156 --> 00:01:35,206
具体举例说明


40
00:01:35,206 --> 00:01:37,346
如何使用迁移学习


41
00:01:37,346 --> 00:01:38,046
训练文本分类器


42
00:01:39,446 --> 00:01:41,336
要训练这样的一个模型


43
00:01:41,336 --> 00:01:42,566
你要做的第一件事


44
00:01:42,886 --> 00:01:44,616
就是收集一些训练数据


45
00:01:46,336 --> 00:01:48,386
一旦获得数据后


46
00:01:48,386 --> 00:01:50,066
你们便可以轻松地进行整理


47
00:01:51,116 --> 00:01:54,056
我这儿有运动类 娱乐类和自然类


48
00:01:55,166 --> 00:01:56,996
在每个文件夹下


49
00:01:56,996 --> 00:01:57,626
我有一些文本文件


50
00:01:58,236 --> 00:02:00,316
而且他们中的每一个都是


51
00:02:00,316 --> 00:02:02,996
一个训练样例


52
00:02:03,146 --> 00:02:04,996
它们的标签就是


53
00:02:04,996 --> 00:02:05,406
它们所在文件夹的名称


54
00:02:05,946 --> 00:02:07,786
就是这样


55
00:02:07,786 --> 00:02:08,806
这就是你们要对这些数据


56
00:02:08,806 --> 00:02:09,186
做的所有处理


57
00:02:10,156 --> 00:02:11,636
我会给你们一个快速演示


58
00:02:11,636 --> 00:02:12,576
告诉你们如何做到这一点


59
00:02:12,776 --> 00:02:15,606
在我的桌面上


60
00:02:15,606 --> 00:02:15,956
我有一个训练数据的文件夹


61
00:02:20,386 --> 00:02:22,026
那么 我决定找点乐子


62
00:02:22,716 --> 00:02:24,356
我没有使用纯文本作为标签


63
00:02:24,356 --> 00:02:26,546
而是使用了一些表情符号


64
00:02:27,426 --> 00:02:29,116
例如 对于娱乐类我使用


65
00:02:29,116 --> 00:02:30,306
一个摄像机图标


66
00:02:31,106 --> 00:02:33,836
对于运动类 我用了一个橄榄球


67
00:02:35,196 --> 00:02:36,836
对于自然类


68
00:02:36,836 --> 00:02:39,486
我则用了一个可爱的小帐篷


69
00:02:40,856 --> 00:02:40,966
旁边有棵大松树


70
00:02:41,186 --> 00:02:42,536
你注意那儿还有


71
00:02:42,656 --> 00:02:43,306
这个其他文件夹


72
00:02:44,186 --> 00:02:45,686
这其实是我不想要的


73
00:02:45,686 --> 00:02:46,936
训练数据


74
00:02:46,936 --> 00:02:49,466
我希望我的模型能够学习


75
00:02:49,466 --> 00:02:51,326
任何不属于


76
00:02:51,326 --> 00:02:53,416
以上三个目标类的东西


77
00:02:53,416 --> 00:02:55,756
我希望我的模型将它们


78
00:02:56,726 --> 00:02:58,516
分到这个类中


79
00:02:58,686 --> 00:03:00,286
那么 我们来看看


80
00:03:00,286 --> 00:03:00,936
这里的一些例子


81
00:03:01,766 --> 00:03:05,186
例如 如果你们读了


82
00:03:05,186 --> 00:03:06,056
这个句子 有一些关于


83
00:03:06,056 --> 00:03:07,586
作家和 IMDB 的东西


84
00:03:07,586 --> 00:03:09,026
这显然与


85
00:03:09,026 --> 00:03:09,806
娱乐有关


86
00:03:13,006 --> 00:03:15,066
如果我进入其他文件夹


87
00:03:15,926 --> 00:03:20,006
它不是以上三个类中的一个


88
00:03:24,536 --> 00:03:25,546
这是关于数据的问题


89
00:03:25,796 --> 00:03:32,446
现在 我要进入 Create ML App


90
00:03:34,436 --> 00:03:36,806
为此 我转到开发人员工具中


91
00:03:36,806 --> 00:03:39,356
并找到 Create ML


92
00:03:42,116 --> 00:03:43,256
然而我要做一个新文件


93
00:03:43,256 --> 00:03:48,336
然后转去文本


94
00:03:48,496 --> 00:03:49,496
我会这样命名它


95
00:03:50,736 --> 00:03:53,906
创建 好的 我相信你们


96
00:03:53,906 --> 00:03:56,476
已经在早期的会议中


97
00:03:56,476 --> 00:03:58,096
看到了这个用户界面


98
00:03:58,096 --> 00:03:59,916
对象连接和子分类


99
00:04:00,226 --> 00:04:01,466
所以 我在这里就


100
00:04:01,466 --> 00:04:02,826
直接拖动我的训练数据


101
00:04:03,446 --> 00:04:05,956
所以它会为你们提供一些


102
00:04:05,956 --> 00:04:06,926
有关你们训练数据的反馈


103
00:04:07,366 --> 00:04:08,606
但是文本分类器的新功能是


104
00:04:08,606 --> 00:04:11,236
这个特殊的参数部分


105
00:04:11,866 --> 00:04:15,026
所以 对于今天的演示


106
00:04:15,026 --> 00:04:16,296
我将选择迁移学习


107
00:04:17,736 --> 00:04:19,065
如果我们看看它的话就知道


108
00:04:19,065 --> 00:04:20,596
自去年以来


109
00:04:20,596 --> 00:04:21,995
实际上前两种算法


110
00:04:21,995 --> 00:04:22,136
已经被鼓励使用了


111
00:04:22,776 --> 00:04:23,826
那么今年我们正在


112
00:04:23,826 --> 00:04:24,606
添加迁移学习


113
00:04:25,096 --> 00:04:27,086
对于演示 我将


114
00:04:27,086 --> 00:04:28,546
使用名为 Dynamic Embedding 的


115
00:04:28,546 --> 00:04:29,826
此功能提取器


116
00:04:30,156 --> 00:04:32,496
我将在稍后的演示之后


117
00:04:32,496 --> 00:04:33,946
详细介绍


118
00:04:33,946 --> 00:04:35,936
什么是迁移学习


119
00:04:35,936 --> 00:04:37,846
但现在你需要知道的


120
00:04:37,846 --> 00:04:39,256
是用 Dynamic Embedding 进行的迁移学习


121
00:04:39,676 --> 00:04:41,686
它实际上是一种


122
00:04:41,686 --> 00:04:43,096
注重输入文本的


123
00:04:43,096 --> 00:04:45,446
语义含义的算法


124
00:04:47,036 --> 00:04:48,216
我要开始训练数据了


125
00:04:49,346 --> 00:04:50,506
因此 一般来说


126
00:04:50,506 --> 00:04:52,726
迁移学习需要更长的时间来训练


127
00:04:53,516 --> 00:04:54,716
对于这个特定的数据集


128
00:04:55,176 --> 00:04:57,416
在这台特定的机器上


129
00:04:57,416 --> 00:04:58,316
大约需要五分钟


130
00:04:59,376 --> 00:05:01,196
好了 我不会干等着


131
00:05:02,666 --> 00:05:04,636
相反 我在这里预先选择的


132
00:05:04,966 --> 00:05:07,116
解决方案是在完全相同的数据上


133
00:05:07,116 --> 00:05:08,386
进行训练的


134
00:05:08,956 --> 00:05:12,286
模型一旦经过训练后


135
00:05:12,286 --> 00:05:14,996
精度测试可以很好地


136
00:05:14,996 --> 00:05:16,846
总结你的模型


137
00:05:16,846 --> 00:05:18,786
对不同的数据执行情况如何


138
00:05:18,786 --> 00:05:21,676
分解为不同的类做得如何


139
00:05:22,666 --> 00:05:24,216
看起来我的模型


140
00:05:24,216 --> 00:05:26,246
在训练验证和测试数据方面


141
00:05:26,246 --> 00:05:26,836
做得很好


142
00:05:27,486 --> 00:05:30,446
所以 我将直接跳转到


143
00:05:30,446 --> 00:05:31,196
输出选项卡


144
00:05:31,946 --> 00:05:34,566
此预览窗格给你提供了


145
00:05:34,636 --> 00:05:37,116
有关模型的一些总结


146
00:05:37,116 --> 00:05:38,906
以及一些快速实验的


147
00:05:38,906 --> 00:05:40,506
不同方法


148
00:05:41,286 --> 00:05:44,576
例如 如果你转到右下角


149
00:05:45,246 --> 00:05:47,526
则可以直接添加 File


150
00:05:47,526 --> 00:05:50,166
以进行快速测试


151
00:05:50,336 --> 00:05:56,016
或者 你可以跟踪


152
00:05:56,016 --> 00:05:57,756
模型能够预测该文件夹中


153
00:05:57,756 --> 00:06:00,406
所有文本文件的文件夹


154
00:06:01,256 --> 00:06:02,696
该模型实际上


155
00:06:02,696 --> 00:06:04,856
将使用每个文件中的


156
00:06:04,856 --> 00:06:06,276
整个文本来进行


157
00:06:06,276 --> 00:06:06,776
单个预测


158
00:06:07,306 --> 00:06:10,336
但是还有另一种方法


159
00:06:10,336 --> 00:06:12,416
可以让你进行快速实验


160
00:06:12,826 --> 00:06:13,626
即手动输入


161
00:06:16,446 --> 00:06:19,356
因此 在这个特定的文本输入部分


162
00:06:19,506 --> 00:06:22,066
当你 当我键入每个空格时


163
00:06:22,376 --> 00:06:25,566
或者如果我


164
00:06:25,616 --> 00:06:27,406
停止输入一段时间


165
00:06:27,406 --> 00:06:28,436
模型将进行预测


166
00:06:29,186 --> 00:06:30,966
那么 让我们看看它是如何运作的


167
00:06:33,136 --> 00:06:35,336
真是反败为胜啊


168
00:06:36,076 --> 00:06:40,886
运动类 让我们来试试


169
00:06:40,926 --> 00:06:41,546
不同的东西


170
00:06:42,896 --> 00:06:46,796
本季结局为情节


171
00:06:47,486 --> 00:06:48,966
增添了一丝转折


172
00:06:49,456 --> 00:06:52,076
这似乎刚刚好


173
00:06:52,386 --> 00:06:56,826
娱乐类 [掌声]


174
00:06:57,326 --> 00:06:58,516
我实际上也想尝试


175
00:06:58,516 --> 00:07:00,086
一些更近期和


176
00:07:00,086 --> 00:07:00,566
更相关的东西


177
00:07:01,006 --> 00:07:03,166
我昨晚才想到这件事


178
00:07:04,266 --> 00:07:15,976
猛龙是联盟总冠军


179
00:07:18,316 --> 00:07:18,796
自然类 [笑声]


180
00:07:20,476 --> 00:07:21,856
好吧 如果我切换语境的话


181
00:07:26,016 --> 00:07:27,096
[掌声]


182
00:07:27,096 --> 00:07:27,946
它也可以预测运动类


183
00:07:28,516 --> 00:07:32,926
[掌声]


184
00:07:33,426 --> 00:07:35,206
好了 我对模型的表现


185
00:07:35,206 --> 00:07:35,966
非常满意


186
00:07:36,766 --> 00:07:38,276
现在我准备好进行布置


187
00:07:38,556 --> 00:07:40,186
所以 我只需将其拖出来


188
00:07:40,536 --> 00:07:42,086
我就可以把它放在


189
00:07:42,146 --> 00:07:42,626
我的 iOS 设备上


190
00:07:51,556 --> 00:07:53,186
这就是你如何使用


191
00:07:53,186 --> 00:07:54,876
迁移学习训练


192
00:07:54,876 --> 00:07:55,146
文本分类器


193
00:07:56,366 --> 00:07:58,286
但你们可能想问


194
00:07:58,286 --> 00:07:59,856
什么是迁移学习


195
00:08:02,196 --> 00:08:03,896
迁移学习是一种功能强大的


196
00:08:03,896 --> 00:08:05,736
机器学习技术


197
00:08:05,736 --> 00:08:07,526
这其中针对一个特定任务的


198
00:08:07,526 --> 00:08:09,516
大量数据训练模型


199
00:08:10,086 --> 00:08:11,936
可以被重新用于另一个任务


200
00:08:11,936 --> 00:08:15,226
因此你们作为开发人员


201
00:08:15,226 --> 00:08:17,226
只需要准备有限数目的数据


202
00:08:17,226 --> 00:08:19,486
并同样可以获得


203
00:08:19,486 --> 00:08:21,256
个性化的机器学习模型


204
00:08:21,706 --> 00:08:25,816
Create ML 如今实际上使用


205
00:08:25,816 --> 00:08:26,646
迁移学习来进行


206
00:08:26,646 --> 00:08:27,866
图像分类


207
00:08:28,326 --> 00:08:31,536
现在我们将它带到文本中


208
00:08:32,426 --> 00:08:34,296
那么 要为文本训练


209
00:08:34,296 --> 00:08:36,866
一个好的迁移学习模型


210
00:08:36,866 --> 00:08:38,256
问题就有点不同了


211
00:08:39,176 --> 00:08:40,796
如果你们读到这句话


212
00:08:41,056 --> 00:08:44,806
“我能把车停在公园入口附近”


213
00:08:46,736 --> 00:08:48,936
对于一个使用传统技术


214
00:08:49,506 --> 00:08:51,776
或研究嵌入


215
00:08:51,776 --> 00:08:54,726
进行训练的模型


216
00:08:54,726 --> 00:08:57,586
这两个部分看起来是完全相同的


217
00:08:57,766 --> 00:08:59,386
但是对于一个使用 Dynamic Embedding 


218
00:08:59,386 --> 00:09:01,036
的迁移学习训练的模型


219
00:09:01,036 --> 00:09:03,706
因为它注重


220
00:09:03,706 --> 00:09:04,916
整个上下文的


221
00:09:04,916 --> 00:09:06,716
语义含义


222
00:09:07,406 --> 00:09:09,826
所以它能够弄清楚


223
00:09:09,826 --> 00:09:11,216
这两个部分实际上意味着


224
00:09:11,216 --> 00:09:12,666
不同的事物


225
00:09:16,136 --> 00:09:18,206
要训练这样好的一个模型


226
00:09:18,206 --> 00:09:19,586
你需要在很多文本上训练


227
00:09:20,056 --> 00:09:21,586
这正是我们所做的


228
00:09:22,566 --> 00:09:26,716
我们对数十亿文本进行了训练


229
00:09:26,876 --> 00:09:28,096
并将这种预先训练的模型


230
00:09:28,096 --> 00:09:29,586
发送到你们的移动设备上去


231
00:09:30,066 --> 00:09:31,956
更重要的是


232
00:09:31,956 --> 00:09:34,446
我们优化了其性能


233
00:09:34,446 --> 00:09:38,316
因此你们只需准备


234
00:09:38,466 --> 00:09:40,126
有限数量的原始文本


235
00:09:40,626 --> 00:09:43,686
将其发送到 Create ML App 上


236
00:09:44,006 --> 00:09:46,286
在它深处 它将与


237
00:09:46,286 --> 00:09:47,736
已经是你们 OS 中


238
00:09:47,736 --> 00:09:50,956
一部分的模型进行交互


239
00:09:50,956 --> 00:09:52,816
并提供自定义文本分类器


240
00:09:55,696 --> 00:09:57,236
而且 你们可以在 iOS 设备上


241
00:09:57,236 --> 00:09:59,116
无缝地部署


242
00:09:59,436 --> 00:10:01,386
相同的模型 因为


243
00:10:01,386 --> 00:10:03,116
预训练模型


244
00:10:03,116 --> 00:10:06,166
已经可供你们使用


245
00:10:06,476 --> 00:10:09,216
好了 这就是使用 Create ML App


246
00:10:09,216 --> 00:10:11,016
训练文本分类器的


247
00:10:11,016 --> 00:10:12,116
工作流程


248
00:10:13,216 --> 00:10:14,816
如果你也想编写代码


249
00:10:15,056 --> 00:10:17,706
那同样会很容易


250
00:10:18,816 --> 00:10:20,106
要使用带 Dynamic Embedding 的


251
00:10:20,106 --> 00:10:22,136
迁移学习


252
00:10:22,136 --> 00:10:23,496
你唯一需要指定的是


253
00:10:23,496 --> 00:10:24,816
此模型参数


254
00:10:25,616 --> 00:10:27,096
其余代码


255
00:10:27,096 --> 00:10:27,976
与去年完全相同


256
00:10:32,986 --> 00:10:35,246
现在 我已经向你们展示了


257
00:10:35,246 --> 00:10:37,756
如何训练文本分类器


258
00:10:37,756 --> 00:10:39,866
但我还想给你们一些简单的提示


259
00:10:39,866 --> 00:10:42,476
以便充分利用你们的文本分类器


260
00:10:45,086 --> 00:10:47,876
现在 选择适合


261
00:10:47,876 --> 00:10:49,206
你们所用例子的算法


262
00:10:50,296 --> 00:10:51,836
迁移学习


263
00:10:51,836 --> 00:10:53,966
只是文本分类器支持的


264
00:10:53,966 --> 00:10:55,256
三种算法之一


265
00:10:57,656 --> 00:10:58,726
不同的算法有


266
00:10:58,806 --> 00:10:59,556
不同的侧重点


267
00:11:00,676 --> 00:11:02,236
要找出哪一个最适合


268
00:11:02,236 --> 00:11:04,596
你的所选例子


269
00:11:04,596 --> 00:11:05,926
请看看这之后举行的


270
00:11:05,926 --> 00:11:10,156
Natural Language 会议


271
00:11:10,346 --> 00:11:11,816
提供均衡的分类


272
00:11:12,196 --> 00:11:13,256
这是非常重要的


273
00:11:14,376 --> 00:11:15,686
在我向你们展示的特定示例中


274
00:11:15,686 --> 00:11:17,606
因为每个文本文件


275
00:11:17,606 --> 00:11:19,756
都是一个训练示例


276
00:11:20,526 --> 00:11:22,076
所以 我大致在每个文件夹中


277
00:11:22,076 --> 00:11:24,646
保留了相同数量的文本文件


278
00:11:28,086 --> 00:11:29,126
数据一致性


279
00:11:29,626 --> 00:11:31,256
如果你希望你的文本分类器


280
00:11:31,256 --> 00:11:33,226
主要用于短句


281
00:11:33,226 --> 00:11:35,876
就像我一样


282
00:11:35,876 --> 00:11:37,336
你的训练数据应该


283
00:11:37,336 --> 00:11:39,026
主要由这些示例组成


284
00:11:39,906 --> 00:11:42,876
如果你希望你的文本分类器


285
00:11:42,876 --> 00:11:44,196
能够处理


286
00:11:44,196 --> 00:11:47,076
几句话 段落 甚至整篇文章


287
00:11:47,076 --> 00:11:49,866
你也需要确保


288
00:11:49,866 --> 00:11:51,236
你的训练数据


289
00:11:51,236 --> 00:11:52,626
同样包括这些例子


290
00:11:53,516 --> 00:11:58,506
[掌声]

