1
00:00:06,516 --> 00:00:16,500
[ 人群讲话声 ]


2
00:00:23,516 --> 00:00:27,046
[ 掌声 ]


3
00:00:27,546 --> 00:00:30,546
>> 哇哦 非常激动能够来到	


4
00:00:30,546 --> 00:00:30,676
这里


5
00:00:31,606 --> 00:00:32,786
我叫 Gaurav


6
00:00:32,786 --> 00:00:35,046
今天我们将会


7
00:00:35,776 --> 00:00:37,466
探讨一下机器学习


8
00:00:37,466 --> 00:00:38,686
机器学习是一项非常


9
00:00:38,686 --> 00:00:39,866
强大的技术


10
00:00:40,516 --> 00:00:42,066
再结合我们设备的性能


11
00:00:42,066 --> 00:00:44,656
你们能够创造出许多


12
00:00:44,656 --> 00:00:46,556
令人惊叹的体验


13
00:00:47,896 --> 00:00:49,946
比如说 你可以


14
00:00:49,946 --> 00:00:51,746
进行实时图像识别


15
00:00:52,346 --> 00:00:53,846
和内容创建


16
00:00:54,926 --> 00:00:56,366
在接下来的40分钟里 我们


17
00:00:56,366 --> 00:00:57,576
将会向大家讲述


18
00:00:57,576 --> 00:01:00,126
那些体验以及 Apple 如何


19
00:01:00,126 --> 00:01:01,866
方便快捷地


20
00:01:02,076 --> 00:01:03,846
将机器学习融入


21
00:01:03,846 --> 00:01:04,965
你们的 App 中


22
00:01:06,156 --> 00:01:07,916
具体来说 我们将


23
00:01:07,916 --> 00:01:10,366
专注于讨论 Core ML 和我们的机器


24
00:01:10,366 --> 00:01:11,066
学习框架


25
00:01:14,946 --> 00:01:17,026
在 Apple 中 我们正在广泛地使用


26
00:01:17,026 --> 00:01:18,786
机器学习


27
00:01:19,796 --> 00:01:22,586
在我们的照片 App 中 我们使用它来做


28
00:01:22,586 --> 00:01:24,096
人物识别 


29
00:01:24,096 --> 00:01:24,886
场景识别


30
00:01:28,796 --> 00:01:31,106
在我们的键盘 App 中 我们使用它


31
00:01:31,106 --> 00:01:32,496
来做输入预测


32
00:01:33,006 --> 00:01:34,146
和智能回复


33
00:01:35,236 --> 00:01:37,006
我们甚至在 Apple Watch 中使用它


34
00:01:37,006 --> 00:01:38,366
来做智能回复


35
00:01:38,366 --> 00:01:39,736
和手写输入识别


36
00:01:40,926 --> 00:01:43,466
我很确信你们也同样希望


37
00:01:43,466 --> 00:01:45,966
创造出类似的体验


38
00:01:45,966 --> 00:01:47,306
在你们自己的 App 中


39
00:01:48,206 --> 00:01:51,346
比如说 你们中的一些人可能


40
00:01:51,346 --> 00:01:52,646
想要做实时图像


41
00:01:52,646 --> 00:01:53,446
识别


42
00:01:53,996 --> 00:01:56,856
这样的话 你们可以告诉用户


43
00:01:56,856 --> 00:01:59,046
为他们提供


44
00:01:59,046 --> 00:02:00,636
他们所看到的 与场景更加相关的信息


45
00:02:00,636 --> 00:02:02,246
比如说


46
00:02:02,246 --> 00:02:03,536
他们是不是


47
00:02:03,536 --> 00:02:03,956
在吃热狗


48
00:02:04,516 --> 00:02:07,816
[ 笑声 ]


49
00:02:08,316 --> 00:02:11,656
我们希望你们能够启用


50
00:02:11,656 --> 00:02:13,956
这些非常棒的功能


51
00:02:13,956 --> 00:02:14,236
在你们的 App 里


52
00:02:15,076 --> 00:02:17,176
因此 我们推出


53
00:02:17,266 --> 00:02:18,996
机器学习框架 


54
00:02:18,996 --> 00:02:20,476
让你们能够启用所有这些


55
00:02:20,476 --> 00:02:21,116
酷炫的东西


56
00:02:21,536 --> 00:02:22,586
你们该鼓掌了


57
00:02:23,516 --> 00:02:27,916
[ 掌声 ]


58
00:02:28,416 --> 00:02:30,276
但是在我们鼓掌之前 我们应该


59
00:02:30,276 --> 00:02:31,686
首先了解我们需要


60
00:02:31,686 --> 00:02:32,816
机器学习


61
00:02:32,816 --> 00:02:33,096
的原因是什么


62
00:02:33,616 --> 00:02:38,826
以及你们什么时候会用到


63
00:02:38,886 --> 00:02:39,036
机器学习


64
00:02:39,036 --> 00:02:42,486
假设我是一名花匠


65
00:02:42,986 --> 00:02:44,926
我想展示的全都是


66
00:02:44,926 --> 00:02:46,416
玫瑰的图片


67
00:02:46,416 --> 00:02:47,886
在用户照片图库当中


68
00:02:48,596 --> 00:02:50,386
这看起来是一件挺简单的事


69
00:02:50,386 --> 00:02:51,876
那么我要来编程


70
00:02:53,196 --> 00:02:56,006
可能我会从


71
00:02:56,006 --> 00:02:56,756
颜色入手


72
00:02:57,346 --> 00:02:59,406
如果照片里的主色调


73
00:02:59,406 --> 00:03:00,766
是红色 那这可能是一朵


74
00:03:00,766 --> 00:03:01,026
玫瑰


75
00:03:02,576 --> 00:03:03,966
问题在于 事实上


76
00:03:03,966 --> 00:03:05,386
有许多玫瑰是白色的


77
00:03:05,386 --> 00:03:07,876
或者是


78
00:03:09,076 --> 00:03:09,216
黄色的


79
00:03:09,456 --> 00:03:11,916
所以事实上我要更深入一些


80
00:03:11,916 --> 00:03:13,996
描述外形


81
00:03:13,996 --> 00:03:17,716
很快我就意识到


82
00:03:17,716 --> 00:03:20,016
这是非常困难的


83
00:03:20,356 --> 00:03:23,866
就算去写一个如此简单的程序


84
00:03:25,656 --> 00:03:27,016
通过编程的方式


85
00:03:27,016 --> 00:03:28,276
因此 我们需要机器学习


86
00:03:28,276 --> 00:03:29,216
来帮助我们


87
00:03:30,546 --> 00:03:32,116
与其去以编程的形式来描述


88
00:03:32,116 --> 00:03:33,336
玫瑰是什么样的


89
00:03:33,376 --> 00:03:34,966
我们会


90
00:03:34,966 --> 00:03:37,816
通过我们的经验来描述一朵玫瑰


91
00:03:38,176 --> 00:03:39,026
我们会去了解


92
00:03:39,026 --> 00:03:40,466
玫瑰所代表的东西


93
00:03:40,726 --> 00:03:41,386
通过以观察经验为主的方式


94
00:03:42,036 --> 00:03:43,896
事实上机器学习


95
00:03:43,896 --> 00:03:44,416
有两步


96
00:03:45,146 --> 00:03:46,406
第一步 训练


97
00:03:48,116 --> 00:03:50,096
那么在这一情况下你们要做什么


98
00:03:50,096 --> 00:03:51,376
你们要在离线情况下收集


99
00:03:51,376 --> 00:03:53,056
玫瑰 百合 向日葵的图片


100
00:03:53,666 --> 00:03:56,086
并标记它们


101
00:03:56,086 --> 00:03:59,036
然后你们要在一个


102
00:03:59,096 --> 00:04:01,156
学习算法中运行它们


103
00:04:01,156 --> 00:04:05,506
之后你们会得到一个我们称之为


104
00:04:05,546 --> 00:04:06,036
模型的东西


105
00:04:07,416 --> 00:04:10,396
这个模型


106
00:04:10,396 --> 00:04:12,616
代表着一朵玫瑰


107
00:04:13,286 --> 00:04:14,896
是什么样子的


108
00:04:15,116 --> 00:04:17,055
几乎所有这些事情


109
00:04:17,156 --> 00:04:17,656
都是在离线状态下完成的


110
00:04:18,446 --> 00:04:21,196
有一个巨大的 [未听清]


111
00:04:21,196 --> 00:04:23,426
在互联网上 围绕着训练这个步骤


112
00:04:23,906 --> 00:04:25,346
训练这一步骤算是一个复杂的问题


113
00:04:27,236 --> 00:04:28,846
那么一旦你们有了这个模型


114
00:04:28,846 --> 00:04:30,026
你们就要使用这个模型


115
00:04:30,026 --> 00:04:33,976
那么你们要怎样做


116
00:04:33,976 --> 00:04:36,236
拍一张玫瑰花的照片


117
00:04:36,286 --> 00:04:38,056
将这个模型嵌入你们的 App


118
00:04:38,136 --> 00:04:41,706
将照片在模型中运行


119
00:04:42,376 --> 00:04:44,546
你们就会得到标签	


120
00:04:44,546 --> 00:04:44,996
以及可信度


121
00:04:45,806 --> 00:04:48,436
这一步被称为推断


122
00:04:49,726 --> 00:04:52,036
训练这一步是非常复杂的


123
00:04:52,336 --> 00:04:53,886
但在今天 推断也在变得


124
00:04:53,886 --> 00:04:55,636
非常非常具有挑战性


125
00:04:58,686 --> 00:05:00,526
比如说 如果你们想


126
00:05:00,526 --> 00:05:02,516
以编程的方式描述出一个全新的


127
00:05:02,516 --> 00:05:05,336
Deep Neural Network （深度神经网络） 在你们的代码中


128
00:05:05,336 --> 00:05:06,336
那你们将要写出


129
00:05:06,336 --> 00:05:07,726
上千行的代码


130
00:05:07,726 --> 00:05:08,686
仅仅为了描述出这个网络


131
00:05:09,336 --> 00:05:12,146
这会是 [未听清] 很单调乏味的


132
00:05:12,146 --> 00:05:15,866
很有可能你们会面临你们


133
00:05:15,866 --> 00:05:17,946
最大的挑战 就是当你们想证明


134
00:05:17,946 --> 00:05:21,436
这样一个程序的正确性的时候


135
00:05:21,436 --> 00:05:23,826
一旦你们确定


136
00:05:23,826 --> 00:05:26,636
这程序完全正确 你们还需要


137
00:05:26,636 --> 00:05:28,656
确认这一程序


138
00:05:28,656 --> 00:05:30,176
尽可能有着最好的性能表现


139
00:05:31,996 --> 00:05:33,886
最后 你还必须得确认


140
00:05:33,886 --> 00:05:35,496
高能效


141
00:05:35,496 --> 00:05:36,686
也包括在内


142
00:05:37,216 --> 00:05:40,116
这些工作是


143
00:05:40,116 --> 00:05:43,216
非常非常具有挑战性的


144
00:05:43,596 --> 00:05:44,246
同时也可以让你完全深陷其中


145
00:05:44,816 --> 00:05:48,046
在 Apple 中 我们使用设备端的


146
00:05:48,046 --> 00:05:49,306
机器学习


147
00:05:49,306 --> 00:05:49,996
已经有很多年了


148
00:05:50,536 --> 00:05:53,536
并且我们已经完成了


149
00:05:53,536 --> 00:05:54,046
这些挑战


150
00:05:54,126 --> 00:05:55,386
我们已经面对过这些挑战


151
00:05:56,016 --> 00:05:56,716
并且成功完成了它们


152
00:05:57,286 --> 00:05:58,466
我们真的不希望


153
00:05:58,466 --> 00:05:59,096
由你们来面对这些难题


154
00:05:59,096 --> 00:06:00,066
我们会替你们搞定


155
00:06:00,306 --> 00:06:01,746
我们希望你们只用专注于


156
00:06:01,746 --> 00:06:02,596
体验即可


157
00:06:02,596 --> 00:06:03,166
我们会直接给你们编译器


158
00:06:03,166 --> 00:06:04,476
尽可能是


159
00:06:04,476 --> 00:06:05,776
最好的编译器


160
00:06:06,536 --> 00:06:09,136
因此 我们为你们推出


161
00:06:09,536 --> 00:06:11,216
机器学习框架


162
00:06:11,216 --> 00:06:13,706
这样我们就可以来解决


163
00:06:13,706 --> 00:06:15,516
所有的技术难题 由你们


164
00:06:15,586 --> 00:06:17,016
来负责所有体验方面的问题


165
00:06:17,296 --> 00:06:17,656
在你们的 App 里


166
00:06:18,786 --> 00:06:21,426
这样做的话 我们要


167
00:06:21,426 --> 00:06:22,686
遵从一种分层的形式


168
00:06:23,376 --> 00:06:26,966
最上层的是你们的 App


169
00:06:29,256 --> 00:06:31,016
我们推出全新的


170
00:06:31,016 --> 00:06:32,746
Domain Specific Framework （特定领域框架）


171
00:06:32,746 --> 00:06:33,686
具体来说是 


172
00:06:34,876 --> 00:06:36,496
Vision Framework （视觉框架）


173
00:06:36,496 --> 00:06:38,846
使得你们能够做所有


174
00:06:38,846 --> 00:06:40,266
与计算机视觉


175
00:06:40,266 --> 00:06:40,716
相关的工作


176
00:06:41,506 --> 00:06:42,976
计算机视觉在 Vision Framework （视觉框架）中


177
00:06:42,976 --> 00:06:44,626
最棒的部分


178
00:06:44,626 --> 00:06:46,406
就是你不需要是一名


179
00:06:46,406 --> 00:06:49,616
视觉构造专家


180
00:06:49,616 --> 00:06:50,406
就可以使用 Vision Framework （视觉框架）


181
00:06:50,906 --> 00:06:53,816
我们也在不断强化我们的


182
00:06:53,816 --> 00:06:56,966
NLP API （自然语言处理接口） 来容纳更多的语言


183
00:06:57,466 --> 00:06:58,606
和更多的功能


184
00:06:59,196 --> 00:07:02,486
我们推出一个全新的


185
00:07:02,486 --> 00:07:04,106
框架 它叫做 Core ML


186
00:07:05,076 --> 00:07:06,676
这一框架


187
00:07:06,756 --> 00:07:08,366
对机器学习算法有着全面的支持


188
00:07:08,366 --> 00:07:10,286
更有深度的学习机制


189
00:07:10,586 --> 00:07:11,656
以及标准


190
00:07:12,276 --> 00:07:16,266
那么最终 所有这些


191
00:07:16,266 --> 00:07:18,496
框架都是建立在


192
00:07:18,496 --> 00:07:20,596
Accelerate and Metal Performance


193
00:07:20,596 --> 00:07:20,826
Shaders 上的


194
00:07:21,396 --> 00:07:28,086
我们可以通过 Vision Framework （视觉框架）


195
00:07:28,306 --> 00:07:29,506
让大家先睹为快


196
00:07:31,206 --> 00:07:33,526
Vision 是我们的一站式商店


197
00:07:33,526 --> 00:07:34,656
在其中可以做所有与


198
00:07:34,656 --> 00:07:36,006
计算机视觉和图像有关的事 


199
00:07:37,056 --> 00:07:38,966
你们可以用它来做像


200
00:07:39,026 --> 00:07:43,316
物体追踪或者


201
00:07:43,316 --> 00:07:44,506
基于深度学习的


202
00:07:44,506 --> 00:07:45,006
面部识别


203
00:07:45,006 --> 00:07:47,266
Vision Framework （视觉框架）


204
00:07:47,266 --> 00:07:47,736
能做的还有很多


205
00:07:47,736 --> 00:07:50,306
我们会更加细化地讨论 Vision 


206
00:07:50,576 --> 00:07:52,066
在明天下午的时候


207
00:07:52,626 --> 00:07:59,566
NLP 这是我们另一个一站式商店


208
00:07:59,566 --> 00:08:00,836
用来进行文字处理


209
00:08:01,366 --> 00:08:04,686
你们可以使用它来做


210
00:08:04,686 --> 00:08:05,916
诸如语言鉴别之类的事


211
00:08:07,126 --> 00:08:09,416
那么我们也会推出 


212
00:08:09,416 --> 00:08:10,886
Named Entity Recognition API （命名实体识别接口）


213
00:08:11,956 --> 00:08:14,986
这些 API 可以告诉你


214
00:08:14,986 --> 00:08:17,116
在你的文字中这是否是一个


215
00:08:17,116 --> 00:08:18,916
地名 人名 


216
00:08:18,916 --> 00:08:19,626
或是组织机构名


217
00:08:20,146 --> 00:08:21,246
我们相信这对于许多 App 开发者而言


218
00:08:21,246 --> 00:08:22,856
是非常强大的功能


219
00:08:23,256 --> 00:08:24,276
所以请各位去更多的了解它


220
00:08:24,656 --> 00:08:26,086
在明天早上的


221
00:08:26,156 --> 00:08:27,946
有关 NLP 的研讨会中


222
00:08:29,876 --> 00:08:33,606
Core ML 直到现在


223
00:08:33,606 --> 00:08:35,476
我们一直在讨论


224
00:08:35,566 --> 00:08:35,936
Domain Specific Framework（特定领域框架）


225
00:08:36,395 --> 00:08:37,916
Core ML 是我们的 


226
00:08:37,916 --> 00:08:39,806
机器学习框架


227
00:08:39,806 --> 00:08:40,525
并且它是对领域不敏感的


228
00:08:41,756 --> 00:08:44,316
它支持许多种


229
00:08:44,316 --> 00:08:47,136
输入形式 例如图像 文字 


230
00:08:48,256 --> 00:08:50,636
字典 原始数据


231
00:08:51,566 --> 00:08:53,156
所以你可以做例如


232
00:08:53,196 --> 00:08:53,566
标记音乐之类的事


233
00:08:55,876 --> 00:08:57,346
Core ML 还有一个有趣的地方


234
00:08:57,346 --> 00:08:59,006
就是


235
00:08:59,006 --> 00:09:01,116
他有处理混合


236
00:09:01,116 --> 00:09:02,136
输入输出类型的能力


237
00:09:02,446 --> 00:09:04,396
你可以拍一张照片


238
00:09:04,396 --> 00:09:06,286
然后得到一段文字


239
00:09:09,116 --> 00:09:10,916
这些框架最棒的部分


240
00:09:11,026 --> 00:09:13,386
在于它们可以一起


241
00:09:13,386 --> 00:09:13,776
工作


242
00:09:15,086 --> 00:09:17,316
你可以写一段文字 然后使它


243
00:09:17,316 --> 00:09:18,866
通过你的 NLP 之后你得到一个输出值


244
00:09:18,866 --> 00:09:20,476
接着你运行使它通过


245
00:09:20,476 --> 00:09:22,356
Core ML 来做出如


246
00:09:22,436 --> 00:09:23,376
情感分析之类的事


247
00:09:23,376 --> 00:09:25,336
我们将会在关于 Core ML 的研讨会上


248
00:09:25,336 --> 00:09:27,666
更细化地探讨这些


249
00:09:27,746 --> 00:09:29,706
如何进行操作


250
00:09:30,166 --> 00:09:32,876
上述研讨会将会在周四时举行


251
00:09:33,026 --> 00:09:34,556
所有这些框架


252
00:09:34,556 --> 00:09:36,546
都是由 Accelerate and MPS 	


253
00:09:36,856 --> 00:09:37,106
所驱动的


254
00:09:38,316 --> 00:09:39,276
这些就是我们的引擎


255
00:09:40,746 --> 00:09:42,946
无论何时当你们需要某些


256
00:09:43,566 --> 00:09:45,246
与数学相关的功能的时候


257
00:09:45,246 --> 00:09:46,566
你们可以使用 Accelerate and MPS


258
00:09:46,566 --> 00:09:47,876
所以它不一定必须


259
00:09:48,056 --> 00:09:49,436
与机器学习


260
00:09:49,436 --> 00:09:49,706
相关联


261
00:09:50,116 --> 00:09:53,576
你们也可以


262
00:09:53,956 --> 00:09:57,766
在创造定制化的 ML 模型时


263
00:09:57,766 --> 00:10:00,876
使用 Accelerate and MPS


264
00:10:00,876 --> 00:10:02,156
所以当你们在使用


265
00:10:02,156 --> 00:10:03,746
机器学习模型时 


266
00:10:03,746 --> 00:10:05,776
你会想要用到 Accelerate and MPS 


267
00:10:08,076 --> 00:10:10,836
所有这些 API


268
00:10:10,836 --> 00:10:11,196
都是在用户设备上运行的


269
00:10:11,266 --> 00:10:12,486
并且它们都有非常


270
00:10:12,486 --> 00:10:13,036
优秀的性能表现


271
00:10:13,146 --> 00:10:14,656
我们十分努力地钻研


272
00:10:14,656 --> 00:10:15,846
以确保你们能够得到最好的	


273
00:10:15,846 --> 00:10:16,856
性能表现


274
00:10:18,346 --> 00:10:19,576
因为它们是在用户设备上进行学习的


275
00:10:19,576 --> 00:10:21,786
所以具有以下优势


276
00:10:22,366 --> 00:10:24,456
首先 用户个人隐私


277
00:10:24,626 --> 00:10:27,676
用户非常乐意知道


278
00:10:27,676 --> 00:10:28,716
你并没有


279
00:10:28,716 --> 00:10:30,896
发送他们的个人短信 文字


280
00:10:30,896 --> 00:10:34,456
和图像到服务器上


281
00:10:34,456 --> 00:10:35,866
你们的用户不需要花费额外的


282
00:10:35,866 --> 00:10:38,956
数据流量 来接收这些


283
00:10:38,956 --> 00:10:40,556
不 来发送这些


284
00:10:40,556 --> 00:10:42,686
到服务器端以获得	


285
00:10:44,176 --> 00:10:44,566
预测功能


286
00:10:44,566 --> 00:10:46,496
你们同样不用支付


287
00:10:46,706 --> 00:10:48,136
一大笔钱


288
00:10:48,136 --> 00:10:49,516
给服务器公司 就为了


289
00:10:49,516 --> 00:10:50,586
建立服务器来获得


290
00:10:50,586 --> 00:10:51,176
预测的功能


291
00:10:51,726 --> 00:10:53,136
我们设备的


292
00:10:53,136 --> 00:10:53,486
性能非常非常的强大


293
00:10:53,486 --> 00:10:54,696
你们可以在设备上做许多事  


294
00:10:55,306 --> 00:11:00,206
最后 你的 App 会保持


295
00:11:00,206 --> 00:11:00,646
可使用的状态


296
00:11:01,866 --> 00:11:03,856
让我们假设你们的用户去了


297
00:11:03,936 --> 00:11:06,896
约塞米蒂国家公园里的荒野


298
00:11:06,896 --> 00:11:08,246
到了一个没有


299
00:11:08,246 --> 00:11:08,966
网络的地方


300
00:11:10,076 --> 00:11:11,186
他们还是能够使用你们的 App


301
00:11:11,186 --> 00:11:13,186
这是非常强大的


302
00:11:14,476 --> 00:11:17,366
然而 也许你们能做的最棒的事之一


303
00:11:17,436 --> 00:11:19,686
就是


304
00:11:19,686 --> 00:11:20,396
实时机器学习


305
00:11:21,706 --> 00:11:23,396
我们的设备性能非常强大


306
00:11:23,396 --> 00:11:25,136
它们可以运行 Modern Deep Neural Network（现代深度神经网络）


307
00:11:25,136 --> 00:11:28,356
例如 ResNet 15


308
00:11:28,356 --> 00:11:29,656
[未听清 ]


309
00:11:29,656 --> 00:11:32,966
你们可以使用我们的设备来做


310
00:11:32,966 --> 00:11:34,426
实时图像识别


311
00:11:34,816 --> 00:11:37,176
在这些场景下 你不会有


312
00:11:37,226 --> 00:11:39,306
任何延迟就能够获得


313
00:11:40,076 --> 00:11:42,146
实际应用


314
00:11:43,516 --> 00:11:51,296
[ 掌声 ]


315
00:11:51,796 --> 00:11:53,336
所以对于任何具有潜在敏感性的事物


316
00:11:53,396 --> 00:11:54,716
你可能会使用


317
00:11:54,896 --> 00:11:56,326
实时图像识别


318
00:11:56,326 --> 00:12:01,276
那么我在这里简要重述一下


319
00:12:01,276 --> 00:12:02,556
我们将会推出一系列的机器学习


320
00:12:02,556 --> 00:12:03,286
框架


321
00:12:03,816 --> 00:12:05,606
如果你的 App 是以视觉显示为主的


322
00:12:05,786 --> 00:12:07,066
请务必使用


323
00:12:07,066 --> 00:12:07,516
Vision Framework （视觉框架）


324
00:12:08,166 --> 00:12:10,326
如果你的 App 是基于文字的


325
00:12:10,386 --> 00:12:11,486
请使用 NLP


326
00:12:12,226 --> 00:12:14,426
那么如果你觉得 NLP 和 Vision Framework（视觉框架）


327
00:12:14,426 --> 00:12:16,286
都没有提供


328
00:12:16,776 --> 00:12:18,896
你所需要的 API


329
00:12:18,896 --> 00:12:19,956
就直接去到 Core ML 层面


330
00:12:20,266 --> 00:12:21,996
Core ML 可对


331
00:12:22,666 --> 00:12:24,366
标准机器学习


332
00:12:24,366 --> 00:12:26,076
和深度学习算法


333
00:12:27,046 --> 00:12:27,586
提供全面支持


334
00:12:27,586 --> 00:12:28,816
假设你


335
00:12:28,956 --> 00:12:30,736
[未听清] 你的 API 机器


336
00:12:30,736 --> 00:12:31,906
学习算法 那么你


337
00:12:31,906 --> 00:12:34,346
应该去使用 Accelerate and MPS.


338
00:12:34,996 --> 00:12:36,806
在接下来的几天里 我们将会深入地探讨


339
00:12:36,806 --> 00:12:39,116
这些框架


340
00:12:39,116 --> 00:12:41,366
所以你们


341
00:12:41,896 --> 00:12:43,796
[未听清] 但是今天


342
00:12:43,796 --> 00:12:44,956
让我们只关注于 Core ML.


343
00:12:44,956 --> 00:12:46,806
接下来 我将邀请


344
00:12:46,866 --> 00:12:50,586
我的朋友和同事 Micheal 上场


345
00:12:51,696 --> 00:12:53,356
>> 谢了 Gaurav 


346
00:12:53,486 --> 00:12:54,186
大家好


347
00:12:54,186 --> 00:12:56,056
我非常激动能够在这里介绍


348
00:12:56,056 --> 00:12:58,066
Core ML 以及它在帮助你们


349
00:12:58,066 --> 00:13:00,066
创造一款优秀的 App 时所扮演的角色


350
00:13:00,996 --> 00:13:02,246
我们的讨论将从


351
00:13:02,246 --> 00:13:04,146
高级别 Core ML 的主要目的概览


352
00:13:04,146 --> 00:13:04,976
开始


353
00:13:06,056 --> 00:13:07,106
之后我们会讨论一些


354
00:13:07,106 --> 00:13:08,286
关于模型的事项以及它们


355
00:13:08,286 --> 00:13:08,976
是如果被表现出来的


356
00:13:09,016 --> 00:13:11,666
随后我们会带大家了解一下


357
00:13:11,666 --> 00:13:13,196
使用 Core ML 的


358
00:13:13,196 --> 00:13:16,766
典型的开发过程


359
00:13:17,006 --> 00:13:18,766
Core ML 框架


360
00:13:18,766 --> 00:13:20,956
适用于 macOS iOS


361
00:13:22,186 --> 00:13:23,716
watchOS 和 tvOS


362
00:13:25,046 --> 00:13:26,676
但 Core ML 不仅仅是


363
00:13:26,676 --> 00:13:28,946
一个框架和一大堆的 API 


364
00:13:29,436 --> 00:13:30,946
它实际上是一套开发工具


365
00:13:30,946 --> 00:13:33,016
被设计用于


366
00:13:33,016 --> 00:13:35,046
尽可能地简化


367
00:13:35,046 --> 00:13:36,506
机器学习模型的创造


368
00:13:36,506 --> 00:13:38,826
并将其融入你们的 App


369
00:13:39,556 --> 00:13:41,366
这会让你们专注于


370
00:13:41,366 --> 00:13:42,826
你们希望实现的用户体验


371
00:13:42,826 --> 00:13:44,216
而不是


372
00:13:44,216 --> 00:13:45,546
代码编译的细节方面


373
00:13:47,876 --> 00:13:51,446
Core ML 使用非常简单


374
00:13:51,446 --> 00:13:52,476
它会提供给你所需要的性能表现


375
00:13:52,476 --> 00:13:55,166
同时兼容


376
00:13:55,166 --> 00:13:56,316
多种


377
00:13:56,316 --> 00:14:00,066
机器学习工具


378
00:14:00,266 --> 00:14:02,516
它的简约之处来自于


379
00:14:02,516 --> 00:14:04,196
它统一标准的推断 API 


380
00:14:04,196 --> 00:14:05,226
涵盖了所有类型的模型


381
00:14:06,276 --> 00:14:08,066
与 Xcode 相融合让你们能够


382
00:14:08,066 --> 00:14:09,166
与机器学习模型互动


383
00:14:09,166 --> 00:14:10,626
通过


384
00:14:10,626 --> 00:14:12,046
你们早就非常熟练的


385
00:14:12,166 --> 00:14:13,556
软件开发应用


386
00:14:15,626 --> 00:14:18,616
Apple 已经把


387
00:14:18,746 --> 00:14:20,066
它使用的推断引擎销售给了


388
00:14:20,066 --> 00:14:21,526
上百万顾客


389
00:14:21,526 --> 00:14:23,136
的 App 和系统服务中


390
00:14:23,136 --> 00:14:24,766
现在你们也可以使用它了


391
00:14:24,766 --> 00:14:25,286
通过 Core ML


392
00:14:25,946 --> 00:14:27,316
如之前所说 它们


393
00:14:27,316 --> 00:14:28,466
是建立在 Metal and


394
00:14:28,466 --> 00:14:29,836
Accelerate 的上层 


395
00:14:29,836 --> 00:14:31,076
以求最大化得提升你的 App


396
00:14:31,076 --> 00:14:32,396
所依附的硬件的性能


397
00:14:35,096 --> 00:14:36,986
Core ML 也同样被设计工作于


398
00:14:36,986 --> 00:14:39,266
这快速更迭的


399
00:14:39,266 --> 00:14:40,126
机器学习生态系统中


400
00:14:40,746 --> 00:14:43,086
它定义了一个全新的公共格式


401
00:14:43,086 --> 00:14:45,196
以描述模型


402
00:14:45,196 --> 00:14:46,856
同时还有一套工具


403
00:14:46,856 --> 00:14:48,056
使你能够将


404
00:14:48,056 --> 00:14:50,316
Popular Training Libraries （普通训练库）的输出值转换


405
00:14:50,316 --> 00:14:51,506
为这一格式


406
00:14:53,156 --> 00:14:55,056
简言之 这就是 Core ML


407
00:14:55,476 --> 00:14:56,656
能够让


408
00:14:56,656 --> 00:14:58,836
你的 App 中融入学习模型的过程


409
00:14:59,056 --> 00:15:00,566
变得极其简单


410
00:15:00,756 --> 00:15:02,416
让我们再多讨论一下


411
00:15:02,416 --> 00:15:03,316
这些模型


412
00:15:03,816 --> 00:15:07,726
因为 Core ML 


413
00:15:07,726 --> 00:15:08,256
一个模型就基本上是一项功能


414
00:15:08,976 --> 00:15:10,836
那么这项功能的逻辑


415
00:15:10,966 --> 00:15:12,386
恰好是从数据中学习而来


416
00:15:12,696 --> 00:15:13,666
但就像其他任何功能一样


417
00:15:13,666 --> 00:15:15,086
它接受一系列输入值


418
00:15:15,086 --> 00:15:16,756
然后产出一系列


419
00:15:16,756 --> 00:15:17,356
输出值


420
00:15:17,956 --> 00:15:19,046
在这个情况下 如幻灯片所示


421
00:15:19,046 --> 00:15:20,756
我们有一个单一的图像输入


422
00:15:20,756 --> 00:15:22,766
和一个输出值


423
00:15:22,766 --> 00:15:24,006
可能会告诉你什么种类的花


424
00:15:24,116 --> 00:15:26,196
包含在其中


425
00:15:26,456 --> 00:15:28,966
在许多使用场景中


426
00:15:28,966 --> 00:15:30,066
你也许想应用


427
00:15:30,066 --> 00:15:31,976
在核心中有关键功能的


428
00:15:32,206 --> 00:15:33,806
机器学习模型


429
00:15:34,996 --> 00:15:36,876
一项常见的功能就是


430
00:15:36,876 --> 00:15:37,766
做出一种


431
00:15:37,766 --> 00:15:38,636
分类


432
00:15:39,576 --> 00:15:41,636
它接受一系列的输入值


433
00:15:41,636 --> 00:15:42,946
并给它们指定


434
00:15:42,946 --> 00:15:43,316
一些分类标签


435
00:15:43,846 --> 00:15:46,466
比如说


436
00:15:46,466 --> 00:15:47,066
拿情感分析举例


437
00:15:47,706 --> 00:15:49,206
你输入一句英文语句


438
00:15:49,206 --> 00:15:51,196
并输出


439
00:15:51,196 --> 00:15:52,566
这句话是积极的还是消极的


440
00:15:52,566 --> 00:15:55,506
然后这里


441
00:15:56,836 --> 00:15:57,026
由一个 emoji 代表


442
00:15:57,116 --> 00:15:58,736
那么为了编写


443
00:15:59,106 --> 00:16:01,606
这种类型的功能 Core ML


444
00:16:01,606 --> 00:16:02,836
支持种类繁多的


445
00:16:02,836 --> 00:16:03,366
模型


446
00:16:03,906 --> 00:16:08,866
它对于神经网络有广泛的支持


447
00:16:08,866 --> 00:16:10,886
包括前惯性


448
00:16:10,886 --> 00:16:11,946
和周期性神经网络两种


449
00:16:11,946 --> 00:16:13,246
以及超过三十种不同的层级


450
00:16:13,246 --> 00:16:13,706
类型


451
00:16:14,956 --> 00:16:17,076
它同样支持 Tree Ensembles （树集）


452
00:16:17,076 --> 00:16:18,546
支持向量机


453
00:16:18,546 --> 00:16:19,886
和广义线性模型


454
00:16:21,176 --> 00:16:22,516
每一个类型的模型


455
00:16:22,516 --> 00:16:23,996
事实上都是


456
00:16:23,996 --> 00:16:24,536
模型的大集合


457
00:16:24,766 --> 00:16:26,046
我们可以利用这场研讨会


458
00:16:26,046 --> 00:16:27,696
以及整场大会所剩余的时间


459
00:16:27,696 --> 00:16:28,956
来讨论


460
00:16:28,956 --> 00:16:31,696
它们其中的一个


461
00:16:31,696 --> 00:16:32,826
但是请不要被吓到了


462
00:16:33,106 --> 00:16:34,536
你不需要成为一个


463
00:16:34,536 --> 00:16:36,036
机器学习专家才能使用


464
00:16:36,036 --> 00:16:36,796
这些模型


465
00:16:37,296 --> 00:16:39,446
你只要继续专注于


466
00:16:39,446 --> 00:16:41,246
这些你尽力想实现的使用场景


467
00:16:41,246 --> 00:16:42,936
让 Core ML 去处理那些


468
00:16:42,936 --> 00:16:43,966
低级的细节即可


469
00:16:44,546 --> 00:16:45,896
Core ML 代表一个模型


470
00:16:45,896 --> 00:16:46,776
在一个文件中


471
00:16:47,316 --> 00:16:48,946
也就是说 分享一个模型就像


472
00:16:48,946 --> 00:16:50,196
分享一个文件


473
00:16:50,806 --> 00:16:52,686
这个文件有着高级信息


474
00:16:52,686 --> 00:16:53,976
是作为开发者的你


475
00:16:53,976 --> 00:16:54,886
需要编程完成的


476
00:16:54,886 --> 00:16:55,656
这就是功能


477
00:16:55,656 --> 00:16:57,276
描述 它的输入 类型 


478
00:16:57,276 --> 00:16:59,566
输出 以及那些


479
00:16:59,566 --> 00:17:00,846
Core ML 为了执行功能


480
00:17:00,846 --> 00:17:02,106
所需要的细节部分


481
00:17:02,446 --> 00:17:03,656
对于神经网络而言 这应该就是


482
00:17:03,656 --> 00:17:04,685
神经网络的结构


483
00:17:04,685 --> 00:17:06,486
加上它的


484
00:17:06,486 --> 00:17:06,915
训练参数


485
00:17:07,006 --> 00:17:08,616
我们鼓励大家去


486
00:17:08,616 --> 00:17:10,036
我们周四的研讨会来了解更多


487
00:17:10,036 --> 00:17:11,665
关于这个格式


488
00:17:11,665 --> 00:17:15,695
和一系列它可以编码的模型


489
00:17:15,695 --> 00:17:16,856
但是可能现在


490
00:17:16,856 --> 00:17:17,715
你们会想


491
00:17:17,715 --> 00:17:20,066
我到哪里才能弄到这些


492
00:17:20,066 --> 00:17:20,616
模型


493
00:17:21,116 --> 00:17:24,175
模型是哪里来的


494
00:17:24,175 --> 00:17:25,965
那么 建议大家从这里开始


495
00:17:25,965 --> 00:17:27,326
查看我们的机器学习


496
00:17:27,326 --> 00:17:28,156
登场介绍页面


497
00:17:28,156 --> 00:17:29,386
在 developer.apple.com.


498
00:17:30,816 --> 00:17:32,286
接着你们会找到一些


499
00:17:32,286 --> 00:17:34,276
执行特定任务


500
00:17:34,766 --> 00:17:36,966
立即可用的模型


501
00:17:36,966 --> 00:17:37,916
已经是 Core ML 格式的了


502
00:17:38,976 --> 00:17:40,186
我们会扩充这一套模型	


503
00:17:40,186 --> 00:17:40,746
随着时间的推移


504
00:17:40,746 --> 00:17:42,586
同时我们鼓励大家不断探索


505
00:17:42,826 --> 00:17:43,556
尝试一下


506
00:17:43,556 --> 00:17:44,586
这是一个很棒的途径


507
00:17:44,586 --> 00:17:45,656
去总体了解一下机器学习


508
00:17:45,656 --> 00:17:47,406
和 Core ML 以及


509
00:17:47,406 --> 00:17:49,126
它们可以怎样被应用到你的 App 中


510
00:17:51,076 --> 00:17:52,586
但是我们可能没有


511
00:17:52,586 --> 00:17:53,366
所有你们需要的模型


512
00:17:53,516 --> 00:17:54,886
为了让你们能够应用


513
00:17:54,886 --> 00:17:55,586
你们可能需要基于现有的模型做一些


514
00:17:55,586 --> 00:17:56,956
定制 


515
00:17:56,956 --> 00:17:58,376
或者从头开始


516
00:17:58,376 --> 00:17:59,086
制作一个全新的模型


517
00:18:00,016 --> 00:18:01,856
因此我们鼓励你 


518
00:18:01,856 --> 00:18:03,986
和你的同事们利用好


519
00:18:03,986 --> 00:18:05,256
机器学习社区


520
00:18:05,776 --> 00:18:07,526
这是一个非常活跃


521
00:18:07,526 --> 00:18:08,016
的社区


522
00:18:09,396 --> 00:18:11,026
那里有无数的库和现成的


523
00:18:11,026 --> 00:18:12,486
模型可供你们


524
00:18:12,486 --> 00:18:13,326
使用


525
00:18:14,096 --> 00:18:15,686
另外 每周都会有非常棒的


526
00:18:15,686 --> 00:18:17,426
线上教程和全新的课程


527
00:18:17,426 --> 00:18:18,806
上线


528
00:18:19,966 --> 00:18:20,586
你们可以做到的


529
00:18:20,796 --> 00:18:22,106
那里有非常棒的资源


530
00:18:22,106 --> 00:18:22,606
可供学习


531
00:18:22,606 --> 00:18:24,036
我有信心


532
00:18:24,036 --> 00:18:24,906
你们都可以成功起步的


533
00:18:24,906 --> 00:18:26,776
这是个美好的时代


534
00:18:28,316 --> 00:18:30,066
但你们会发现


535
00:18:30,066 --> 00:18:32,096
大部分的库都是专注于


536
00:18:32,096 --> 00:18:33,266
训练的 


537
00:18:33,986 --> 00:18:35,266
因为 这是非常重要的一步


538
00:18:35,266 --> 00:18:36,986
他们会花大量的


539
00:18:36,986 --> 00:18:38,146
时间确保你们可以


540
00:18:38,146 --> 00:18:39,046
训练出一个很棒的模型


541
00:18:39,046 --> 00:18:40,866
我们希望你们做的是


542
00:18:40,926 --> 00:18:42,776
让 Core ML 代替你们


543
00:18:42,776 --> 00:18:44,686
去获得那些机器学习模型


544
00:18:44,686 --> 00:18:45,916
并切实部署到


545
00:18:45,916 --> 00:18:46,986
你们的 App 上


546
00:18:47,736 --> 00:18:49,416
所以我们推出 Core ML 工具


547
00:18:49,416 --> 00:18:51,206
来做这些


548
00:18:51,206 --> 00:18:52,166
Python package 


549
00:18:52,696 --> 00:18:54,546
这是一个 Python package 


550
00:18:54,546 --> 00:18:55,686
它完全集中于


551
00:18:55,686 --> 00:18:57,826
接受这些来自于机器学习库的


552
00:18:57,826 --> 00:18:59,536
输出值


553
00:18:59,536 --> 00:19:01,126
并将它们转化为


554
00:19:01,126 --> 00:19:01,576
Core ML 格式


555
00:19:02,646 --> 00:19:04,096
随后我们会不断扩充这些工具


556
00:19:04,096 --> 00:19:06,606
但同时


557
00:19:06,606 --> 00:19:07,976
它们也是开源的


558
00:19:08,516 --> 00:19:15,046
[ 掌声 ]


559
00:19:15,546 --> 00:19:16,706
所以这意味着 就算你没有


560
00:19:16,706 --> 00:19:17,626
找到你需要的转换器


561
00:19:17,626 --> 00:19:19,466
我们非常相信


562
00:19:19,466 --> 00:19:20,606
你也已经可以自己写出一个了


563
00:19:21,136 --> 00:19:22,576
所有这些原始数据


564
00:19:22,576 --> 00:19:23,606
都可以随时为你所用


565
00:19:24,086 --> 00:19:25,316
我再次鼓励大家


566
00:19:25,316 --> 00:19:27,306
来参加我们周四的研讨会


567
00:19:27,306 --> 00:19:28,836
了解更多关于 Python package 的信息


568
00:19:28,836 --> 00:19:30,116
以及你可以怎样简单地转换


569
00:19:30,116 --> 00:19:30,516
模型


570
00:19:30,516 --> 00:19:34,946
好的 现在我们有了这个模型


571
00:19:35,396 --> 00:19:36,626
让我们来讨论一下如果


572
00:19:36,626 --> 00:19:37,156
在我们的 App 中使用它


573
00:19:37,156 --> 00:19:40,256
那么你需要从


574
00:19:40,256 --> 00:19:41,626
以 Core ML 为格式的


575
00:19:41,626 --> 00:19:42,616
机器学习模型入手


576
00:19:43,986 --> 00:19:45,666
你只需要将它加入到


577
00:19:45,666 --> 00:19:46,656
你的 Xcode 的项目里


578
00:19:47,416 --> 00:19:49,036
然后 Xcode 就会自动


579
00:19:49,176 --> 00:19:50,636
将这个模型识别为


580
00:19:50,636 --> 00:19:51,626
机器学习模型


581
00:19:51,626 --> 00:19:53,366
然后它会为你生成一个


582
00:19:53,366 --> 00:19:53,566
交互界面


583
00:19:54,116 --> 00:19:55,036
它会给你一个


584
00:19:55,036 --> 00:19:56,326
这个模型的编程界面


585
00:19:56,326 --> 00:19:58,746
使用的数据类型和


586
00:19:58,746 --> 00:19:59,646
结构都是


587
00:19:59,646 --> 00:20:00,906
你们编程时很熟悉的


588
00:20:01,386 --> 00:20:03,536
你们将会使用


589
00:20:03,686 --> 00:20:05,346
这一交互界面并将它编译进


590
00:20:05,346 --> 00:20:06,446
你们的 App


591
00:20:07,376 --> 00:20:09,086
但除此之外 模型本身


592
00:20:09,086 --> 00:20:10,866
也会被编译


593
00:20:10,936 --> 00:20:12,496
并归入到你们的 App 中


594
00:20:12,856 --> 00:20:14,636
也就是说 我们使用的这一格式


595
00:20:14,636 --> 00:20:15,636
是已被优化过的


596
00:20:15,636 --> 00:20:17,856
变得更加开放及兼容


597
00:20:17,856 --> 00:20:19,176
并且使它成为


598
00:20:19,176 --> 00:20:20,886
为了在设备上运行


599
00:20:20,886 --> 00:20:21,456
而优化的格式


600
00:20:22,996 --> 00:20:24,556
为了给你们展示这一操作


601
00:20:24,656 --> 00:20:25,866
我要邀请我的朋友


602
00:20:25,866 --> 00:20:27,156
兼同事 Lizi 到台上来


603
00:20:28,516 --> 00:20:34,406
[ 掌声 ]


604
00:20:34,906 --> 00:20:36,436
我是 Core ML 团队


605
00:20:36,436 --> 00:20:36,946
的工程师


606
00:20:37,926 --> 00:20:40,316
今天 让我们来看一下


607
00:20:40,316 --> 00:20:42,216
你们该如何使用 Core ML 将


608
00:20:42,216 --> 00:20:43,576
机器学习融入你们的


609
00:20:43,576 --> 00:20:44,106
App


610
00:20:45,156 --> 00:20:46,976
首先设定一个背景


611
00:20:47,796 --> 00:20:49,016
就像我喜爱机器


612
00:20:49,016 --> 00:20:51,076
学习一样 我同样喜欢园艺


613
00:20:51,076 --> 00:20:53,096
如果你是像我一样的人


614
00:20:53,546 --> 00:20:54,796
每当你见到


615
00:20:54,796 --> 00:20:56,436
新品种的花时


616
00:20:56,436 --> 00:20:58,336
相信你会非常激动并会马上


617
00:20:58,336 --> 00:20:59,276
就想认出它的种类


618
00:21:00,366 --> 00:21:01,706
所以我们希望打造一款 App


619
00:21:02,296 --> 00:21:03,866
可以获取


620
00:21:03,866 --> 00:21:05,476
不同种类的花的图像


621
00:21:05,516 --> 00:21:07,426
并把它们按类型分类


622
00:21:08,346 --> 00:21:09,886
但首先 要做到这一点


623
00:21:10,466 --> 00:21:11,296
我们需要一个模型


624
00:21:12,866 --> 00:21:14,166
所以我们进一步


625
00:21:14,166 --> 00:21:15,766
收集了许多


626
00:21:15,896 --> 00:21:17,116
不同类型的花的图片


627
00:21:17,486 --> 00:21:18,686
并给每一个都做了标记


628
00:21:20,286 --> 00:21:21,656
之后我训练了一个神经网络分类器


629
00:21:21,756 --> 00:21:23,686
通过使用一个开源的


630
00:21:23,756 --> 00:21:25,296
机器学习工具


631
00:21:25,296 --> 00:21:27,326
将其转换成了我们的 Core ML


632
00:21:27,416 --> 00:21:27,666
格式


633
00:21:29,256 --> 00:21:31,896
有了这个训练出的模型


634
00:21:31,896 --> 00:21:33,086
和这个花朵分类器的 App Shell （程序外壳）


635
00:21:33,086 --> 00:21:35,006
我们来看一下


636
00:21:35,006 --> 00:21:36,906
如果将这两者


637
00:21:36,906 --> 00:21:37,276
合二为一


638
00:21:38,946 --> 00:21:40,746
在 Xcode 里 你可以看到


639
00:21:40,746 --> 00:21:42,736
我正在运行花朵分类器


640
00:21:42,736 --> 00:21:44,616
这个 App 


641
00:21:44,616 --> 00:21:45,626
就在我设备屏幕的边上


642
00:21:46,686 --> 00:21:48,606
我可以做的就是


643
00:21:48,606 --> 00:21:50,346
进入到照片图库中


644
00:21:50,346 --> 00:21:52,626
选择一张图片 但现在


645
00:21:52,736 --> 00:21:53,906
它还不能为输出结果


646
00:21:53,906 --> 00:21:54,906
做任何预测


647
00:21:55,396 --> 00:21:57,246
它只显示出这一行而已


648
00:21:58,796 --> 00:22:00,086
那么如果我去看


649
00:22:00,086 --> 00:22:02,606
视频控制器 我们能看到的是


650
00:22:02,606 --> 00:22:04,836
它有这样一个 Caption Method （说明方式）


651
00:22:05,046 --> 00:22:06,226
目前只会返回


652
00:22:06,256 --> 00:22:06,856
空白行


653
00:22:07,426 --> 00:22:10,746
它实际上并没有做什么


654
00:22:10,836 --> 00:22:12,636
在这里面 我有


655
00:22:12,636 --> 00:22:14,176
花朵分类器 


656
00:22:14,236 --> 00:22:14,506
是以 ML 模型为格式的


657
00:22:15,186 --> 00:22:16,656
我需要做的就是选中它


658
00:22:17,306 --> 00:22:18,696
并将它拖拽到


659
00:22:18,696 --> 00:22:19,066
项目中


660
00:22:19,786 --> 00:22:22,936
我们可以看到 我一把它加入进去


661
00:22:23,066 --> 00:22:24,796
Xcode 就自动


662
00:22:24,796 --> 00:22:26,546
识别了这个文件格式


663
00:22:27,406 --> 00:22:28,716
显示出了模型的名字


664
00:22:28,716 --> 00:22:30,816
以及它的类型


665
00:22:30,816 --> 00:22:31,346
在这下面


666
00:22:31,926 --> 00:22:33,666
我们可以看到文件大小是


667
00:22:33,666 --> 00:22:35,226
41 兆字节 以及其它


668
00:22:35,226 --> 00:22:36,616
信息例如作者


669
00:22:36,866 --> 00:22:38,296
许可或者描述


670
00:22:38,296 --> 00:22:39,226
都一起显示出来


671
00:22:40,446 --> 00:22:41,876
在底部 我们可以看到


672
00:22:41,916 --> 00:22:43,266
这个模型所承接的


673
00:22:43,266 --> 00:22:45,736
输入和输出 首先就是


674
00:22:46,126 --> 00:22:48,136
花朵图像 它的类型是图像 


675
00:22:48,476 --> 00:22:49,966
被划分为红色 绿色 蓝色


676
00:22:50,086 --> 00:22:51,096
以及宽度和高度


677
00:22:52,406 --> 00:22:53,816
我们同样可以看到


678
00:22:53,816 --> 00:22:55,506
它将花朵类型输出为一行


679
00:22:56,166 --> 00:22:57,756
所以如果给它


680
00:22:57,756 --> 00:22:59,576
一张玫瑰的图片 我会想要花朵类型


681
00:22:59,646 --> 00:23:00,526
显示玫瑰


682
00:23:01,896 --> 00:23:03,466
这里同样存在一个词典


683
00:23:03,466 --> 00:23:05,016
包含许多不同类型花朵


684
00:23:05,016 --> 00:23:05,736
的可能性


685
00:23:06,306 --> 00:23:08,796
我要做的第一件事


686
00:23:10,206 --> 00:23:11,236
就是我要确保


687
00:23:11,436 --> 00:23:12,966
我把它加入到了我的 App


688
00:23:13,586 --> 00:23:15,876
之后你们会看到


689
00:23:16,396 --> 00:23:18,406
这中间的窗口会显示


690
00:23:18,406 --> 00:23:20,086
Swift Generated Source （生成源） 


691
00:23:20,366 --> 00:23:21,896
已经加入到了 App 中


692
00:23:22,896 --> 00:23:23,966
这意味着我们可以


693
00:23:23,966 --> 00:23:25,866
真正地使用这生成的代码


694
00:23:26,176 --> 00:23:27,536
来加载这一模型


695
00:23:27,536 --> 00:23:28,046
并靠它来做出预测


696
00:23:28,846 --> 00:23:30,576
为了给你们展示 我们看一下


697
00:23:30,576 --> 00:23:31,206
视频控制器


698
00:23:31,816 --> 00:23:36,156
我要做的第一件事是


699
00:23:36,156 --> 00:23:37,526
定义这些花朵模型
 
00:23:38,766 --> 00:23:40,216
为了将它实例化 我需要


700
00:23:40,216 --> 00:23:42,086
做的就是使用


701
00:23:42,206 --> 00:23:45,656
模型类本身的名字


702
00:23:45,806 --> 00:23:47,346
我们会看到它被高亮的颜色标出


703
00:23:47,506 --> 00:23:48,456
因为它已经存在于


704
00:23:48,456 --> 00:23:48,866
这个项目中


705
00:23:49,906 --> 00:23:51,516
在下一个 Caption Method （说明方式） 中


706
00:23:51,766 --> 00:23:52,866
我们来定义一个预测


707
00:23:53,446 --> 00:23:56,886
我们会使用


708
00:23:56,936 --> 00:24:00,206
这个花朵模型并查看它


709
00:24:01,076 --> 00:24:02,546
我们会看到使用自动完成
 
00:24:02,696 --> 00:24:03,896
这个预测方式是


710
00:24:03,896 --> 00:24:05,156
可用的 并且它将


711
00:24:05,156 --> 00:24:07,056
CVPixelBuffer 作为输入值


712
00:24:07,906 --> 00:24:09,666
我们要使用它并将


713
00:24:09,666 --> 00:24:12,786
图像直接传输给它


714
00:24:13,286 --> 00:24:14,726
现在 我们可以取代


715
00:24:14,866 --> 00:24:16,776
这一预先设定的行 我们可以使用


716
00:24:16,776 --> 00:24:18,716
预测物 同时取代之前的


717
00:24:19,236 --> 00:24:20,966
并返回出花朵类型


718
00:24:21,676 --> 00:24:24,166
现在如果我保存 我们就可以创建


719
00:24:24,166 --> 00:24:25,266
并运行这个 App


720
00:24:26,026 --> 00:24:27,586
我在做这件事的时候


721
00:24:27,586 --> 00:24:29,916
这个模型本身


722
00:24:29,916 --> 00:24:31,306
正在被编译


723
00:24:31,306 --> 00:24:32,566
并归入到 App 中


724
00:24:33,706 --> 00:24:34,936
那么我们回到设备上看


725
00:24:35,476 --> 00:24:37,196
打开我的照片图库


726
00:24:37,506 --> 00:24:39,136
选择一朵


727
00:24:39,136 --> 00:24:39,366
在第二排的玫瑰图片


728
00:24:40,216 --> 00:24:41,536
我们可以看到


729
00:24:41,536 --> 00:24:42,696
它能够显示出 玫瑰


730
00:24:43,516 --> 00:24:49,356
[ 掌声 ]


731
00:24:49,856 --> 00:24:51,106
我们再选一张 


732
00:24:51,106 --> 00:24:52,356
比如第三排的向日葵


733
00:24:53,406 --> 00:24:54,746
它同样能够显示出来


734
00:24:55,736 --> 00:24:56,846
或者识别起来


735
00:24:56,846 --> 00:24:58,216
更加困难的 比如下面的


736
00:24:58,216 --> 00:24:59,646
西番莲


737
00:24:59,646 --> 00:25:00,196
它还是可以识别出来


738
00:25:01,296 --> 00:25:04,346
那么简要重述一下 我们可以


739
00:25:04,576 --> 00:25:06,876
将一个训练好的机器学习模型


740
00:25:07,146 --> 00:25:09,236
拖拽到 Xcode 中  并将它十分简单地添加到


741
00:25:09,236 --> 00:25:10,906
App 中 只需要三行


742
00:25:10,946 --> 00:25:11,346
代码


743
00:25:12,006 --> 00:25:13,696
现在我们有一个完整的神经


744
00:25:13,696 --> 00:25:15,186
网络分类器


745
00:25:15,186 --> 00:25:15,616
在设备上运行


746
00:25:16,576 --> 00:25:19,096
但我还有一些其他的模型


747
00:25:19,096 --> 00:25:20,576
可能也想要尝试一下


748
00:25:21,006 --> 00:25:21,896
那么让我们再做一次


749
00:25:22,376 --> 00:25:25,016
你们可能注意到了


750
00:25:25,016 --> 00:25:26,506
这也有一个叫 FlowerSqueeze 的模型


751
00:25:27,356 --> 00:25:28,996
那么首先我要做的


752
00:25:28,996 --> 00:25:31,346
就是再一次地拖拽它


753
00:25:32,066 --> 00:25:35,476
然后我也要将它加入到


754
00:25:35,596 --> 00:25:37,246
花朵分类器中  


755
00:25:37,386 --> 00:25:39,416
这个叫 Hello Flowers （你好花朵）的目标项目中


756
00:25:39,566 --> 00:25:40,686
然后在后台


757
00:25:40,816 --> 00:25:41,786
开始生成 Swift 源


758
00:25:42,566 --> 00:25:43,956
我们会看到 如果我们再放大一些


759
00:25:44,036 --> 00:25:46,016
这个模型的名字


760
00:25:46,056 --> 00:25:46,456
是不同的


761
00:25:46,606 --> 00:25:48,606
它叫做 FlowerSqueeze 但是在


762
00:25:48,606 --> 00:25:50,186
底部 输入和


763
00:25:50,186 --> 00:25:51,706
输出是完全一样的


764
00:25:53,086 --> 00:25:54,626
这意味着如果


765
00:25:54,626 --> 00:25:55,886
我回到视频控制器中


766
00:25:57,786 --> 00:25:59,016
取代了花朵 干脆


767
00:25:59,476 --> 00:26:00,906
我们直接删除花朵分类器


768
00:26:01,076 --> 00:26:02,006
我们不再需要


769
00:26:02,006 --> 00:26:02,336
那个模型了


770
00:26:02,926 --> 00:26:05,656
在视频控制器中


771
00:26:06,216 --> 00:26:07,436
不再将这个实例化


772
00:26:07,436 --> 00:26:10,146
我们来使用 FlowerSqueeze


773
00:26:10,786 --> 00:26:13,336
这个模型非常干净整洁的地方在于


774
00:26:13,386 --> 00:26:15,276
它的大小


775
00:26:16,136 --> 00:26:19,106
我们返回 它的大小


776
00:26:19,106 --> 00:26:21,146
只有 5.4 兆字节 


777
00:26:21,146 --> 00:26:21,806
这是一个非常大的不同之处


778
00:26:22,266 --> 00:26:27,086
回到设备上 我们进入到


779
00:26:27,086 --> 00:26:28,756
照片图库中并选择


780
00:26:28,756 --> 00:26:29,906
另一个 比如这朵雾中之爱


781
00:26:29,906 --> 00:26:32,256
可以看到这个 App


782
00:26:32,256 --> 00:26:34,966
同样可以


783
00:26:35,556 --> 00:26:35,676
将它分类


784
00:26:35,886 --> 00:26:38,856
试一下另一朵西番莲或者


785
00:26:38,856 --> 00:26:40,376
一张更难识别的


786
00:26:40,376 --> 00:26:42,696
边上这朵玫瑰的照片


787
00:26:42,696 --> 00:26:43,966
它仍然能够正确地预测出来


788
00:26:44,586 --> 00:26:48,716
再扼要重述一下 我们刚看到


789
00:26:48,856 --> 00:26:50,126
我们可以在设备上运行这个


790
00:26:50,126 --> 00:26:51,676
神经网络分类器


791
00:26:51,896 --> 00:26:54,086
通过使用 Core ML 这一切


792
00:26:54,176 --> 00:26:55,886
都只用了仅仅几行代码而已


793
00:26:56,516 --> 00:27:04,086
[ 掌声 ]


794
00:27:04,586 --> 00:27:06,396
现在我们来回顾一下


795
00:27:06,396 --> 00:27:08,616
我们刚才都看到了什么


796
00:27:08,856 --> 00:27:11,556
我们看到在 Xcode 中  一旦


797
00:27:11,746 --> 00:27:13,586
你将一个训练过的机器学习模型拖拽进


798
00:27:13,586 --> 00:27:15,106
你的 App 中


799
00:27:15,376 --> 00:27:16,446
你会得到这个


800
00:27:16,446 --> 00:27:17,956
生成的界面 在下方提供给你


801
00:27:17,956 --> 00:27:19,616
例如模型名称


802
00:27:19,616 --> 00:27:21,836
和类型的信息


803
00:27:21,836 --> 00:27:23,316
以及其他信息


804
00:27:23,316 --> 00:27:25,806
例如模型大小


805
00:27:25,806 --> 00:27:27,526
或者任何其他


806
00:27:27,526 --> 00:27:27,676
作者加入进去的信息


807
00:27:28,276 --> 00:27:29,996
在底部


808
00:27:30,086 --> 00:27:31,816
你们可以看到 例如这一模型的


809
00:27:31,816 --> 00:27:33,096
输入和输出的信息


810
00:27:33,096 --> 00:27:34,946
这是非常有帮助的


811
00:27:34,946 --> 00:27:35,946
当你想要


812
00:27:35,946 --> 00:27:36,106
使用它的时候


813
00:27:36,106 --> 00:27:38,276
一旦你将它加入到你的


814
00:27:38,276 --> 00:27:40,166
App 中  你就会得到生成的代码


815
00:27:40,166 --> 00:27:42,106
你可以用来加载并使用


816
00:27:42,106 --> 00:27:45,366
这一模型来做出预测


817
00:27:45,436 --> 00:27:47,076
我们也在 App 中看到


818
00:27:47,076 --> 00:27:48,706
使用它


819
00:27:48,706 --> 00:27:49,106
是多么的简单


820
00:27:49,956 --> 00:27:51,826
再说一次 即便模型是


821
00:27:51,826 --> 00:27:53,746
一个神经网络分类器 


822
00:27:53,746 --> 00:27:55,266
我们将它实例化所需要做的


823
00:27:55,266 --> 00:27:56,626
就是访问


824
00:27:56,626 --> 00:27:57,066
文件的名称


825
00:27:57,736 --> 00:27:58,856
这意味着模型类型


826
00:27:58,856 --> 00:28:00,686
是完全抽象的


827
00:28:00,686 --> 00:28:01,856
不论它是一个向量机


828
00:28:01,856 --> 00:28:03,536
一个一般线性模型


829
00:28:03,536 --> 00:28:05,686
或者一个神经网络


830
00:28:05,916 --> 00:28:07,906
你都可以以同样的方式加载它


831
00:28:07,906 --> 00:28:09,206
我们还注意到 


832
00:28:09,206 --> 00:28:11,036
预测方式使用到了一个


833
00:28:11,136 --> 00:28:12,106
CVPixelBuffer


834
00:28:12,776 --> 00:28:14,346
它是一个强类型 所以你很清楚


835
00:28:14,346 --> 00:28:15,406
你要在


836
00:28:15,536 --> 00:28:17,496
编辑的时候就检查输入错误


837
00:28:17,646 --> 00:28:18,616
而不是在运行的时候


838
00:28:20,026 --> 00:28:22,766
现在让我们来更深入的看一下


839
00:28:23,126 --> 00:28:24,486
由 Xcode 创建的


840
00:28:24,536 --> 00:28:27,416
Generated Source （生成源）


841
00:28:27,476 --> 00:28:29,706
在这里 我们看到它定义了三个


842
00:28:29,706 --> 00:28:31,696
层级 第一级是输入


843
00:28:31,696 --> 00:28:33,966
将花朵图片


844
00:28:33,966 --> 00:28:35,456
定义为一个 CVPixelBuffer


845
00:28:36,456 --> 00:28:38,306
之后我们看到输出值


846
00:28:38,306 --> 00:28:40,836
和两种相同的类型被列在


847
00:28:40,836 --> 00:28:41,976
生成的交互界面中


848
00:28:43,176 --> 00:28:44,936
接下来 在模型层级中


849
00:28:44,936 --> 00:28:46,586
我们能看到


850
00:28:46,586 --> 00:28:48,116
我们用来创造模型的


851
00:28:48,116 --> 00:28:50,346
便利构造器


852
00:28:50,346 --> 00:28:53,336
以及预测方式


853
00:28:53,536 --> 00:28:55,486
同时在 Generated Source （生成源）内


854
00:28:55,486 --> 00:28:57,326
你可以接入


855
00:28:57,386 --> 00:28:58,376
底层模型


856
00:28:58,986 --> 00:29:00,676
那么在更高级的使用场景中


857
00:29:01,006 --> 00:29:02,656
你可以使用它


858
00:29:02,656 --> 00:29:04,096
也可以以编程的形式


859
00:29:04,096 --> 00:29:04,226
与它互动


860
00:29:05,556 --> 00:29:06,816
我们来看一下


861
00:29:06,886 --> 00:29:08,966
机器学习模型层级的内部 我们可以看到


862
00:29:08,966 --> 00:29:10,186
有一个模型描述


863
00:29:10,896 --> 00:29:12,626
使你可以访问


864
00:29:12,626 --> 00:29:14,946
任何你在 Xcode


865
00:29:15,136 --> 00:29:16,066
元数据中看到的东西


866
00:29:16,636 --> 00:29:18,196
还有一个额外的


867
00:29:18,196 --> 00:29:19,726
预测方式 它接受


868
00:29:19,816 --> 00:29:21,726
符合协议的输入


869
00:29:21,726 --> 00:29:23,206
并返回符合协议的输出


870
00:29:23,206 --> 00:29:24,606
这给你


871
00:29:24,676 --> 00:29:26,456
提供输入的方式


872
00:29:26,456 --> 00:29:26,956
以更多的弹性空间


873
00:29:27,836 --> 00:29:29,366
我们看过了


874
00:29:29,366 --> 00:29:31,016
这一开发流程的上半部分


875
00:29:31,446 --> 00:29:32,946
并看到了


876
00:29:32,946 --> 00:29:34,826
当你将一个训练过的模型拖拽进 Xcode 会发生什么


877
00:29:35,486 --> 00:29:36,766
它可以生成 Swift 源


878
00:29:36,856 --> 00:29:38,806
你可以在你的 App 里使用


879
00:29:39,486 --> 00:29:41,436
在你的 App 里


880
00:29:41,526 --> 00:29:42,006
使用这一模型


881
00:29:44,096 --> 00:29:46,156
如我们所见 这一模型本身


882
00:29:46,156 --> 00:29:47,926
同样也被编译并归入


883
00:29:47,926 --> 00:29:49,066
到你的 App 中


884
00:29:51,816 --> 00:29:53,506
在这一步做一个更详细的说明


885
00:29:53,506 --> 00:29:55,986
我们要做什么 首先


886
00:29:55,986 --> 00:29:58,646
我们从模型的 JSON 形式中得到它


887
00:29:58,836 --> 00:29:59,756
这是优化过的


888
00:29:59,846 --> 00:30:01,056
为了更加便携和易于转化


889
00:30:01,056 --> 00:30:02,886
并编译它


890
00:30:03,166 --> 00:30:04,606
使它能在设备上快速加载


891
00:30:04,606 --> 00:30:06,826
当你启动它的时候


892
00:30:08,036 --> 00:30:09,886
我们还需要确认模型


893
00:30:09,886 --> 00:30:11,376
与底层推断引擎


894
00:30:11,376 --> 00:30:12,716
相连接


895
00:30:12,716 --> 00:30:14,276
最终在你的设备上做出评估


896
00:30:14,276 --> 00:30:15,916
并给你一个优化的预测结果


897
00:30:16,026 --> 00:30:17,426
当你需要的时候


898
00:30:17,426 --> 00:30:20,576
我们在演示中看到的最后一样东西


899
00:30:20,576 --> 00:30:22,806
就是我们换掉了模型


900
00:30:23,646 --> 00:30:25,586
大多数时候都是为了缩减体积


901
00:30:26,426 --> 00:30:28,196
但是还有其他的原因


902
00:30:28,196 --> 00:30:29,226
为什么你可能会需要


903
00:30:29,226 --> 00:30:29,936
使用别的模型


904
00:30:30,346 --> 00:30:32,406
比如说 为了精确性或者仅仅是


905
00:30:32,406 --> 00:30:34,266
为了测试出不同的类型


906
00:30:34,266 --> 00:30:35,096
看它们表现如何


907
00:30:35,696 --> 00:30:40,636
总的来说 今天我们了解了


908
00:30:40,636 --> 00:30:41,966
我们可用的一些


909
00:30:41,966 --> 00:30:43,206
机器学习模型框架


910
00:30:43,206 --> 00:30:43,746
的概览


911
00:30:44,686 --> 00:30:46,736
我们还推出了 Core ML


912
00:30:46,736 --> 00:30:48,166
一个全新的框架


913
00:30:48,276 --> 00:30:48,746
用于设备端的推断


914
00:30:49,956 --> 00:30:51,176
我们也实际向你们展示了


915
00:30:51,176 --> 00:30:52,456
开发流程


916
00:30:54,536 --> 00:30:55,946
需要更多信息的话


917
00:30:55,946 --> 00:30:56,786
请到


918
00:30:56,786 --> 00:30:58,376
developer.apple.com 查看


919
00:30:58,376 --> 00:30:59,816
我们的研讨会序号是 703


920
00:31:00,696 --> 00:31:02,096
同时 周四可以参加一些


921
00:31:02,096 --> 00:31:03,976
的相关研讨会进行深入了解 例如 Vision


922
00:31:03,976 --> 00:31:06,536
和 NLP 以及 Core ML 


923
00:31:06,596 --> 00:31:08,076
如果你们想了解


924
00:31:08,076 --> 00:31:09,606
更多 Core ML 的使用场景


925
00:31:09,606 --> 00:31:11,366
或者如何


926
00:31:11,366 --> 00:31:12,946
将模型转换为 Core ML


927
00:31:13,006 --> 00:31:13,266
格式


928
00:31:14,276 --> 00:31:15,666
感谢各位 


929
00:31:15,666 --> 00:31:16,206
并请期待大会接下来的日程

