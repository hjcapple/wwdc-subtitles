1
00:00:01,516 --> 00:00:04,500
[音乐]


2
00:00:07,796 --> 00:00:09,296
>> 大家好 欢迎来到


3
00:00:09,296 --> 00:00:11,706
Audio API Updates 会场


4
00:00:12,116 --> 00:00:14,116
我是 Peter Vasil


5
00:00:14,116 --> 00:00:16,276
是 Core Audio 团队的一名软件工程师


6
00:00:18,426 --> 00:00:21,186
我们先来介绍 AVAudioEngine 中的新内容


7
00:00:24,206 --> 00:00:25,226
我们在 AVAudioEngine 中


8
00:00:25,226 --> 00:00:26,976
进行了一些改进


9
00:00:26,976 --> 00:00:27,996
添加了新 API


10
00:00:28,946 --> 00:00:30,946
现在支持语音处理


11
00:00:31,946 --> 00:00:33,486
我们添加了两个新的节点


12
00:00:33,726 --> 00:00:35,346
即 AVAudioSourceNode 和


13
00:00:35,346 --> 00:00:37,646
AVAudioSinkNode 并且


14
00:00:37,646 --> 00:00:40,256
我们还改进了空间音频渲染


15
00:00:41,616 --> 00:00:46,516
现在 我们来谈谈其中的细节


16
00:00:46,516 --> 00:00:49,156
AVAudioEngine 现在拥有语音处理模式


17
00:00:49,726 --> 00:00:51,916
该模式的主要用例


18
00:00:51,916 --> 00:00:54,926
为回音消除和 VoIP App


19
00:00:55,956 --> 00:00:56,836
这意味着什么


20
00:00:57,836 --> 00:00:59,346
启用时将对输入音频


21
00:00:59,346 --> 00:01:00,826
进行额外信号处理


22
00:01:00,826 --> 00:01:03,286
任何设备本身


23
00:01:03,286 --> 00:01:06,046
产生的音频将被剔除


24
00:01:06,816 --> 00:01:10,506
这需要输入和输出节点均处于


25
00:01:10,506 --> 00:01:11,686
语音处理模式


26
00:01:13,126 --> 00:01:15,236
因此 在输入或


27
00:01:15,236 --> 00:01:16,966
输出节点上启用该模式后


28
00:01:17,536 --> 00:01:19,556
引擎便可确保


29
00:01:19,556 --> 00:01:21,406
输入输出节点均已存在


30
00:01:21,406 --> 00:01:23,336
并已切换至语音处理模式


31
00:01:24,966 --> 00:01:26,296
语音处理仅发生在


32
00:01:26,296 --> 00:01:27,886
渲染至音频设备时


33
00:01:27,886 --> 00:01:30,746
而不是在手动渲染


34
00:01:34,326 --> 00:01:35,966
要启用或禁用


35
00:01:35,966 --> 00:01:38,456
语音处理 我们可以在输入


36
00:01:38,496 --> 00:01:40,616
或输出节点启用


37
00:01:40,616 --> 00:01:42,066
setVoiceProcessingEnabled


38
00:01:43,406 --> 00:01:44,826
语音处理无法


39
00:01:44,826 --> 00:01:47,046
动态启用 也就是说


40
00:01:47,106 --> 00:01:48,586
启用该模式时


41
00:01:48,586 --> 00:01:50,466
引擎须处于停止状态


42
00:01:50,466 --> 00:01:54,296
AVEchoTouch 示例代码项目


43
00:01:54,296 --> 00:01:56,726
详细展示了


44
00:01:56,726 --> 00:01:57,826
如何运用 AVAudioEngine


45
00:01:57,826 --> 00:01:59,396
使用语音处理


46
00:01:59,846 --> 00:02:03,616
我们再来看看 AVAudioEngine


47
00:02:03,616 --> 00:02:06,376
中的新节点 AVAudioSourceNode


48
00:02:06,376 --> 00:02:07,766
和 AVAudioSinkNode


49
00:02:08,955 --> 00:02:10,826
两种节点都封装了用户定义的块


50
00:02:10,826 --> 00:02:13,006
App 可以借此


51
00:02:13,006 --> 00:02:15,006
从 AVAudioEngine 收发音频


52
00:02:16,176 --> 00:02:17,646
渲染至音频设备时


53
00:02:17,646 --> 00:02:20,056
块操作受到实时限制


54
00:02:20,056 --> 00:02:22,796
实时限制 在块内部


55
00:02:22,796 --> 00:02:24,156
不应存在任何阻塞调用


56
00:02:24,156 --> 00:02:26,106
包括内存分配


57
00:02:26,566 --> 00:02:28,066
调用 libdispatch 或


58
00:02:28,066 --> 00:02:28,946
使用互斥锁阻塞


59
00:02:32,936 --> 00:02:35,176
我们使用 AVAudioSourceNode


60
00:02:35,176 --> 00:02:36,566
将块传递或渲染至节点


61
00:02:36,566 --> 00:02:38,736
节点将音频数据传递至输出


62
00:02:40,066 --> 00:02:41,626
这就可以很方便地


63
00:02:41,626 --> 00:02:43,446
创建生成节点 而无需


64
00:02:43,446 --> 00:02:45,406
实现完整的音频单元


65
00:02:45,406 --> 00:02:47,486
并将其与 AVAudio 单元封装


66
00:02:49,046 --> 00:02:51,306
节点可用于


67
00:02:51,306 --> 00:02:53,246
实时渲染和手动渲染两种模式


68
00:02:54,476 --> 00:02:56,726
AVAudioSourceNode 支持


69
00:02:56,726 --> 00:02:59,316
线性 PCM 转换 例如采样率


70
00:02:59,316 --> 00:03:01,056
或位深转换


71
00:03:01,616 --> 00:03:04,996
仅有一个输出且没有输入


72
00:03:09,436 --> 00:03:11,476
这段代码片段展示了


73
00:03:11,476 --> 00:03:13,366
如何使用 AVAudioSourceNode


74
00:03:14,056 --> 00:03:16,096
可见 这个块


75
00:03:16,096 --> 00:03:18,126
作为初始化参数值被传递


76
00:03:18,126 --> 00:03:19,986
节点创建后


77
00:03:19,986 --> 00:03:22,906
便可以像其他节点一样建立连接


78
00:03:23,936 --> 00:03:25,676
更细致的示例


79
00:03:25,676 --> 00:03:27,306
可以在我们的 Signal Generator


80
00:03:27,306 --> 00:03:28,536
示例代码项目中找到


81
00:03:32,356 --> 00:03:34,166
我们来看看 AVAudioSinkNode


82
00:03:34,866 --> 00:03:37,156
AVAudioSinkNode


83
00:03:37,156 --> 00:03:39,256
与 AVAudioSourceNode 对应


84
00:03:40,086 --> 00:03:41,916
它封装了用户定义的块


85
00:03:41,966 --> 00:03:43,636
从节点链接收


86
00:03:43,636 --> 00:03:45,086
输入音频


87
00:03:45,086 --> 00:03:46,446
并连接至输出


88
00:03:47,516 --> 00:03:50,776
AVAudioSinkNode 仅可用于输入链


89
00:03:51,176 --> 00:03:52,746
换言之 它必须


90
00:03:52,746 --> 00:03:54,796
连接至输入节点的下游


91
00:03:56,076 --> 00:03:59,306
它不支持格式转换


92
00:03:59,306 --> 00:04:00,916
块内的格式必须与


93
00:04:00,916 --> 00:04:02,836
硬件输入格式一致


94
00:04:04,236 --> 00:04:06,436
这个节点可以用于


95
00:04:06,436 --> 00:04:09,086
VoIP App


96
00:04:09,086 --> 00:04:10,756
因为此时输入需要实时处理


97
00:04:10,756 --> 00:04:12,596
这种情形下


98
00:04:12,596 --> 00:04:14,256
安装常规的 Tap


99
00:04:14,256 --> 00:04:18,815
并不够 因为 Tap 无法实时运行


100
00:04:21,076 --> 00:04:22,746
这段代码片段


101
00:04:22,746 --> 00:04:24,636
展示了如何创建


102
00:04:24,636 --> 00:04:25,826
AVAudioSinkNode


103
00:04:26,466 --> 00:04:29,206
与创建 AVAudioSourceNode 非常类似


104
00:04:29,976 --> 00:04:32,096
需要注意的主要步骤是


105
00:04:32,096 --> 00:04:33,606
用一个块初始化节点


106
00:04:33,606 --> 00:04:35,836
将其附加在 Engine 上


107
00:04:36,146 --> 00:04:37,676
再将其连接至输入节点


108
00:04:37,676 --> 00:04:39,266
下游的节点上


109
00:04:42,996 --> 00:04:45,576
我们来看看空间渲染的改进


110
00:04:46,666 --> 00:04:48,426
我们引入了自动


111
00:04:48,426 --> 00:04:51,256
空间渲染算法


112
00:04:51,256 --> 00:04:53,486
而且 AVAudioPlayerNode 现在支持


113
00:04:53,486 --> 00:04:56,546
多声道音频内容空间化


114
00:05:00,716 --> 00:05:02,076
自动空间


115
00:05:02,076 --> 00:05:03,806
渲染算法是


116
00:05:03,806 --> 00:05:07,786
当前路由下最适合的空间化算法


117
00:05:08,626 --> 00:05:10,576
这意味着 开发者不需要


118
00:05:10,576 --> 00:05:12,396
专门针对耳机


119
00:05:12,396 --> 00:05:14,066
或不同的扬声器设置


120
00:05:14,066 --> 00:05:15,816
找出最适合的算法


121
00:05:16,896 --> 00:05:18,846
算法为耳机加入了


122
00:05:18,846 --> 00:05:20,856
近场渲染和头内渲染


123
00:05:20,856 --> 00:05:22,426
为内置扬声器加入了虚拟环绕


124
00:05:22,426 --> 00:05:24,546
可以在 2018 年及之后的


125
00:05:24,546 --> 00:05:26,466
iOS 设备和 MacBook 上


126
00:05:26,466 --> 00:05:28,646
提供使用


127
00:05:32,096 --> 00:05:34,026
这是 AVAudio3DMixing


128
00:05:34,026 --> 00:05:36,126
协议中的新 API


129
00:05:36,746 --> 00:05:39,656
AVAudio3DMixingRenderingAlgorithm enum


130
00:05:39,656 --> 00:05:43,006
有了新的条目 auto


131
00:05:44,056 --> 00:05:45,926
此外 我们可以用 outputType 属性


132
00:05:45,926 --> 00:05:48,576
指定输出类型


133
00:05:49,076 --> 00:05:52,346
将属性设定为 auto 时


134
00:05:52,636 --> 00:05:54,146
输出类型可以在


135
00:05:54,146 --> 00:05:56,346
实时模式下被自动检测


136
00:05:56,346 --> 00:05:59,076
但在手动渲染模式中则不然


137
00:06:03,056 --> 00:06:05,116
能够空间化


138
00:06:05,116 --> 00:06:07,546
多声道流


139
00:06:07,546 --> 00:06:09,916
我们便可支持点声源渲染和环境声效渲染


140
00:06:10,816 --> 00:06:12,476
我们也支持基于声道的格式


141
00:06:12,476 --> 00:06:14,066
以及更高阶的


142
00:06:14,066 --> 00:06:15,996
Ambisonics 最高可达三阶


143
00:06:19,616 --> 00:06:20,786
我们为 AVAudio3DMixing 协议


144
00:06:20,786 --> 00:06:22,706
添加了两个新的空间化属性


145
00:06:22,706 --> 00:06:25,946
sourceMode


146
00:06:25,946 --> 00:06:27,996
以及 pointSourceInHeadMode


147
00:06:29,936 --> 00:06:33,056
spatializeIfMono 是过时行为


148
00:06:33,246 --> 00:06:35,416
这与多声道流的


149
00:06:35,416 --> 00:06:37,546
bypass 相同


150
00:06:37,546 --> 00:06:39,596
代表直通或缩混至


151
00:06:39,596 --> 00:06:40,806
输出格式


152
00:06:41,906 --> 00:06:44,016
pointSource 下


153
00:06:44,016 --> 00:06:45,826
音频被归为单声道


154
00:06:45,826 --> 00:06:47,366
并在播放器节点渲染


155
00:06:47,446 --> 00:06:50,096
ambienceBed 下


156
00:06:50,096 --> 00:06:52,246
音频被锚定在三维世界中


157
00:06:52,246 --> 00:06:53,596
并可根据播放器节点


158
00:06:53,596 --> 00:06:55,506
相对听众朝向


159
00:06:55,506 --> 00:06:56,716
所处的位置旋转


160
00:06:59,326 --> 00:07:00,856
这个例子是


161
00:07:00,856 --> 00:07:02,616
环境声效声源模式


162
00:07:02,616 --> 00:07:04,376
自动渲染算法


163
00:07:05,476 --> 00:07:07,496
设定属性后


164
00:07:07,496 --> 00:07:09,156
很重要的一点是确保


165
00:07:09,156 --> 00:07:10,666
连接播放器节点


166
00:07:10,666 --> 00:07:12,426
和环境节点


167
00:07:12,606 --> 00:07:13,836
所用的格式


168
00:07:14,106 --> 00:07:15,936
要包含多声道布局


169
00:07:19,176 --> 00:07:21,546
接下来 我们来看


170
00:07:21,546 --> 00:07:22,606
AVAudioSession 中的新内容


171
00:07:25,316 --> 00:07:27,906
AVAudioSessionPromptStyle 用于


172
00:07:27,906 --> 00:07:30,576
播放语音提示的 App


173
00:07:30,616 --> 00:07:32,366
可以修改


174
00:07:32,366 --> 00:07:34,076
语音提示的样式


175
00:07:35,036 --> 00:07:37,596
例如 如果 Siri 正在讲话


176
00:07:37,596 --> 00:07:39,116
或者通话正在进行


177
00:07:39,506 --> 00:07:41,116
言语导航提示便会


178
00:07:41,116 --> 00:07:42,756
干扰用户体验


179
00:07:43,696 --> 00:07:45,366
我们也不希望 Siri


180
00:07:45,366 --> 00:07:47,046
录下导航提示


181
00:07:47,946 --> 00:07:49,526
比方说 导航 App


182
00:07:49,526 --> 00:07:53,016
应当多关注提示样式的变化


183
00:07:53,016 --> 00:07:55,566
并修改提示 以改善用户体验


184
00:07:56,276 --> 00:07:57,746
我们有三种提示样式


185
00:07:57,916 --> 00:08:00,066
.none .short 和 .normal


186
00:08:00,756 --> 00:08:02,676
我们可以指明


187
00:08:02,676 --> 00:08:04,446
完全不播放提示


188
00:08:04,446 --> 00:08:06,496
播放简短提示


189
00:08:06,496 --> 00:08:07,446
或播放常规提示


190
00:08:10,026 --> 00:08:11,126
我们再来看看


191
00:08:11,126 --> 00:08:12,946
AVAudioSession 的其他改进


192
00:08:14,176 --> 00:08:15,766
默认策略是 


193
00:08:15,766 --> 00:08:17,406
音频录制激活时


194
00:08:17,406 --> 00:08:21,766
禁用触觉反馈和系统音效新属性


195
00:08:21,766 --> 00:08:23,076
allowHapticsAndSystemSoundsDuringRecording


196
00:08:23,076 --> 00:08:25,436
可以在会话正在


197
00:08:25,826 --> 00:08:27,186
使用音频录制时


198
00:08:27,186 --> 00:08:28,836
允许播放系统音效


199
00:08:28,836 --> 00:08:29,566
和触觉反馈


200
00:08:30,366 --> 00:08:32,126
它可以使用


201
00:08:32,336 --> 00:08:33,466
set allowHapticsAndSystemSoundsDuringRecording


202
00:08:33,466 --> 00:08:35,376
来设置


203
00:08:37,976 --> 00:08:40,096
欲知更多信息


204
00:08:40,096 --> 00:08:41,846
请访问开发者网站


205
00:08:43,196 --> 00:08:44,936
谢谢收看

