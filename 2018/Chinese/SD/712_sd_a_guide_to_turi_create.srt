1
00:00:06,516 --> 00:00:15,500
[ 音乐 ]


2
00:00:21,836 --> 00:00:23,076
>> [ 掌声 ] 嘿 大家好


3
00:00:25,266 --> 00:00:25,736
[ 掌声 ] 谢谢


4
00:00:25,736 --> 00:00:27,126
下午好 欢迎来到


5
00:00:27,126 --> 00:00:28,726
我们的 Turi Create 会议


6
00:00:30,286 --> 00:00:31,676
本会议将基于


7
00:00:31,676 --> 00:00:33,586
昨天的 Create ML 会议


8
00:00:34,076 --> 00:00:35,316
昨天的会议涵盖了很多


9
00:00:35,316 --> 00:00:37,336
Swift 中机器学习的基础


10
00:00:37,336 --> 00:00:38,596
所以如果你昨天没有出席


11
00:00:38,596 --> 00:00:40,006
我建议你把它


12
00:00:40,006 --> 00:00:40,916
添加到观看列表中


13
00:00:42,486 --> 00:00:44,396
Turi Create 的目标是


14
00:00:44,396 --> 00:00:46,236
帮助你为你的 App 


15
00:00:46,236 --> 00:00:48,866
添加智能用户体验


16
00:00:49,516 --> 00:00:52,606
例如 你可能想要拍摄一张


17
00:00:52,606 --> 00:00:53,266
早餐的照片后


18
00:00:53,526 --> 00:00:54,916
点击不同的食物项目


19
00:00:54,916 --> 00:00:56,726
看看你摄入了


20
00:00:56,726 --> 00:00:57,386
多少卡路里


21
00:00:59,076 --> 00:01:01,136
或者 也许你想


22
00:01:01,136 --> 00:01:03,496
使用你的 iPhone 和


23
00:01:03,496 --> 00:01:04,486
简单的手势来进行控制灯泡


24
00:01:07,356 --> 00:01:08,736
也许你想实时跟踪


25
00:01:08,736 --> 00:01:11,096
一个物体 比如一条狗


26
00:01:11,156 --> 00:01:12,866
或者狗的图片


27
00:01:12,866 --> 00:01:13,976
因为办公室里没有狗


28
00:01:14,516 --> 00:01:17,266
[ 笑声 ]


29
00:01:17,766 --> 00:01:20,116
也许你的游戏中


30
00:01:20,116 --> 00:01:21,566
有自定义的头像


31
00:01:21,696 --> 00:01:22,516
而你想要提供


32
00:01:22,516 --> 00:01:24,136
个性化的建议


33
00:01:24,496 --> 00:01:26,186
比如基于用户已选胡须


34
00:01:26,186 --> 00:01:26,826
推荐发型


35
00:01:28,216 --> 00:01:29,676
或者 也许你想让你的用户


36
00:01:29,676 --> 00:01:31,846
在自己的照片中


37
00:01:31,846 --> 00:01:33,756
应用艺术风格或滤镜


38
00:01:35,096 --> 00:01:37,806
这些是非常不同的用户体验


39
00:01:38,256 --> 00:01:40,136
但它们有几点是相同的


40
00:01:41,046 --> 00:01:43,536
首先 它们使用了机器学习


41
00:01:44,846 --> 00:01:46,556
创建这些体验


42
00:01:46,556 --> 00:01:49,906
只需要很少的数据


43
00:01:50,036 --> 00:01:51,516
所有这些模型都是用


44
00:01:51,516 --> 00:01:53,646
Turi Create 制作的 并用 Core ML 


45
00:01:53,646 --> 00:01:54,186
部署的


46
00:01:55,656 --> 00:01:57,176
它们都是按照五步创建的 


47
00:01:57,176 --> 00:01:59,096
我们今天会介绍


48
00:01:59,096 --> 00:02:00,226
这五个步骤


49
00:02:01,776 --> 00:02:02,906
所有这些演示 App


50
00:02:02,906 --> 00:02:04,366
都可以在我们的实验室中使用


51
00:02:04,366 --> 00:02:06,056
所以请大家今天或星期五


52
00:02:06,056 --> 00:02:08,326
前往 ML 实验室


53
00:02:08,326 --> 00:02:09,376
亲身体验这些 App


54
00:02:11,696 --> 00:02:14,026
Turi Create 是一个 Python 包


55
00:02:14,436 --> 00:02:16,186
帮助你创建 Core ML 模型


56
00:02:17,436 --> 00:02:19,446
它使用方便


57
00:02:19,446 --> 00:02:20,816
你不用成为 ML 专家


58
00:02:20,816 --> 00:02:22,066
甚至无需机器学习背景


59
00:02:22,066 --> 00:02:23,326
就可以创造这些


60
00:02:23,326 --> 00:02:24,676
激动人心的用户体验


61
00:02:25,626 --> 00:02:27,366
它使用方便 是因为


62
00:02:27,366 --> 00:02:29,646
它把关注任务


63
00:02:29,646 --> 00:02:30,206
放在了首位


64
00:02:30,206 --> 00:02:32,906
我们把复杂的机器学习算法


65
00:02:32,906 --> 00:02:34,776
抽象化了


66
00:02:34,776 --> 00:02:36,746
所以你可以专心于 想要创建的用户体验


67
00:02:38,056 --> 00:02:39,796
Turi Create 是跨平台的


68
00:02:39,796 --> 00:02:42,226
在 Mac 和 Linux 上都可以使用


69
00:02:43,066 --> 00:02:44,436
它也是开源的


70
00:02:45,726 --> 00:02:47,446
我们在 GitHub 上有一个代码仓库


71
00:02:47,446 --> 00:02:48,056
希望你们可以访问


72
00:02:48,056 --> 00:02:49,406
那里有很多很棒的资源


73
00:02:49,406 --> 00:02:50,186
可以帮助你们入门


74
00:02:51,456 --> 00:02:52,786
我们期待着与你


75
00:02:52,786 --> 00:02:54,156
和开发者社区的其他人


76
00:02:54,156 --> 00:02:55,716
一起努力


77
00:02:55,716 --> 00:02:57,856
让 Turi Create 变得越来越好


78
00:02:58,676 --> 00:03:00,276
今天我们很高兴地宣布


79
00:03:00,276 --> 00:03:01,886
Turi Create 5.0 Beta 版本


80
00:03:01,886 --> 00:03:04,216
现已可用


81
00:03:04,986 --> 00:03:06,576
它有一些强大的新功能


82
00:03:06,896 --> 00:03:08,336
比如 GPU 加速等


83
00:03:08,556 --> 00:03:09,846
我们将在今天晚些时候


84
00:03:09,846 --> 00:03:11,396
详细研究这些功能


85
00:03:12,776 --> 00:03:14,756
今天的重点主要是


86
00:03:14,756 --> 00:03:17,086
通过五个步骤


87
00:03:17,086 --> 00:03:18,366
创建 Core ML 模型


88
00:03:18,746 --> 00:03:20,306
我先要从高层次


89
00:03:20,306 --> 00:03:21,676
讨论这些步骤


90
00:03:22,086 --> 00:03:23,196
然后我们会深入讨论


91
00:03:23,196 --> 00:03:24,486
演示和代码


92
00:03:25,026 --> 00:03:28,746
所以你需要的第一步是


93
00:03:28,746 --> 00:03:31,126
理解你想要完成的任务


94
00:03:31,566 --> 00:03:33,276
以及我们如何使用


95
00:03:33,276 --> 00:03:34,316
机器学习的术语描述该任务


96
00:03:35,686 --> 00:03:37,536
其次 你需要明白


97
00:03:37,866 --> 00:03:39,656
完成这个任务


98
00:03:39,656 --> 00:03:40,616
所需的数据类型


99
00:03:41,026 --> 00:03:42,526
还有需要多少数据


100
00:03:43,696 --> 00:03:46,156
第三 你需要创建模型


101
00:03:48,056 --> 00:03:50,626
第四 你需要评估创建的模型


102
00:03:50,766 --> 00:03:52,066
这意味着了解


103
00:03:52,066 --> 00:03:53,536
模型的质量


104
00:03:53,536 --> 00:03:54,926
以及它是否可以投入生产环境


105
00:03:56,106 --> 00:03:57,946
最后 当你的模型


106
00:03:57,946 --> 00:03:59,566
可以进行部署时


107
00:03:59,566 --> 00:04:00,856
你可以轻松地使用 Core ML


108
00:04:02,356 --> 00:04:04,786
让我们深入每一个步骤


109
00:04:06,076 --> 00:04:07,656
Turi Create 可以让你完成


110
00:04:07,656 --> 00:04:10,566
各种各样常见的机器学习任务


111
00:04:10,836 --> 00:04:11,976
你也可以处理很多


112
00:04:11,976 --> 00:04:13,306
不同类型的数据


113
00:04:13,926 --> 00:04:16,296
例如 如果你有图像数据 


114
00:04:16,616 --> 00:04:18,646
你可能会对图像分类


115
00:04:18,805 --> 00:04:19,815
或对象检测感兴趣


116
00:04:20,856 --> 00:04:23,796
你可能想为用户提供个性化推荐 00:04:24,976 --> 00:04:25,876你可能想要能够


117
00:04:25,876 --> 00:04:27,756
自动检测活动


118
00:04:27,756 --> 00:04:30,226
比如步行或伸展跳跃


119
00:04:30,416 --> 00:04:33,056
你可能想要了解


120
00:04:33,056 --> 00:04:35,426
用户针对给定文本的情绪反应


121
00:04:36,256 --> 00:04:37,606
或者你可能对


122
00:04:37,606 --> 00:04:39,006
更传统的机器学习算法


123
00:04:39,006 --> 00:04:40,306
感兴趣00:04:40,306 --> 00:04:42,316比如分类和回归


124
00:04:44,636 --> 00:04:46,316
我知道现在


125
00:04:46,316 --> 00:04:47,806
那些机器学习的新手


126
00:04:47,806 --> 00:04:49,236
可能会很迷惑


127
00:04:49,696 --> 00:04:51,906
所以我们尝试


128
00:04:51,906 --> 00:04:53,866
在文档中为你们简化这部分内容


129
00:04:54,266 --> 00:04:56,986
我们从帮助你了解可能的


130
00:04:57,286 --> 00:04:59,156
任务类型开始


131
00:04:59,156 --> 00:05:00,436
然后是如何使用机器学习术语


132
00:05:00,436 --> 00:05:01,176
描述它们


133
00:05:01,716 --> 00:05:03,196
所以我们现在要做的是


134
00:05:03,196 --> 00:05:04,596
重新审视那些


135
00:05:04,596 --> 00:05:05,326
本次演讲开始时


136
00:05:05,326 --> 00:05:06,606
提到的智能体验


137
00:05:06,956 --> 00:05:08,176
并将它们对应到


138
00:05:08,176 --> 00:05:09,026
各个机器学习任务


139
00:05:09,626 --> 00:05:10,856
例如 如果你想


140
00:05:10,856 --> 00:05:12,616
识别照片中


141
00:05:12,616 --> 00:05:14,676
不同类型的花朵


142
00:05:14,676 --> 00:05:15,826
这称为图像分类


143
00:05:17,236 --> 00:05:19,136
如果你想拍下


144
00:05:19,406 --> 00:05:20,766
你的早餐


145
00:05:20,766 --> 00:05:22,096
并查看不同的食物对象


146
00:05:22,096 --> 00:05:24,876
这称为对象检测


147
00:05:25,436 --> 00:05:27,986
如果你想将艺术风格


148
00:05:27,986 --> 00:05:30,246
应用到自己的照片中


149
00:05:30,246 --> 00:05:31,546
我们称之为风格转移


150
00:05:33,606 --> 00:05:35,256
如果你想使用


151
00:05:35,356 --> 00:05:37,046
不同的设备的传感器


152
00:05:37,046 --> 00:05:38,816
识别手势 动作或不同活动


153
00:05:38,816 --> 00:05:41,896
我们称之为活动分类


154
00:05:43,996 --> 00:05:45,616
最后 如果你想向用户


155
00:05:45,656 --> 00:05:46,906
提供个性化的建议


156
00:05:46,906 --> 00:05:48,886
我们称这个任务为


157
00:05:49,106 --> 00:05:50,086
推荐系统


158
00:05:50,766 --> 00:05:53,936
现在很棒的一点是


159
00:05:53,936 --> 00:05:55,756
我们刚刚提到过的


160
00:05:55,756 --> 00:05:57,596
五个步骤方法 也适用于


161
00:05:57,596 --> 00:05:58,106
代码编写


162
00:05:59,156 --> 00:06:01,236
我们从导入 Turi Create 开始


163
00:06:02,526 --> 00:06:04,796
然后把我们的数据加载到


164
00:06:04,796 --> 00:06:06,466
SFrame 数据结构中


165
00:06:06,816 --> 00:06:07,796
我们稍后会进一步


166
00:06:07,796 --> 00:06:09,156
详细讨论 SFrame


167
00:06:09,156 --> 00:06:10,006
数据结构


168
00:06:10,486 --> 00:06:13,106
然后使用一个简单的函数 


169
00:06:13,106 --> 00:06:14,736
.create


170
00:06:14,816 --> 00:06:15,446
创建我们的模型


171
00:06:15,966 --> 00:06:18,116
这个函数把


172
00:06:18,116 --> 00:06:19,336
复杂的机器学习


173
00:06:19,336 --> 00:06:22,066
藏在了幕后


174
00:06:22,956 --> 00:06:24,966
之后我们使用


175
00:06:24,966 --> 00:06:26,916
简单的函数 .evaluate 评估我们的模型


176
00:06:27,476 --> 00:06:30,266
最后我们把最终模型


177
00:06:30,266 --> 00:06:32,586
导出为 Core ML 的


178
00:06:32,626 --> 00:06:34,396
mlmodel 格式


179
00:06:34,396 --> 00:06:36,686
可以被拖拽到 Xcode 中


180
00:06:37,356 --> 00:06:39,226
现在我想提的是


181
00:06:39,226 --> 00:06:41,166
这样的五步模板


182
00:06:41,166 --> 00:06:42,866
适用于 Turi Create 中


183
00:06:42,866 --> 00:06:43,506
所有不同的任务


184
00:06:44,296 --> 00:06:45,146
所以无论你在做的是


185
00:06:45,146 --> 00:06:47,186
对象检测 图像分类


186
00:06:47,186 --> 00:06:49,716
或活动分类


187
00:06:49,716 --> 00:06:51,896
代码模板


188
00:06:51,896 --> 00:06:52,806
是通用的


189
00:06:52,806 --> 00:06:56,826
我们今天的第一个演示


190
00:06:57,066 --> 00:06:59,846
是一个卡路里计算 App


191
00:06:59,846 --> 00:07:01,196
它使用了对象检测模型


192
00:07:01,746 --> 00:07:02,866
我们想要识别


193
00:07:03,186 --> 00:07:04,486
图像中的不同食物


194
00:07:04,726 --> 00:07:05,636
我们需要知道它们在哪里


195
00:07:05,636 --> 00:07:07,046
在图像的哪个位置


196
00:07:07,046 --> 00:07:08,396
然后才能轻点它们


197
00:07:08,396 --> 00:07:10,000
查看不同的卡路里数值


198
00:07:13,196 --> 00:07:14,636
所以让我们来看看


199
00:07:14,636 --> 00:07:16,036
创建这个机器学习模型


200
00:07:16,036 --> 00:07:17,846
所需要的数据类型 00:07:18,436 --> 00:07:20,906当然 我们需要图像


201
00:07:20,906 --> 00:07:21,866
如果我们只是建立一个


202
00:07:21,866 --> 00:07:24,006
简单的图像分类器模型 


203
00:07:24,306 --> 00:07:25,286
那我们只需要一套图像


204
00:07:25,286 --> 00:07:28,356
和描述图像的标签


205
00:07:29,366 --> 00:07:30,506
但是因为我们要进行


206
00:07:30,746 --> 00:07:32,506
对象检测


207
00:07:32,506 --> 00:07:33,316
我们需要更多信息


208
00:07:33,956 --> 00:07:35,416
我们不仅需要了解


209
00:07:35,416 --> 00:07:36,226
图像中有什么


210
00:07:36,496 --> 00:07:37,766
还有那些物体在哪里


211
00:07:38,146 --> 00:07:40,126
现在 如果我们仔细看一个例子


212
00:07:40,126 --> 00:07:42,596
可以看到红色框圈出了


213
00:07:42,646 --> 00:07:43,756
一杯咖啡


214
00:07:44,616 --> 00:07:46,376
绿色框圈出了羊角面包


215
00:07:47,336 --> 00:07:48,916
我们称这些方框为边界框


216
00:07:48,916 --> 00:07:50,996
并用 JSON 格式


217
00:07:50,996 --> 00:07:51,936
写出来


218
00:07:52,296 --> 00:07:53,806
设置一个标签


219
00:07:53,806 --> 00:07:56,086
然后写出 x y 坐标 宽度和高度


220
00:07:56,656 --> 00:07:58,186
其中 x 和 y 坐标指的是


221
00:07:58,186 --> 00:07:59,926
该边界框的中心


222
00:08:00,216 --> 00:08:01,426
还有一点值得注意


223
00:08:01,426 --> 00:08:03,066
通过对象检测


224
00:08:03,066 --> 00:08:05,196
你可以找到或检测


225
00:08:05,196 --> 00:08:07,996
多张图像中 每个图像里的多个对象


226
00:08:07,996 --> 00:08:11,086
所以我提到我们会


227
00:08:11,086 --> 00:08:12,816
将数据加载到


228
00:08:12,816 --> 00:08:14,686
这种表格数据结构中 称为 SFrame


229
00:08:15,406 --> 00:08:16,716
在这个例子中


230
00:08:16,716 --> 00:08:17,926
我们的表格最终包含两列


231
00:08:18,136 --> 00:08:19,836
第一列是你的图像


232
00:08:20,466 --> 00:08:22,086
第二列是


233
00:08:22,086 --> 00:08:24,000
以 JSON 格式写出的注释


234
00:08:27,476 --> 00:08:29,306
现在你可能会好奇


235
00:08:29,306 --> 00:08:30,886
什么是 SFrame


236
00:08:30,886 --> 00:08:32,506
所以让我们退一步 


237
00:08:32,506 --> 00:08:34,706
一起了解它


238
00:08:34,706 --> 00:08:36,596
SFrame 是一种基于磁盘的


239
00:08:36,596 --> 00:08:37,376
表格数据结构


240
00:08:37,566 --> 00:08:39,006
而这意味着你可以


241
00:08:39,395 --> 00:08:40,976
在笔记本上


242
00:08:40,976 --> 00:08:41,806
创建机器学习模型


243
00:08:41,966 --> 00:08:43,015
即使你有巨大的


244
00:08:43,015 --> 00:08:45,226
数据量


245
00:08:45,366 --> 00:08:46,656
SFrame 允许你执行


246
00:08:46,656 --> 00:08:48,676
常规的数据操作任务


247
00:08:49,026 --> 00:08:50,816
像连接两个 SFrame 或


248
00:08:50,816 --> 00:08:53,476
过滤到特定的数据行或数据列


249
00:08:55,296 --> 00:08:57,976
SFrames 可让你整合不同的数据类型


250
00:08:58,926 --> 00:08:59,986
一旦你将数据


251
00:09:00,046 --> 00:09:02,486
加载到一个 SFrame 中


252
00:09:02,486 --> 00:09:04,446
就很容易可视化探索和检查


253
00:09:04,446 --> 00:09:05,000
你的数据


254
00:09:08,936 --> 00:09:10,426
让我们再进一步 了解


255
00:09:10,426 --> 00:09:11,796
SFrame 提供了哪些可能


256
00:09:12,796 --> 00:09:13,946
用我们的物体探测器


257
00:09:13,946 --> 00:09:14,396
作为例子


258
00:09:15,446 --> 00:09:17,026
在我们导入 Turi Create 之后 


259
00:09:17,426 --> 00:09:18,436
针对我们的对象探测器


260
00:09:18,436 --> 00:09:20,206
我们需要


261
00:09:20,276 --> 00:09:21,606
加载两个不同的 SFrame


262
00:09:22,086 --> 00:09:23,406
第一个包含我们的注释


263
00:09:23,406 --> 00:09:27,166
第二个包含我们的图像


264
00:09:27,896 --> 00:09:29,556
有一个简单的函数


265
00:09:29,556 --> 00:09:31,526
.explore 可以让你


266
00:09:31,526 --> 00:09:33,276
可视化检查你导入的数据


267
00:09:34,276 --> 00:09:36,896
我们可以做到访问特定的行


268
00:09:37,386 --> 00:09:38,496
或访问特定的数据列


269
00:09:39,866 --> 00:09:40,976
当然我们可以完成常规操作


270
00:09:40,976 --> 00:09:43,266
比如把两个 SFrame


271
00:09:43,266 --> 00:09:44,286
连接成一个


272
00:09:44,826 --> 00:09:46,546
并保存所产生的 SFrame


273
00:09:46,986 --> 00:09:51,356
供以后使用或与同事分享


274
00:09:51,486 --> 00:09:52,746
下一步是创建我们的模型


275
00:09:53,146 --> 00:09:54,306
我刚刚提到


276
00:09:54,396 --> 00:09:56,746
有一个简单的函数 .create 


277
00:09:56,746 --> 00:09:58,126
创造实际模型的


278
00:09:58,126 --> 00:09:59,576
所有重任


279
00:10:00,016 --> 00:10:01,486
我们在幕后做的


280
00:10:01,486 --> 00:10:03,026
就是创建的模型


281
00:10:03,026 --> 00:10:04,546
是为你的任务


282
00:10:04,546 --> 00:10:06,496
量身定制的 像是艺术品


283
00:10:06,496 --> 00:10:07,916
这意味着我们尽力


284
00:10:07,956 --> 00:10:10,016
保证它的高质量 高准确度


285
00:10:10,016 --> 00:10:12,256
无论你的数据规模是大还是小


286
00:10:12,256 --> 00:10:14,206
我们都可以做到


287
00:10:14,516 --> 00:10:16,336
对我们而言重要的是


288
00:10:16,386 --> 00:10:17,926
所有的任务都可以正常工作


289
00:10:17,926 --> 00:10:19,846
就算每个


290
00:10:19,846 --> 00:10:22,116
你想要检测的


291
00:10:22,176 --> 00:10:23,266
对象类中的项目


292
00:10:23,266 --> 00:10:24,676
只有 40 张图像


293
00:10:25,106 --> 00:10:26,276
在对象检测的例子中


294
00:10:26,826 --> 00:10:30,866
让我们进行下一步 评估


295
00:10:31,236 --> 00:10:32,446
我提到有一个简单的


296
00:10:32,446 --> 00:10:34,936
函数 .evaluate


297
00:10:34,936 --> 00:10:36,566
它会告诉你模型的


298
00:10:36,566 --> 00:10:37,106
质量如何


299
00:10:38,216 --> 00:10:40,006
在这个例子中


300
00:10:40,416 --> 00:10:42,086
我们有两个考虑因素


301
00:10:42,406 --> 00:10:43,846
首先 我们想知道


302
00:10:43,846 --> 00:10:44,766
标签匹配正确吗


303
00:10:45,386 --> 00:10:46,966
但我们也必须知道


304
00:10:46,966 --> 00:10:48,306
框住对象的边界框


305
00:10:48,666 --> 00:10:49,476
是否正确


306
00:10:50,616 --> 00:10:51,876
所以我们可以建立


307
00:10:51,876 --> 00:10:53,846
对这两个因素的衡量标准


308
00:10:53,846 --> 00:10:55,906
并通过测试数据集


309
00:10:55,906 --> 00:10:57,696
对预测进行评分


310
00:10:57,696 --> 00:11:00,616
基于完全正确的已知数据


311
00:11:01,446 --> 00:11:02,726
所以我们希望


312
00:11:02,726 --> 00:11:04,026
标签都是正确的


313
00:11:04,506 --> 00:11:07,046
并且对边界框的


314
00:11:07,046 --> 00:11:08,906
衡量标准是


315
00:11:08,906 --> 00:11:10,616
预测边界框


316
00:11:10,616 --> 00:11:12,756
至少有 50% 与完全正确的边界框重叠


317
00:11:13,206 --> 00:11:14,676
我们来看几个例子


318
00:11:15,236 --> 00:11:18,296
在这个预测中 可以看到


319
00:11:18,296 --> 00:11:19,806
模型得出了正确的标签


320
00:11:20,336 --> 00:11:21,316
是一杯咖啡


321
00:11:21,906 --> 00:11:25,016
但边界框 并未框住整杯咖啡


322
00:11:25,016 --> 00:11:27,286
与完全正确的边界框只有 10% 重合


323
00:11:27,726 --> 00:11:29,256
所以我们会认为


324
00:11:29,666 --> 00:11:31,676
这是一个失败的预测


325
00:11:31,676 --> 00:11:33,136
这是一个非常准确的


326
00:11:33,136 --> 00:11:35,106
边界框


327
00:11:35,106 --> 00:11:35,816
但标签错了


328
00:11:35,896 --> 00:11:36,786
那不是香蕉


329
00:11:37,206 --> 00:11:38,706
所以我们认为这也不是一个


330
00:11:38,706 --> 00:11:39,896
成功的预测


331
00:11:41,006 --> 00:11:42,236
这是我们想要看到的


332
00:11:42,236 --> 00:11:42,866
处于中间的例子


333
00:11:43,336 --> 00:11:44,906
70% 重叠于


334
00:11:44,906 --> 00:11:46,836
绝对正确的边界框


335
00:11:46,836 --> 00:11:47,896
和正确的标签 咖啡


336
00:11:48,796 --> 00:11:49,776
所以我们做的就是


337
00:11:49,776 --> 00:11:51,416
运用测试数据集


338
00:11:51,416 --> 00:11:53,066
系统地分析所有预测


339
00:11:53,656 --> 00:11:55,026
获得新模型准确性的


340
00:11:55,026 --> 00:11:56,806
整体评分


341
00:11:57,356 --> 00:12:01,196
最后一步是部署


342
00:12:01,896 --> 00:12:03,146
这是一个导出到 Core ML 的函数


343
00:12:03,146 --> 00:12:04,556
能将你的模型保存为


344
00:12:04,626 --> 00:12:06,386
Core ML 的 mlmodel 格式


345
00:12:06,816 --> 00:12:08,056
然后你可以将该模型


346
00:12:08,056 --> 00:12:09,486
拖拽到 Xcode 中


347
00:12:10,696 --> 00:12:12,046
本周其实我们推出了


348
00:12:12,046 --> 00:12:13,806
激动人心的新功能


349
00:12:13,806 --> 00:12:15,296
与物体检测相关


350
00:12:15,856 --> 00:12:16,876
所以我鼓励你参加


351
00:12:16,876 --> 00:12:18,716
明天的 Vision with Core ML 会议


352
00:12:18,716 --> 00:12:20,506
以了解更多信息


353
00:12:20,876 --> 00:12:21,886
在那个会议上


354
00:12:21,886 --> 00:12:23,076
演讲者会使用今天我们构建的


355
00:12:23,076 --> 00:12:24,036
对象检测模型


356
00:12:24,036 --> 00:12:26,146
并且详细介绍


357
00:12:26,146 --> 00:12:27,706
部署选项


358
00:12:28,316 --> 00:12:30,996
这就是


359
00:12:31,536 --> 00:12:33,826
Turi Create 的五个步骤


360
00:12:35,516 --> 00:12:38,946
[ 掌声 ]


361
00:12:39,446 --> 00:12:40,036
谢谢


362
00:12:40,316 --> 00:12:41,256
现在我要将话筒传给


363
00:12:41,256 --> 00:12:42,896
我的同事 Zach Nation 


364
00:12:42,896 --> 00:12:43,426
他会进行演示


365
00:12:45,516 --> 00:12:50,436
[ 掌声 ]


366
00:12:50,936 --> 00:12:51,536
>> 谢谢 Aaron


367
00:12:52,466 --> 00:12:54,616
我想我们就直接进入代码部分


368
00:12:54,616 --> 00:12:55,616
今天现场


369
00:12:55,616 --> 00:12:56,516
有谁想写代码 


370
00:12:56,946 --> 00:12:58,096
我们将继续


371
00:12:58,096 --> 00:13:00,000
构建一个对象检测器模型


372
00:13:10,046 --> 00:13:11,956
所以我要从访达 开始


373
00:13:12,336 --> 00:13:14,216
这里有一个图像文件夹


374
00:13:14,596 --> 00:13:16,266
我想用它来训练一个模型


375
00:13:17,206 --> 00:13:18,546
我们可以看到这个文件夹叫 Data


376
00:13:18,546 --> 00:13:22,296
里面全是早餐食品的图像


377
00:13:22,786 --> 00:13:25,936
这里有牛角面包 鸡蛋等等


378
00:13:26,516 --> 00:13:29,006
这是一个很好的早餐食物


379
00:13:29,006 --> 00:13:29,736
数据集


380
00:13:29,736 --> 00:13:31,746
那么我们开始写一些代码


381
00:13:33,016 --> 00:13:34,806
我要切换到这个环境


382
00:13:34,806 --> 00:13:36,466
叫做 Jupyter Notebook


383
00:13:37,096 --> 00:13:38,546
它是一个交互式的 Python 环境


384
00:13:38,546 --> 00:13:40,576
你可以在此运行


385
00:13:40,576 --> 00:13:42,026
Python 代码片段


386
00:13:42,026 --> 00:13:43,256
并立即看到输出结果


387
00:13:43,526 --> 00:13:45,126
所以这是一个很好的方法


388
00:13:45,126 --> 00:13:46,526
可以交互使用模型


389
00:13:46,776 --> 00:13:50,066
它的概念与 Xcode Playgrounds 非常相似


390
00:13:51,056 --> 00:13:52,116
我们要做的第一件事是


391
00:13:52,116 --> 00:13:55,996
导入 Turi Create 并称之为 tc


392
00:13:56,396 --> 00:14:00,376
这样在剩下的


393
00:14:00,376 --> 00:14:02,416
代码中都可以称它为 tc


394
00:14:03,576 --> 00:14:05,326
现在 第一个任务


395
00:14:06,166 --> 00:14:07,336
是加载数据


396
00:14:07,916 --> 00:14:12,086
我们将以 SFrame 格式


397
00:14:12,086 --> 00:14:13,356
加载数据


398
00:14:14,256 --> 00:14:15,846
首先我们我们将 images


399
00:14:15,846 --> 00:14:18,046
赋值为 tc.loadimages


400
00:14:18,536 --> 00:14:19,386
参数为 我刚刚展示


401
00:14:19,386 --> 00:14:21,616
访达中的文件夹 Data


402
00:14:22,166 --> 00:14:26,476
Turi Create 提供了


403
00:14:26,476 --> 00:14:28,206
工具 可以让我们交互式


404
00:14:28,206 --> 00:14:29,766
探索和可视化数据


405
00:14:30,006 --> 00:14:31,346
所以让我们确保


406
00:14:31,346 --> 00:14:32,866
正确加载这些图像


407
00:14:32,866 --> 00:14:34,496
然后我们得到了想要的 SFrame


408
00:14:35,216 --> 00:14:36,696
我将调用 .explore 


409
00:14:37,456 --> 00:14:38,826
这将打开一个


410
00:14:38,826 --> 00:14:40,346
可视化窗口


411
00:14:40,346 --> 00:14:41,976
我们在这里可以看到


412
00:14:41,976 --> 00:14:42,696
我们的 SFrame 有两列


413
00:14:43,166 --> 00:14:44,746
第一个叫做 path


414
00:14:44,746 --> 00:14:46,256
这是相对路径


415
00:14:46,256 --> 00:14:47,106
指向磁盘上的图像


416
00:14:47,536 --> 00:14:49,296
第二列叫做 image


417
00:14:49,566 --> 00:14:51,866
而这其实就是图像内容本身


418
00:14:52,096 --> 00:14:53,166
我们可以看到我们的早餐食物


419
00:14:53,206 --> 00:14:53,906
就在这里


420
00:14:54,676 --> 00:14:55,586
看起来数据加载正确


421
00:14:55,586 --> 00:14:56,956
所以我要继续


422
00:14:56,956 --> 00:14:57,356
下一步


423
00:14:57,906 --> 00:15:01,026
回到 Jupyter Notebook


424
00:15:01,416 --> 00:15:02,786
现在我要加载


425
00:15:02,786 --> 00:15:04,996
第二个 SFrame 叫 annotations


426
00:15:05,536 --> 00:15:09,416
我打算调用


427
00:15:09,416 --> 00:15:11,066
SFrame 构造函数


428
00:15:11,066 --> 00:15:13,896
并提供一个文件名 annotations.csv


429
00:15:14,326 --> 00:15:16,286
这是一个 CSV 文件


430
00:15:16,286 --> 00:15:18,546
包含与图像对应的注释


431
00:15:19,236 --> 00:15:23,256
让我们看一看


432
00:15:23,876 --> 00:15:25,206
就在 Jupyter Notebook 中


433
00:15:25,206 --> 00:15:26,296
可以看到这个 SFrame


434
00:15:26,296 --> 00:15:28,146
包含一个 path 列


435
00:15:28,146 --> 00:15:29,476
同样是相对路径


436
00:15:29,476 --> 00:15:30,706
指向磁盘上的图像


437
00:15:31,206 --> 00:15:32,926
还有一个 annotation 列


438
00:15:33,156 --> 00:15:34,606
包含一个 JSON 对象


439
00:15:34,806 --> 00:15:36,326
描述边界框和


440
00:15:36,326 --> 00:15:38,366
与图片对应的标签


441
00:15:39,806 --> 00:15:40,866
但现在我们有两个不同的


442
00:15:40,866 --> 00:15:42,636
数据来源


443
00:15:42,826 --> 00:15:44,776
我们需要提供一个数据源来训练模型


444
00:15:45,316 --> 00:15:46,406
让我们把它们合并起来


445
00:15:47,096 --> 00:15:48,986
在 Turi Create 中


446
00:15:48,986 --> 00:15:50,186
只要调用 join 方法就可以了


447
00:15:50,616 --> 00:15:52,626
我将 data 赋值为


448
00:15:52,956 --> 00:15:57,946
images.join(annotations)


449
00:15:58,066 --> 00:15:59,916
现在我们就有一个


450
00:16:00,036 --> 00:16:01,656
三列的 SFrame


451
00:16:02,216 --> 00:16:03,766
它将 path 列作为键值进行连接


452
00:16:04,016 --> 00:16:05,956
因此 它为每个具有路径的图像 


453
00:16:06,206 --> 00:16:08,246
添加了指向该路径的注释


454
00:16:09,006 --> 00:16:11,806
因此每张图像都有对应的注释


455
00:16:12,656 --> 00:16:13,786
现在我们可以训练模型了


456
00:16:14,386 --> 00:16:17,936
所以我要创建一个新节


457
00:16:17,936 --> 00:16:20,716
叫做 Train a model


458
00:16:23,406 --> 00:16:26,276
在这里写一行代码


459
00:16:26,276 --> 00:16:28,096
将 model 赋值为


460
00:16:28,426 --> 00:16:30,606
tc.objectdetector.create.


461
00:16:30,936 --> 00:16:31,896
这是我们用于对象检测的


462
00:16:31,896 --> 00:16:33,636
简单任务型 API


463
00:16:33,636 --> 00:16:35,696
它需要以这种形式传入数据


464
00:16:36,476 --> 00:16:37,906
我要传入刚刚创建的


465
00:16:37,906 --> 00:16:39,226
data SFrame


466
00:16:39,686 --> 00:16:41,126
为了今天的演示


467
00:16:41,126 --> 00:16:42,816
我会传入另一个参数


468
00:16:42,816 --> 00:16:44,686
称为 max_iterations


469
00:16:45,136 --> 00:16:46,706
通常你不需要


470
00:16:46,706 --> 00:16:48,046
传递这个参数


471
00:16:48,086 --> 00:16:49,366
因为 Turi Create 会为你


472
00:16:49,366 --> 00:16:51,076
选择正确的迭代次数


473
00:16:51,226 --> 00:16:52,676
次数是根据你提供的数据做出的


474
00:16:53,456 --> 00:16:54,916
针对这个演示 我要将


475
00:16:54,916 --> 00:16:56,876
最大迭代赋值为 1


476
00:16:56,876 --> 00:16:58,216
只是简单展示一下


477
00:16:58,216 --> 00:16:59,076
训练是什么样子的


478
00:16:59,886 --> 00:17:01,216
这要花费一些时间


479
00:17:01,216 --> 00:17:03,856
因为程序需要遍历并调整


480
00:17:03,856 --> 00:17:05,445
所有图像的大小


481
00:17:05,445 --> 00:17:07,435
从而运行神经网络


482
00:17:07,435 --> 00:17:09,665
这是在物体检测器后台发生的


483
00:17:10,465 --> 00:17:12,036
然后它会在这台 Mac GPO 上


484
00:17:12,036 --> 00:17:14,856
仅进行一次迭代


485
00:17:16,116 --> 00:17:17,965
但这可能不是


486
00:17:17,965 --> 00:17:19,435
得出的最好的模型


487
00:17:19,435 --> 00:17:21,306
因为我只能花几秒钟训练它


488
00:17:21,656 --> 00:17:22,906
然后我就要


489
00:17:22,906 --> 00:17:25,016
切换到烹饪节目模式


490
00:17:25,056 --> 00:17:26,406
从烤箱里拿出一个


491
00:17:26,406 --> 00:17:27,445
已经训练一个小时的


492
00:17:27,445 --> 00:17:28,036
成品 [ 笑声 ]


493
00:17:28,726 --> 00:17:30,826
[ 掌声 ] 所以我要输入


494
00:17:30,826 --> 00:17:34,676
tc.load_model


495
00:17:34,796 --> 00:17:36,696
并调用 breakfastmodel.model


496
00:17:36,696 --> 00:17:39,546
我花了较长的时间


497
00:17:39,546 --> 00:17:41,316
训练了这个模型


498
00:17:41,806 --> 00:17:43,466
所以我们 Notebook 中


499
00:17:43,466 --> 00:17:44,026
查看一下


500
00:17:44,266 --> 00:17:45,396
我们可以看到


501
00:17:45,396 --> 00:17:46,576
这是一个物体探测器模型


502
00:17:47,226 --> 00:17:48,356
它已经接受了六个类别的训练


503
00:17:48,386 --> 00:17:50,336
训练时间为


504
00:17:50,336 --> 00:17:51,486
55 分钟


505
00:17:52,026 --> 00:17:53,006
这意味着你


506
00:17:53,006 --> 00:17:54,296
可以在一小时以内


507
00:17:54,296 --> 00:17:55,966
使用你的 Mac


508
00:17:55,966 --> 00:17:58,000
训练出一个可用的物体探测器模型


509
00:18:01,096 --> 00:18:02,866
接下来 让我们测试一下


510
00:18:02,866 --> 00:18:05,000
这个模型的预测效果


511
00:18:11,046 --> 00:18:13,096
所以我会开始一个新节


512
00:18:13,166 --> 00:18:13,676
叫做 Inspect predictions


513
00:18:14,056 --> 00:18:15,506
然后加载一个


514
00:18:15,716 --> 00:18:17,436
测试数据集


515
00:18:18,026 --> 00:18:19,496
在这里我已经准备好了


516
00:18:19,496 --> 00:18:20,676
一个 SFrame 格式的数据


517
00:18:20,676 --> 00:18:21,716
所以我只是要加载它 


518
00:18:22,436 --> 00:18:23,266
文件名为


519
00:18:23,266 --> 00:18:25,046
test-breakfast-data.sframe


520
00:18:25,666 --> 00:18:26,606
这个测试 SFrame


521
00:18:26,606 --> 00:18:28,756
有两个重要的属性


522
00:18:29,146 --> 00:18:31,126
一个是它包含的图像类型


523
00:18:31,126 --> 00:18:33,256
该模型受训的图像类型


524
00:18:33,366 --> 00:18:34,316
完全一样


525
00:18:34,656 --> 00:18:36,216
但第二个属性是


526
00:18:36,216 --> 00:18:37,756
该模型从未见过


527
00:18:37,756 --> 00:18:39,266
这些测试图片


528
00:18:39,556 --> 00:18:41,136
所以这是一个很好的测试


529
00:18:41,136 --> 00:18:42,126
可以检测该模型能否


530
00:18:42,126 --> 00:18:44,176
推广到用户的真实数据


531
00:18:44,756 --> 00:18:48,466
我会调用 model.predict


532
00:18:48,566 --> 00:18:50,176
并传入测试 SFrame


533
00:18:50,176 --> 00:18:52,016
从而对整个测试集


534
00:18:52,016 --> 00:18:54,196
做预测


535
00:18:54,396 --> 00:18:56,546
我们会得到整个


536
00:18:57,096 --> 00:19:00,656
SFframe 的批量预测结果


537
00:19:00,656 --> 00:19:01,136
这只会花费数秒


538
00:19:01,996 --> 00:19:04,306
然后我们要查看结果


539
00:19:04,516 --> 00:19:06,346
我只是随便选一个预测结果


540
00:19:06,626 --> 00:19:08,856
假设下标为 2


541
00:19:09,606 --> 00:19:11,676
在这里我们可以看到预测出的


542
00:19:11,676 --> 00:19:13,346
JSON 对象


543
00:19:13,346 --> 00:19:14,966
与提供的训练数据


544
00:19:14,966 --> 00:19:16,106
格式相同


545
00:19:16,446 --> 00:19:18,316
所以这里有


546
00:19:18,486 --> 00:19:19,776
高度 宽度 x y 坐标


547
00:19:20,056 --> 00:19:21,196
还有标签 香蕉


548
00:19:21,796 --> 00:19:23,816
我们得到了模型给出的置信度评分


549
00:19:23,966 --> 00:19:25,876
对于这个数据 评分为 0.87


550
00:19:26,886 --> 00:19:28,466
我作为人类


551
00:19:28,466 --> 00:19:29,976
很难解读这个数据


552
00:19:30,436 --> 00:19:32,516
我真的不知道


553
00:19:32,516 --> 00:19:33,786
这个图象是否是香蕉


554
00:19:33,786 --> 00:19:35,446
或这些坐标指向的


555
00:19:35,446 --> 00:19:36,866
是否是香蕉


556
00:19:36,866 --> 00:19:38,526
在图像中的位置


557
00:19:39,686 --> 00:19:41,526
Turi Create 有一个函数


558
00:19:41,706 --> 00:19:42,996
可以将预测的边界框


559
00:19:42,996 --> 00:19:44,476
或绝对正确的边界框


560
00:19:44,476 --> 00:19:47,096
绘制在图像上00:19:47,576 --> 00:19:48,836这是我们需要的


561
00:19:49,516 --> 00:19:50,976
我要在测试 SFrame 中


562
00:19:51,046 --> 00:19:52,846
创建一个新列


563
00:19:52,906 --> 00:19:53,856
叫 predicted_image


564
00:19:54,936 --> 00:19:56,926
并调用物体检测器的实用工具


565
00:19:56,926 --> 00:19:58,906
draw_bounding_boxes


566
00:19:58,906 --> 00:20:00,896
为它赋值


567
00:20:01,756 --> 00:20:03,736
我将向 draw_bounding_boxes 函数


568
00:20:03,736 --> 00:20:06,946
传入测试的 image 列


569
00:20:07,016 --> 00:20:09,176
也就是图像本身


570
00:20:09,176 --> 00:20:11,616
并传入


571
00:20:11,616 --> 00:20:13,626
刚刚从模型中得到的预测


572
00:20:13,766 --> 00:20:15,616
这个函数会将


573
00:20:15,656 --> 00:20:17,316
预测的边界框


574
00:20:17,316 --> 00:20:18,126
画到每张图片上


575
00:20:18,656 --> 00:20:19,996
现在我们来看看这个


576
00:20:19,996 --> 00:20:21,286
2 号预测


577
00:20:21,566 --> 00:20:23,096
这次是以图像形式


578
00:20:24,676 --> 00:20:25,586
所以我输入


579
00:20:25,586 --> 00:20:28,396
test[‘predicted_image’][2].show


580
00:20:28,836 --> 00:20:30,786
Notebook 中就会显示结果


581
00:20:31,516 --> 00:20:38,016
[ 掌声 ]


582
00:20:38,516 --> 00:20:39,946
这样的抽样调查很棒


583
00:20:39,946 --> 00:20:41,596
因为我们知道了


584
00:20:41,596 --> 00:20:43,146
至少对这张图片来说 模型是正确的


585
00:20:43,616 --> 00:20:44,706
但我们并不知道它对于接下来


586
00:20:44,706 --> 00:20:45,996
可能传入的 50,000 张图片


587
00:20:45,996 --> 00:20:47,786
能否得出正确结果


588
00:20:48,636 --> 00:20:50,916
为此 我们将会对模型进行


589
00:20:50,976 --> 00:20:51,846
量化评估


590
00:20:52,446 --> 00:20:53,966
我在 Notebook 上


591
00:20:53,966 --> 00:20:55,106
开始一个新节


592
00:20:55,106 --> 00:20:56,326
称为 Evaluate the model


593
00:20:56,426 --> 00:20:58,286
而我们要做的是


594
00:20:58,286 --> 00:21:01,226
调用 model.evaluate


595
00:21:01,226 --> 00:21:04,186
再一次 我将会传入整个测试数据集


596
00:21:05,936 --> 00:21:08,096
这里的评估函数会


597
00:21:08,096 --> 00:21:09,436
依照刚刚 Aaron 所描述的


598
00:21:09,436 --> 00:21:11,526
衡量标准


599
00:21:11,526 --> 00:21:12,546
检查边界框


600
00:21:12,546 --> 00:21:14,556
是否有 50% 的重叠度


601
00:21:14,556 --> 00:21:15,586
以及标签是否正确


602
00:21:15,586 --> 00:21:17,226
它会给我们结果


603
00:21:17,226 --> 00:21:19,926
这个结果是 六个已训类别中的一个


604
00:21:20,516 --> 00:21:22,036
在这里我们可以看到


605
00:21:22,356 --> 00:21:24,096
对于百吉饼 边界框重叠度达标


606
00:21:24,096 --> 00:21:25,636
且标签正确的情况


607
00:21:25,736 --> 00:21:27,696
有 80%


608
00:21:28,106 --> 00:21:31,276
香蕉的正确率为 67%


609
00:21:32,456 --> 00:21:34,016
结果很好


610
00:21:34,096 --> 00:21:35,616
现在我想知道 这个模型


611
00:21:35,616 --> 00:21:37,226
能否在实际的 App 中工作


612
00:21:37,866 --> 00:21:39,526
我打算调用


613
00:21:39,806 --> 00:21:42,366
export_coreml 来创建一个 Core ML 模型


614
00:21:42,366 --> 00:21:44,076
也就是我们刚刚训练的的模型


615
00:21:44,226 --> 00:21:45,666
我决定把它命名为


616
00:21:45,666 --> 00:21:47,536
BreakfastModel.mlmodel.


617
00:21:47,826 --> 00:21:49,036
然后 一旦完成


618
00:21:49,036 --> 00:21:50,546
训练 我就可以在


619
00:21:50,546 --> 00:21:51,656
访达中打开它


620
00:21:52,236 --> 00:21:56,000
对不起口误了 是一旦完成 导出


621
00:22:00,046 --> 00:22:01,686
所以在访达里


622
00:22:01,686 --> 00:22:03,316
我已经得到了 BreakfastModel.mlmodel


623
00:22:03,316 --> 00:22:05,636
当我在 Xcode 中打开它时


624
00:22:05,636 --> 00:22:07,106
它看起来就像


625
00:22:07,106 --> 00:22:08,306
任何 Core ML 模型


626
00:22:08,896 --> 00:22:12,176
它需要一个输入图像


627
00:22:12,176 --> 00:22:15,206
然后输出置信度和坐标


628
00:22:15,616 --> 00:22:16,706
这将告诉我们


629
00:22:16,706 --> 00:22:18,336
预测的边界框和


630
00:22:18,336 --> 00:22:19,436
图像的标签


631
00:22:20,376 --> 00:22:22,206
现在让我们切换到


632
00:22:22,246 --> 00:22:23,646
iPhone App


633
00:22:23,646 --> 00:22:24,616
我们要使用这个模型


634
00:22:25,186 --> 00:22:30,306
在我的 iPhone 上


635
00:22:30,306 --> 00:22:31,716
有一个名为 Food Predictor 的 App


636
00:22:32,356 --> 00:22:33,336
它使用的是


637
00:22:33,336 --> 00:22:34,456
我们刚刚训练的模型


638
00:22:35,356 --> 00:22:37,096
在这里 我要选择 相片


639
00:22:37,416 --> 00:22:39,026
我有今天早上


640
00:22:39,026 --> 00:22:40,036
早餐的照片


641
00:22:40,546 --> 00:22:41,506
这是我非常典型的早餐


642
00:22:41,506 --> 00:22:43,326
包含咖啡和香蕉


643
00:22:43,796 --> 00:22:45,546
好吧 我经常不吃香蕉


644
00:22:46,316 --> 00:22:48,856
假设今天早上我吃了


645
00:22:48,856 --> 00:22:49,346
一根香蕉吧


646
00:22:50,456 --> 00:22:53,796
我们可以直接点击图像


647
00:22:53,796 --> 00:22:54,976
因为我们看到了边界框


648
00:22:54,976 --> 00:22:58,386
我们可以识别边界框内的对象


649
00:22:58,386 --> 00:22:59,716
我们看到模型告诉我们


650
00:22:59,716 --> 00:23:02,976
这是一根香蕉 这是一杯咖啡


651
00:23:03,516 --> 00:23:09,500
[ 掌声 ]


652
00:23:16,136 --> 00:23:17,886
所以让我们回顾一下刚刚的内容


653
00:23:19,886 --> 00:23:21,756
首先 我们以 SFrame 格式


654
00:23:21,756 --> 00:23:23,896
加载图像和注释


655
00:23:24,146 --> 00:23:25,626
并调用简单的函数


656
00:23:25,626 --> 00:23:26,556
把它们连接起来


657
00:23:27,296 --> 00:23:28,976
我们使用 .explore 方法


658
00:23:28,976 --> 00:23:30,786
交互式探索数据


659
00:23:31,826 --> 00:23:33,616
我们创建了一个模型


660
00:23:33,616 --> 00:23:35,606
仅仅是通过简单的高级 API 


661
00:23:35,606 --> 00:23:37,286
传入包含图像


662
00:23:37,286 --> 00:23:39,936
边界框和标签的数据对象


663
00:23:40,906 --> 00:23:42,676
然后我们评估了这个模型


664
00:23:42,836 --> 00:23:43,956
既进行了量化评估


665
00:23:44,026 --> 00:23:45,596
又进行了模仿人类的


666
00:23:45,596 --> 00:23:46,176
抽样输出检查


667
00:23:46,556 --> 00:23:48,566
并得出了一个


668
00:23:48,566 --> 00:23:50,486
适用于所做任务的


669
00:23:50,486 --> 00:23:51,526
量化衡量标准


670
00:23:52,326 --> 00:23:54,206
然后我们将该模型导出为


671
00:23:54,206 --> 00:23:58,446
Core ML 格式 在 App 中使用


672
00:23:58,726 --> 00:24:00,306
接下来 我想换个话题


673
00:24:00,576 --> 00:24:01,976
谈论 Turi Create 5.0 的


674
00:24:01,976 --> 00:24:04,836
一些令人兴奋的新功能


675
00:24:06,776 --> 00:24:09,806
Turi Create 5.0 推出了一项新任务


676
00:24:10,076 --> 00:24:11,186
叫做风格转移


677
00:24:12,556 --> 00:24:13,716
我们对 Mac 上的


678
00:24:13,716 --> 00:24:16,126
本地 GPU 加速


679
00:24:16,126 --> 00:24:18,166
做了重大性能优化


680
00:24:19,016 --> 00:24:20,626
我们提供了新的部署选项


681
00:24:20,626 --> 00:24:24,626
包括个性化推荐模型


682
00:24:24,676 --> 00:24:25,956
和基于视觉特征提取的模型


683
00:24:25,956 --> 00:24:27,466
帮助你00:24:27,466 --> 00:24:29,956利用已存在于操作系统的模型


684
00:24:29,956 --> 00:24:31,386
减少 App 的大小


685
00:24:31,906 --> 00:24:34,696
让我们再谈谈


686
00:24:34,696 --> 00:24:36,176
风格转移任务


687
00:24:37,116 --> 00:24:39,186
想象一下 我们有一些风格图像


688
00:24:39,186 --> 00:24:41,296
它们真的很酷


689
00:24:41,296 --> 00:24:44,376
是辨识度很强的风格化图片


690
00:24:45,016 --> 00:24:46,826
在这里 我们已经有一个


691
00:24:46,826 --> 00:24:48,156
浅色的蜂巢图案


692
00:24:48,156 --> 00:24:49,426
和一个非常鲜艳的花卉图案


693
00:24:49,666 --> 00:24:51,406
我们希望将这些滤镜应用于


694
00:24:51,406 --> 00:24:53,416
我们自己用相机


695
00:24:53,416 --> 00:24:54,246
拍摄的图像


696
00:24:54,836 --> 00:24:57,846
这里有一张小狗的照片


697
00:24:57,896 --> 00:25:01,496
应用两种风格后的图片00:25:01,496 --> 00:25:02,236分别是这样的


698
00:25:02,586 --> 00:25:05,006
使用风格转移模型 


699
00:25:05,196 --> 00:25:06,956
我们可以将相同的风格


700
00:25:06,956 --> 00:25:08,296
应用于更多照片


701
00:25:08,646 --> 00:25:10,246
这里有一只猫和另一只狗的照片


702
00:25:10,916 --> 00:25:13,000
这就是得到的效果


703
00:25:16,046 --> 00:25:17,566
这是一个例子


704
00:25:17,566 --> 00:25:19,646
这个 App 使用风格转移


705
00:25:19,816 --> 00:25:21,946
为用户照片添加滤镜


706
00:25:24,556 --> 00:25:26,526
创建风格转移模型的代码


707
00:25:26,526 --> 00:25:28,386
同样遵循


708
00:25:28,516 --> 00:25:30,466
五步方法 就像其他


709
00:25:30,466 --> 00:25:32,046
Turi Create 高级任务一样


710
00:25:32,296 --> 00:25:33,956
所以你可以从导入


711
00:25:33,956 --> 00:25:36,076
Turi Create 开始


712
00:25:36,076 --> 00:25:38,166
将数据加载为 SFrame 格式


713
00:25:38,166 --> 00:25:40,176
并使用一个简单的高级 API 创建模型


714
00:25:41,326 --> 00:25:42,906
然后做出预测


715
00:25:42,906 --> 00:25:44,166
在本例中


716
00:25:44,166 --> 00:25:46,186
使用 .stylize 函数


717
00:25:46,186 --> 00:25:47,536
在图像上应用风格滤镜


718
00:25:48,166 --> 00:25:49,746
最后 我们可以导出它


719
00:25:49,746 --> 00:25:51,576
部署为 Core ML 格式 


720
00:25:51,576 --> 00:25:53,000
就像 Turi Create 中的其他模型一样


721
00:25:56,266 --> 00:25:57,926
我们来看看另一个演示


722
00:25:58,146 --> 00:26:00,106
这一次 我们要构建


723
00:26:00,106 --> 00:26:02,000
风格转移模型


724
00:26:14,476 --> 00:26:15,926
所以切换回


725
00:26:15,926 --> 00:26:17,196
Jupyter Notebook 环境


726
00:26:17,546 --> 00:26:19,386
我将再次从


727
00:26:19,386 --> 00:26:25,000
导入 Turi Create 作为 tc 开始


728
00:26:29,056 --> 00:26:30,556
然后 我要加载两个 SFrame


729
00:26:30,556 --> 00:26:32,836
每个都包含图像


730
00:26:33,276 --> 00:26:35,236
一个是风格图像


731
00:26:35,236 --> 00:26:36,766
调用 tc.loadimages


732
00:26:36,766 --> 00:26:38,416
并传入目录名称 style


733
00:26:39,106 --> 00:26:41,466
另一个是内容图像


734
00:26:42,956 --> 00:26:44,226
模型的工作方式是


735
00:26:44,266 --> 00:26:46,106
风格图像是


736
00:26:46,106 --> 00:26:47,236
你想变成的


737
00:26:47,236 --> 00:26:48,376
可应用的滤镜风格


738
00:26:48,376 --> 00:26:50,586
内容图像可以是


739
00:26:50,686 --> 00:26:51,596
任何你想要


740
00:26:51,596 --> 00:26:53,286
应用此类滤镜的


741
00:26:53,286 --> 00:26:55,836
照片类型的代表


742
00:26:56,266 --> 00:26:57,596
所以在这种情况下


743
00:26:57,596 --> 00:26:58,896
可以是各种各样的照片


744
00:26:59,796 --> 00:27:01,776
我们将 content 文件夹


745
00:27:01,776 --> 00:27:03,546
加载到这个


746
00:27:03,546 --> 00:27:04,146
SFrame 中


747
00:27:05,226 --> 00:27:07,556
然后我们继续训练模型


748
00:27:08,386 --> 00:27:10,276
我将模型赋值为


749
00:27:10,846 --> 00:27:13,366
tc.styletransfer.create


750
00:27:13,786 --> 00:27:15,986
然后传入 style 和 content


751
00:27:16,226 --> 00:27:19,116
这就是所有内容


752
00:27:19,486 --> 00:27:21,096
但是今天这个演示


753
00:27:21,096 --> 00:27:22,806
需要的训练时间较长


754
00:27:23,276 --> 00:27:24,796
所以我要再一次


755
00:27:24,796 --> 00:27:25,746
像烹饪节目那样


756
00:27:25,746 --> 00:27:27,766
加载烤箱里完成的成品


757
00:27:28,526 --> 00:27:29,936
我将 model 赋值为


758
00:27:29,936 --> 00:27:32,426
tc.loadmodel


759
00:27:32,426 --> 00:27:35,296
加载已经训练好的风格转移模型


760
00:27:35,826 --> 00:27:38,546
我们来看看


761
00:27:38,546 --> 00:27:40,026
一些风格图像


762
00:27:40,026 --> 00:27:41,876
看看这个模型应该输出什么


763
00:27:42,876 --> 00:27:46,476
我们的 style SFrame 中


764
00:27:46,476 --> 00:27:47,336
有一个 image 列


765
00:27:47,746 --> 00:27:49,026
先来看看


766
00:27:49,026 --> 00:27:50,946
三号样式是什么


767
00:27:51,796 --> 00:27:54,056
有点像一堆柴火


768
00:27:54,416 --> 00:27:57,036
这很风格化


769
00:27:57,266 --> 00:27:59,626
如果我们将它作为滤镜应用到另一个图像上


770
00:27:59,626 --> 00:28:01,326
我认为应该很有辨识度


771
00:28:02,676 --> 00:28:04,666
现在我们来看看一些


772
00:28:04,666 --> 00:28:05,566
内容图像


773
00:28:06,016 --> 00:28:07,916
我要加载一个测试数据集


774
00:28:08,126 --> 00:28:10,566
再次重申 这个数据集


775
00:28:10,566 --> 00:28:13,936
代表着用户将在 App 运行时


776
00:28:13,936 --> 00:28:15,326
提供的图像类型


777
00:28:15,776 --> 00:28:18,606
重点是 该模型将这些图像


778
00:28:18,606 --> 00:28:19,346
用作训练材料


779
00:28:19,656 --> 00:28:21,366
所以通过评估测试图像的结果


780
00:28:21,366 --> 00:28:22,836
我们就会知道该模型


781
00:28:22,836 --> 00:28:25,096
是否可以推广到用户数据 


782
00:28:26,206 --> 00:28:28,636
我现在再一次使用


783
00:28:29,166 --> 00:28:30,496
tc.loadimages 函数


784
00:28:30,606 --> 00:28:33,086
加载测试数据集


785
00:28:33,656 --> 00:28:34,906
我们将 test 文件夹


786
00:28:34,906 --> 00:28:36,006
作为参数传入


787
00:28:37,046 --> 00:28:38,406
现在我要将测试数据集中的


788
00:28:38,406 --> 00:28:39,696
一张图像当做样本


789
00:28:39,696 --> 00:28:40,736
设为 sample_image


790
00:28:41,216 --> 00:28:44,576
就选第一张图像吧


791
00:28:45,156 --> 00:28:48,016
我将调用 .show


792
00:28:48,016 --> 00:28:51,446
所以我们可以看到


793
00:28:51,446 --> 00:28:52,526
没有应用任何滤镜的情况下


794
00:28:52,526 --> 00:28:53,256
图像是什么样子的


795
00:28:54,016 --> 00:28:58,216
那是我的猫 九只猫中的老七


796
00:28:59,046 --> 00:29:02,306
它总是这个样子


797
00:29:02,306 --> 00:29:04,546
我们将继续


798
00:29:04,546 --> 00:29:06,096
使用刚刚训练的模型


799
00:29:06,096 --> 00:29:07,036
风格化该图像


800
00:29:08,516 --> 00:29:10,526
所以我要将 stylized_image


801
00:29:10,526 --> 00:29:13,236
赋值为 model.stylize


802
00:29:13,956 --> 00:29:15,876
这个例子中


803
00:29:15,876 --> 00:29:17,486
函数名为 .stylize


804
00:29:17,486 --> 00:29:19,386
因为该模型是针对


805
00:29:19,386 --> 00:29:20,186
风格转移任务的


806
00:29:20,416 --> 00:29:23,606
我们输入 sample_image


807
00:29:23,956 --> 00:29:25,416
我要将 style 赋值为 3


808
00:29:25,416 --> 00:29:27,206
因为这是


809
00:29:27,206 --> 00:29:28,956
我们之前选择的风格


810
00:29:28,956 --> 00:29:30,146
看起来像柴火的那张


811
00:29:32,116 --> 00:29:34,656
所以让我们看看 stylized_image 是什么样的


812
00:29:35,196 --> 00:29:38,646
我来调用 .show


813
00:29:38,646 --> 00:29:40,746
这张图像中 我的猫看起来像一堆柴火


814
00:29:41,516 --> 00:29:46,426
[ 掌声 ]


815
00:29:46,926 --> 00:29:48,376
让我们确保


816
00:29:48,376 --> 00:29:49,256
其他风格也一样奏效


817
00:29:49,946 --> 00:29:52,336
我要继续


818
00:29:52,336 --> 00:29:58,496
基于样本图像


819
00:29:58,496 --> 00:29:59,256
制作风格化图像


820
00:29:59,576 --> 00:30:02,966
我将 style 赋值为 7


821
00:30:03,556 --> 00:30:05,986
然后让我们看看


822
00:30:05,986 --> 00:30:07,000
图片是什么样子


823
00:30:13,056 --> 00:30:13,896
看上去很好


824
00:30:13,896 --> 00:30:15,236
我想知道刚刚应用的


825
00:30:15,236 --> 00:30:16,236
是什么风格


826
00:30:16,716 --> 00:30:18,496
让我们来看看


827
00:30:20,826 --> 00:30:21,000
风格图像


828
00:30:25,306 --> 00:30:26,516
七号风格图像


829
00:30:27,046 --> 00:30:30,066
我们可以再次调用


830
00:30:30,066 --> 00:30:31,436
.show 看看风格图像


831
00:30:31,436 --> 00:30:33,496
是什么样子的


832
00:30:33,496 --> 00:30:35,746
它看上去很像 刚刚用于猫的滤镜


833
00:30:36,426 --> 00:30:38,696
现在我们已经有了一个


834
00:30:38,696 --> 00:30:40,886
很好的风格转移模型


835
00:30:41,216 --> 00:30:43,716
我们可以调用 model.exportcoreml


836
00:30:43,716 --> 00:30:45,206
就像对其他模型一样 


837
00:30:45,206 --> 00:30:47,000
将其保存为 Core ML 格式


838
00:30:52,296 --> 00:30:55,436
现在 让我们切换到 iPhone


839
00:30:55,436 --> 00:30:57,306
里面有一个风格转移 App 


840
00:30:57,306 --> 00:30:58,306
可以使用该模型中的滤镜


841
00:30:58,886 --> 00:31:03,726
我又拿出了我的 iPhone


842
00:31:03,726 --> 00:31:05,936
这里有一个 App 叫做 StyleTransfer


843
00:31:06,696 --> 00:31:08,066
我要从我的照片库中


844
00:31:08,066 --> 00:31:09,946
选择一张照片


845
00:31:09,946 --> 00:31:11,256
来应用这些样式


846
00:31:11,796 --> 00:31:13,846
这些是我的狗


847
00:31:16,136 --> 00:31:19,696
这是 Ryker 


848
00:31:19,696 --> 00:31:20,656
看看 App 中


849
00:31:20,656 --> 00:31:21,696
有什么样的风格可用


850
00:31:22,206 --> 00:31:23,706
我们可以滚动浏览所有的风格


851
00:31:23,706 --> 00:31:26,126
需要注意的是


852
00:31:26,126 --> 00:31:27,766
这些图像文件


853
00:31:27,766 --> 00:31:29,596
被用于训练一个


854
00:31:29,596 --> 00:31:30,636
风格转移模型


855
00:31:30,976 --> 00:31:32,836
一个模型可以包含


856
00:31:32,836 --> 00:31:33,676
任意数量的样式


857
00:31:34,126 --> 00:31:35,636
所以你可以拥有多个滤镜


858
00:31:35,636 --> 00:31:37,116
而无需大大增加


859
00:31:37,166 --> 00:31:37,976
你 App 的大小


860
00:31:39,156 --> 00:31:40,376
让我们看看这些风格


861
00:31:40,376 --> 00:31:43,036
应用到 Ryker 身上是怎样的


862
00:31:43,716 --> 00:31:46,000
很酷


863
00:31:52,646 --> 00:31:52,976
所以


864
00:31:53,516 --> 00:31:58,316
[ 掌声 ]


865
00:31:58,816 --> 00:32:01,266
回顾一下我们刚刚看到的


866
00:32:01,266 --> 00:32:03,336
我们将图像加载到 SFrame 格式


867
00:32:03,646 --> 00:32:05,576
这个例子中的风格图像和内容图像


868
00:32:05,576 --> 00:32:07,346
被分成两个 SFrame


869
00:32:07,836 --> 00:32:09,656
我们使用高级 API


870
00:32:09,656 --> 00:32:10,966
创建了一个


871
00:32:10,966 --> 00:32:12,816
风格转移模型


872
00:32:12,946 --> 00:32:14,576
它可以直接运行于一组风格图像


873
00:32:14,576 --> 00:32:15,646
和一组内容图像上


874
00:32:16,436 --> 00:32:18,956
然后 我们将图片风格化


875
00:32:19,256 --> 00:32:20,836
以检查该模型是否正确运行


876
00:32:21,356 --> 00:32:22,876
我们在 Turi Create


877
00:32:22,876 --> 00:32:23,706
将预测可视化


878
00:32:24,226 --> 00:32:25,686
最后我们导出了


879
00:32:25,686 --> 00:32:27,566
Core ML 格式的模型


880
00:32:27,566 --> 00:32:29,996
在 App 中使用


881
00:32:30,636 --> 00:32:31,566
换一个话题


882
00:32:31,616 --> 00:32:32,656
我想谈谈 Turi Create 5.0 中的


883
00:32:32,656 --> 00:32:34,336
其他一些功能


884
00:32:35,066 --> 00:32:37,186
我们现在有 Mac GPU 加速00:32:37,536 --> 00:32:39,626在图像分类上


885
00:32:39,626 --> 00:32:41,586
达到了高达 12 倍的性能提升


886
00:32:41,756 --> 00:32:43,966
对象检测提升了 9 倍


887
00:32:43,966 --> 00:32:45,226
这都是在 iMac Pro 上做到的


888
00:32:46,516 --> 00:32:50,586
[ 掌声 ]


889
00:32:51,086 --> 00:32:53,096
我们还有一个可用的新任务


890
00:32:53,096 --> 00:32:54,616
可供导出为 Core ML 格式


891
00:32:54,876 --> 00:32:55,776
就是个性化


892
00:32:56,466 --> 00:32:58,096
这个任务是基于


893
00:32:58,096 --> 00:33:00,496
用户的历史偏好


894
00:33:00,496 --> 00:33:01,686
为用户推荐项目


895
00:33:02,896 --> 00:33:04,636
这种类型的模型部署


896
00:33:04,636 --> 00:33:06,506
需使用 Core ML 的新自定义模型支持


897
00:33:06,506 --> 00:33:08,586
该支持在 macOS Mojave


898
00:33:08,586 --> 00:33:11,026
和 iOS 12 上可用


899
00:33:11,686 --> 00:33:12,966
这是在 Turi Create 开源后


900
00:33:12,966 --> 00:33:14,576
呼声最高的


901
00:33:14,576 --> 00:33:15,546
社区功能请求


902
00:33:15,806 --> 00:33:16,956
所以我很高兴


903
00:33:16,956 --> 00:33:17,576
今天向你们介绍它


904
00:33:18,516 --> 00:33:23,546
[ 掌声 ]


905
00:33:24,046 --> 00:33:25,846
Core ML 中的推荐模型


906
00:33:26,076 --> 00:33:27,956
看起来就和任何其他 Core ML 模型一样


907
00:33:28,266 --> 00:33:29,656
但值得注意的是


908
00:33:29,656 --> 00:33:30,876
底部有一个部分


909
00:33:30,876 --> 00:33:32,496
称为 Dependencies


910
00:33:33,046 --> 00:33:34,416
这一部分中 你可以看到


911
00:33:34,416 --> 00:33:36,156
该模型使用了叫做


912
00:33:36,156 --> 00:33:37,986
TCRecommender 的


913
00:33:37,986 --> 00:33:39,006
自定义模型


914
00:33:39,506 --> 00:33:40,886
这是 Turi Create


915
00:33:41,036 --> 00:33:42,056
通过自定义模型 API 提供的


916
00:33:42,056 --> 00:33:45,346
对 Core ML 中 Recommender 的 支持


917
00:33:46,016 --> 00:33:49,476
在 Core ML 中使用该模型


918
00:33:49,536 --> 00:33:51,776
与使用任何其他 Core ML 模型 非常相似


919
00:33:52,316 --> 00:33:53,506
你可以将模型实例化


920
00:33:53,506 --> 00:33:55,696
创建你的输入


921
00:33:55,776 --> 00:33:57,696
在这个例子中


922
00:33:57,696 --> 00:33:59,046
我们有一个头像创建 App


923
00:33:59,386 --> 00:34:01,066
用户可能选择了


924
00:34:01,066 --> 00:34:02,626
棕色胡须 棕色八字胡


925
00:34:02,626 --> 00:34:04,276
和棕色长头发


926
00:34:04,276 --> 00:34:05,966
作为头像


927
00:34:06,346 --> 00:34:08,426
我们可以把这些交互 作为输入


928
00:34:08,626 --> 00:34:10,886
让模型进行预测


929
00:34:11,315 --> 00:34:13,416
从而得出


930
00:34:13,416 --> 00:34:14,996
基于这些输入的 k10 


931
00:34:15,346 --> 00:34:16,426
也就是排名前十的预测


932
00:34:17,045 --> 00:34:21,116
回顾一下我们今天学到的内容


933
00:34:22,286 --> 00:34:24,255
Turi Create 允许你创建


934
00:34:24,255 --> 00:34:26,196
Core ML 模型


935
00:34:26,196 --> 00:34:27,755
用来在你的 App 中


936
00:34:27,985 --> 00:34:28,286
提供智能功能


937
00:34:28,606 --> 00:34:30,775
通过五个简单的步骤就可以完成


938
00:34:30,775 --> 00:34:34,275
首先是确认你正在做的任务


939
00:34:34,485 --> 00:34:36,496
并将其映射至一个机器学习任务


940
00:34:37,025 --> 00:34:39,045
收集和注释用于


941
00:34:39,226 --> 00:34:41,126
训练该模型的数据


942
00:34:42,146 --> 00:34:43,946
使用一个针对任务的


943
00:34:43,946 --> 00:34:47,505
简单的高级 API 来训练模型


944
00:34:48,466 --> 00:34:50,235
在 Turi Create 中对模型


945
00:34:50,235 --> 00:34:52,826
进行定量和定性评估


946
00:34:53,366 --> 00:34:56,406
最后 部署到 Core ML 格式


947
00:34:58,936 --> 00:35:01,196
这五个步骤可以映射到代码编写


948
00:35:01,196 --> 00:35:03,646
首先是导入 Turi Create


949
00:35:04,406 --> 00:35:06,526
你可以将数据加载到 SFrame 格式


950
00:35:07,026 --> 00:35:08,566
使用针对任务的 API 


951
00:35:08,596 --> 00:35:10,026
创建一个模型


952
00:35:11,126 --> 00:35:12,726
使用针对任务的


953
00:35:12,726 --> 00:35:14,076
评估函数


954
00:35:14,076 --> 00:35:16,086
对模型进行评估


955
00:35:16,646 --> 00:35:18,096
最后调用 export_coreml 函数


956
00:35:18,356 --> 00:35:20,066
导出模型进行部署


957
00:35:20,536 --> 00:35:23,576
Turi Create 支持类型多样的


958
00:35:23,576 --> 00:35:25,296
机器学习任务


959
00:35:25,736 --> 00:35:27,196
从高层次的


960
00:35:27,196 --> 00:35:29,286
图像分类和


961
00:35:29,286 --> 00:35:31,296
文本分类


962
00:35:31,296 --> 00:35:32,896
到低级别的


963
00:35:32,896 --> 00:35:33,436
机器学习基础


964
00:35:33,436 --> 00:35:34,186
如任何数据类型的


965
00:35:34,186 --> 00:35:36,246
回归和分类


966
00:35:38,006 --> 00:35:39,806
你可以使用制作的模型 


967
00:35:40,106 --> 00:35:42,986
为你的 App 添加智能功能


968
00:35:42,986 --> 00:35:45,036
比如对象检测


969
00:35:45,036 --> 00:35:47,196
或作为滤镜使用的风格转移


970
00:35:48,216 --> 00:35:50,306
更多有关信息 请参见


971
00:35:50,306 --> 00:35:52,606
developer.apple.com 


972
00:35:52,806 --> 00:35:53,306
会议网址


973
00:35:53,716 --> 00:35:55,316
欢迎我们的实验室


974
00:35:55,316 --> 00:35:56,736
今天下午和周五下午


975
00:35:56,886 --> 00:35:58,056
各有一个活动日程


976
00:35:58,306 --> 00:35:59,726
我们欢迎你的反馈


977
00:36:00,096 --> 00:36:02,126
并且很高兴回答大家的任何问题


978
00:36:02,386 --> 00:36:04,136
今天所有的演示


979
00:36:04,136 --> 00:36:06,376
都可以在实验室中 供大家探索


980
00:36:07,186 --> 00:36:07,506
谢谢 


981
00:36:08,516 --> 00:36:11,500
[ 掌声 ]

