1
00:00:00,506 --> 00:00:05,500
[ Music ]


2
00:00:10,976 --> 00:00:12,336
[ Applause ]


3
00:00:12,336 --> 00:00:12,786
>> Good morning.


4
00:00:14,756 --> 00:00:15,836
Welcome to our session on


5
00:00:15,836 --> 00:00:17,266
Drawing Classification and


6
00:00:17,266 --> 00:00:18,686
One-Shot Object Detection in


7
00:00:18,686 --> 00:00:19,276
Turi Create.


8
00:00:19,956 --> 00:00:21,416
My name is Sam and I'll be


9
00:00:21,416 --> 00:00:22,406
joined by my colleagues,


10
00:00:22,536 --> 00:00:24,306
Shantanu and Abhishek to talk to


11
00:00:24,306 --> 00:00:25,166
you about what we've been


12
00:00:25,166 --> 00:00:27,036
building to enable even richer


13
00:00:27,036 --> 00:00:29,836
experiences in your apps.


14
00:00:29,986 --> 00:00:30,746
Let's dive right in.


15
00:00:32,206 --> 00:00:34,746
First, a quick refresher on Turi


16
00:00:34,746 --> 00:00:35,546
Create itself.


17
00:00:36,646 --> 00:00:38,656
Turi Create is a Python library


18
00:00:38,986 --> 00:00:40,316
used for creating Core ML


19
00:00:40,316 --> 00:00:40,846
models.


20
00:00:41,406 --> 00:00:44,286
It has a simple, easy to use


21
00:00:44,476 --> 00:00:45,826
task-oriented API.


22
00:00:46,966 --> 00:00:49,136
Now, tasks are our term for a


23
00:00:49,136 --> 00:00:50,756
collection of complex, machine


24
00:00:50,756 --> 00:00:52,606
learning algorithms abstracted


25
00:00:52,606 --> 00:00:55,056
away into a simple, easy to use


26
00:00:55,056 --> 00:00:56,586
solution for you to build your


27
00:00:56,586 --> 00:00:57,066
models.


28
00:00:57,616 --> 00:01:00,326
It's cross-platform, working on


29
00:01:00,326 --> 00:01:02,966
both Mac OS and Linux and we're


30
00:01:02,966 --> 00:01:04,296
extremely proud to be open


31
00:01:04,355 --> 00:01:05,936
source, working closely with our


32
00:01:05,936 --> 00:01:08,286
community on features and fixes.


33
00:01:08,896 --> 00:01:12,246
We built Turi Create to enable


34
00:01:12,246 --> 00:01:14,596
you to create Core ML models for


35
00:01:14,596 --> 00:01:16,416
your intelligent applications.


36
00:01:17,646 --> 00:01:19,946
Now to build these models, we


37
00:01:19,946 --> 00:01:21,286
integrate with a various of


38
00:01:21,286 --> 00:01:22,956
system frameworks, accepting


39
00:01:22,956 --> 00:01:25,276
data from frameworks like


40
00:01:25,366 --> 00:01:26,976
PencilKit and Core Motion.


41
00:01:28,496 --> 00:01:30,476
Once we've built our model, we


42
00:01:30,476 --> 00:01:31,756
integrate with other system


43
00:01:31,756 --> 00:01:34,676
frameworks like Vision and Sound


44
00:01:34,676 --> 00:01:36,526
Analysis to create extremely


45
00:01:36,526 --> 00:01:38,196
compelling app experiences.


46
00:01:39,956 --> 00:01:41,696
So say you'd want to build an


47
00:01:41,696 --> 00:01:43,776
application used to classify


48
00:01:43,976 --> 00:01:44,916
musical instruments.


49
00:01:45,066 --> 00:01:47,066
[ Guitar Sound ]


50
00:01:47,156 --> 00:01:49,156
Using microphone data, you can


51
00:01:49,156 --> 00:01:50,576
understand what instrument is


52
00:01:50,676 --> 00:01:53,476
being played and attempt to tune


53
00:01:54,096 --> 00:01:55,176
the instrument.


54
00:01:55,176 --> 00:01:57,036
Or say you'd want to use raw


55
00:01:57,066 --> 00:01:58,876
sensor data from the Apple Watch


56
00:01:59,276 --> 00:02:01,096
to detect what activities a user


57
00:02:01,096 --> 00:02:04,966
may be performing in the gym.


58
00:02:05,166 --> 00:02:07,466
Or say you'd want to use image


59
00:02:07,466 --> 00:02:09,996
data to be able to detect what


60
00:02:09,996 --> 00:02:12,006
ingredients a user may be


61
00:02:12,006 --> 00:02:13,996
holding and to suggest recipes


62
00:02:14,326 --> 00:02:15,636
using these ingredients.


63
00:02:16,096 --> 00:02:18,476
All of these are possible


64
00:02:18,916 --> 00:02:20,256
because we have built an


65
00:02:20,256 --> 00:02:22,126
intelligent Core ML model.


66
00:02:23,196 --> 00:02:25,396
And to build these models, we've


67
00:02:25,396 --> 00:02:27,476
identified a five-step pipeline


68
00:02:27,616 --> 00:02:28,116
to do so.


69
00:02:29,276 --> 00:02:31,246
First up in our pipeline, we


70
00:02:31,246 --> 00:02:32,946
need to identify the task or


71
00:02:32,946 --> 00:02:34,166
what problem it is that we're


72
00:02:34,166 --> 00:02:34,926
trying to solve.


73
00:02:35,476 --> 00:02:38,746
Next, we need to collect data


74
00:02:38,746 --> 00:02:41,246
and sometimes, lots of it.


75
00:02:42,136 --> 00:02:44,506
After that, we train our model.


76
00:02:46,316 --> 00:02:48,656
Next, we evaluate our model,


77
00:02:49,036 --> 00:02:50,386
attempting to understand the


78
00:02:50,436 --> 00:02:51,516
real-world performance


79
00:02:51,516 --> 00:02:52,776
characteristics and to


80
00:02:52,776 --> 00:02:54,356
potentially offer corrections.


81
00:02:56,726 --> 00:02:58,866
After that, we deploy our model


82
00:02:59,116 --> 00:03:01,376
for use within Core ML and your


83
00:03:01,376 --> 00:03:01,976
application.


84
00:03:03,436 --> 00:03:04,806
Now let's take a look at these


85
00:03:04,806 --> 00:03:06,966
five steps in code.


86
00:03:07,816 --> 00:03:11,606
After we import turicreate we


87
00:03:11,606 --> 00:03:14,006
load our data from an SFrame on


88
00:03:14,966 --> 00:03:15,126
disk.


89
00:03:15,126 --> 00:03:16,366
An SFrame is something that


90
00:03:16,366 --> 00:03:17,986
Shantanu will cover in a little


91
00:03:18,646 --> 00:03:18,746
bit.


92
00:03:19,816 --> 00:03:23,036
After this, we split our data


93
00:03:23,036 --> 00:03:25,036
into two sets, one used for


94
00:03:25,036 --> 00:03:26,476
testing and one used for


95
00:03:26,476 --> 00:03:27,426
training our model.


96
00:03:28,966 --> 00:03:31,606
Next, we create our model with


97
00:03:31,606 --> 00:03:33,486
just a single line of code for


98
00:03:33,486 --> 00:03:34,866
running complicated machine


99
00:03:34,866 --> 00:03:35,756
learning algorithms.


100
00:03:38,536 --> 00:03:40,686
Next, we gather metrics as to


101
00:03:40,686 --> 00:03:42,206
the performance of this model.


102
00:03:42,246 --> 00:03:46,536
And finally, we save it to disk


103
00:03:46,636 --> 00:03:49,336
for use within XCode and your


104
00:03:49,646 --> 00:03:50,286
app.


105
00:03:51,366 --> 00:03:53,366
Now we think one of the great


106
00:03:53,366 --> 00:03:55,056
things about Turi Create is its


107
00:03:55,056 --> 00:03:56,716
simple and consistent API.


108
00:03:57,726 --> 00:03:58,536
So no matter whether you're


109
00:03:58,536 --> 00:04:01,446
using an object detector, a


110
00:04:01,446 --> 00:04:04,146
sound classifier, an activity


111
00:04:04,146 --> 00:04:06,096
classifier, or any of our other


112
00:04:06,096 --> 00:04:08,006
tasks, the API remains


113
00:04:08,036 --> 00:04:11,516
consistent and easy to use.


114
00:04:11,716 --> 00:04:13,246
Now I've mentioned these tasks


115
00:04:13,296 --> 00:04:15,066
multiple times and I'd like to


116
00:04:15,116 --> 00:04:16,375
cover the full collection that


117
00:04:16,375 --> 00:04:17,456
Turi Create offers.


118
00:04:17,606 --> 00:04:21,076
We offer tasks that work with


119
00:04:21,185 --> 00:04:25,646
images and sound as well as user


120
00:04:25,646 --> 00:04:29,636
activities and text.


121
00:04:29,796 --> 00:04:31,266
We offer tasks that work with


122
00:04:31,316 --> 00:04:33,746
user preferences and numeric


123
00:04:33,746 --> 00:04:33,976
data.


124
00:04:34,506 --> 00:04:37,276
And today we're extremely


125
00:04:37,276 --> 00:04:39,106
excited to share with you two


126
00:04:39,106 --> 00:04:42,306
brand new tasks.


127
00:04:42,306 --> 00:04:44,446
First, we have our One-Shot


128
00:04:44,566 --> 00:04:45,786
Object Detection task.


129
00:04:46,356 --> 00:04:48,206
Now you may already be familiar


130
00:04:48,206 --> 00:04:49,266
with object detection.


131
00:04:50,626 --> 00:04:52,086
Object detection is the ability


132
00:04:52,086 --> 00:04:54,076
to detect the presence and


133
00:04:54,076 --> 00:04:56,156
location of specific objects


134
00:04:56,206 --> 00:04:56,886
within a frame.


135
00:04:58,176 --> 00:05:00,056
One-Shot Object Detection is a


136
00:05:00,056 --> 00:05:01,226
twist on this existing


137
00:05:01,226 --> 00:05:03,366
framework, which depending on


138
00:05:03,366 --> 00:05:04,806
the type of data that you're


139
00:05:04,806 --> 00:05:06,526
attempting to detect, can


140
00:05:06,526 --> 00:05:07,866
dramatically reduce the amount


141
00:05:07,866 --> 00:05:09,776
of data needed to train a model.


142
00:05:12,186 --> 00:05:13,516
Next, we have our Drawing


143
00:05:13,516 --> 00:05:14,616
Classification task.


144
00:05:15,656 --> 00:05:18,056
Using user input in the form of


145
00:05:18,056 --> 00:05:20,816
a finger on screen or the Apple


146
00:05:20,816 --> 00:05:23,616
Pencil, you can now attempt to


147
00:05:23,616 --> 00:05:25,636
classify and understand what


148
00:05:25,636 --> 00:05:27,496
your users have drawn into your


149
00:05:27,706 --> 00:05:28,446
app.


150
00:05:29,016 --> 00:05:31,436
Now I'd like to take a deep dive


151
00:05:31,576 --> 00:05:32,816
into the One-Shot Object


152
00:05:32,816 --> 00:05:34,426
Detection task.


153
00:05:35,036 --> 00:05:36,296
Say you'd want to build an


154
00:05:36,296 --> 00:05:38,936
application to take an image of


155
00:05:38,936 --> 00:05:40,316
a player's hand in a game of


156
00:05:40,356 --> 00:05:42,446
poker and to offer probabilities


157
00:05:42,486 --> 00:05:43,566
that this hand would occur.


158
00:05:45,246 --> 00:05:46,976
Or say you'd want to build an


159
00:05:46,976 --> 00:05:49,046
application to take a picture of


160
00:05:49,046 --> 00:05:50,386
your car's dashboard and to


161
00:05:50,386 --> 00:05:52,156
attempt to understand what those


162
00:05:52,156 --> 00:05:53,566
obscure icons may mean.


163
00:05:54,176 --> 00:05:56,796
Or say you'd want to build an


164
00:05:56,796 --> 00:05:58,946
app to detect company logos to


165
00:05:58,946 --> 00:06:00,426
provide your users with more


166
00:06:00,426 --> 00:06:02,396
information about this company.


167
00:06:03,516 --> 00:06:04,686
What do all three of these


168
00:06:04,686 --> 00:06:06,146
applications have in common?


169
00:06:07,106 --> 00:06:09,606
They're all trying to detect 2D


170
00:06:09,976 --> 00:06:11,186
regular images.


171
00:06:12,616 --> 00:06:14,356
One-Shot Object Detection is


172
00:06:14,356 --> 00:06:15,776
able to take advantage of these


173
00:06:15,776 --> 00:06:17,606
characteristics of regularity


174
00:06:17,606 --> 00:06:19,666
and consistency to dramatically


175
00:06:19,666 --> 00:06:21,536
reduce the amount of data needed


176
00:06:21,536 --> 00:06:22,706
to build an accurate model.


177
00:06:23,916 --> 00:06:25,586
So let's use this card counting


178
00:06:25,586 --> 00:06:27,076
app, which Shantanu will build


179
00:06:27,076 --> 00:06:28,886
for us in just a minute, as a


180
00:06:28,886 --> 00:06:30,766
case study into how this works.


181
00:06:32,626 --> 00:06:34,856
Originally in order to build an


182
00:06:34,856 --> 00:06:36,736
object detection model, you


183
00:06:36,736 --> 00:06:38,226
would need to collect vast


184
00:06:38,226 --> 00:06:39,986
amounts of data of your object


185
00:06:40,036 --> 00:06:40,846
in the real world.


186
00:06:41,456 --> 00:06:44,566
In addition to this, you would


187
00:06:44,566 --> 00:06:46,246
also need to annotate each of


188
00:06:46,246 --> 00:06:48,066
these images with the location


189
00:06:48,066 --> 00:06:50,586
in the frame of your image.


190
00:06:51,136 --> 00:06:53,646
As you can see, this is an


191
00:06:53,646 --> 00:06:55,556
incredibly data intensive and


192
00:06:55,556 --> 00:06:58,636
time-consuming task.


193
00:06:58,636 --> 00:07:00,916
So we built a better way.


194
00:07:02,416 --> 00:07:04,096
With One-Shot Object Detection,


195
00:07:04,366 --> 00:07:06,096
you now need as little as one


196
00:07:06,096 --> 00:07:07,966
image per class that you're


197
00:07:07,966 --> 00:07:08,896
attempting to detect.


198
00:07:09,806 --> 00:07:11,606
So instead of dozens of images


199
00:07:11,966 --> 00:07:14,046
of the Ace of Clubs, you now


200
00:07:14,046 --> 00:07:16,036
need a single image in order to


201
00:07:16,036 --> 00:07:17,686
build a reliable and accurate


202
00:07:17,686 --> 00:07:17,976
model.


203
00:07:18,196 --> 00:07:20,196
[ Applause ]


204
00:07:20,376 --> 00:07:20,636
Thank you.


205
00:07:21,466 --> 00:07:23,466
[ Applause ]


206
00:07:23,916 --> 00:07:24,926
So let's talk about how this


207
00:07:24,926 --> 00:07:26,066
works behind the scenes.


208
00:07:26,966 --> 00:07:28,486
This works with a process called


209
00:07:28,486 --> 00:07:30,356
Synthetic Data Augmentation.


210
00:07:31,356 --> 00:07:32,566
Turi Create ships with a


211
00:07:32,606 --> 00:07:34,606
collection of images of the real


212
00:07:34,606 --> 00:07:34,976
world.


213
00:07:35,906 --> 00:07:37,806
We then take your source image


214
00:07:37,876 --> 00:07:39,566
that you have supplied and


215
00:07:39,566 --> 00:07:41,616
overlay onto these real-world


216
00:07:41,616 --> 00:07:43,676
images along with various color


217
00:07:43,676 --> 00:07:45,876
perturbations and distortions to


218
00:07:45,916 --> 00:07:47,736
simulate real world effects.


219
00:07:49,186 --> 00:07:50,686
In addition to this, there's


220
00:07:50,686 --> 00:07:52,846
absolutely no need to annotate


221
00:07:53,046 --> 00:07:54,916
these images as our algorithms


222
00:07:54,916 --> 00:07:56,456
do that for you automatically.


223
00:07:58,936 --> 00:08:01,276
Now One-Shot Object Detection


224
00:08:01,516 --> 00:08:03,256
works with 2D objects only.


225
00:08:04,076 --> 00:08:06,306
It requires very little data and


226
00:08:06,306 --> 00:08:08,026
absolutely no annotation.


227
00:08:08,846 --> 00:08:10,276
However, if you're wanting to


228
00:08:10,276 --> 00:08:12,316
detect an object that is


229
00:08:12,316 --> 00:08:14,036
potentially 3D or more


230
00:08:14,036 --> 00:08:15,876
irregular, you may be interested


231
00:08:15,876 --> 00:08:17,266
in our more traditional object


232
00:08:17,356 --> 00:08:18,176
detection framework.


233
00:08:18,686 --> 00:08:21,646
Now let's take a look at this in


234
00:08:21,646 --> 00:08:21,986
code.


235
00:08:22,886 --> 00:08:24,916
As you'd expect, our API is


236
00:08:24,916 --> 00:08:26,776
incredibly consistent with our


237
00:08:26,776 --> 00:08:29,286
other tasks using just a single


238
00:08:29,286 --> 00:08:31,286
line of code with our dot create


239
00:08:31,286 --> 00:08:33,346
method to train an incredibly


240
00:08:33,346 --> 00:08:34,066
accurate model.


241
00:08:34,066 --> 00:08:37,326
And now with code up on the


242
00:08:37,366 --> 00:08:38,866
screen, I'd like to invite my


243
00:08:38,866 --> 00:08:40,576
colleague, Shantanu to talk to


244
00:08:40,576 --> 00:08:42,296
you about our Three Card Poker


245
00:08:42,296 --> 00:08:43,166
App and to give you a


246
00:08:43,166 --> 00:08:44,566
demonstration of this in the


247
00:08:44,566 --> 00:08:45,086
real world.


248
00:08:45,166 --> 00:08:45,976
Shantanu.


249
00:08:46,516 --> 00:08:51,646
[ Applause ]


250
00:08:52,146 --> 00:08:52,746
>> Thanks Sam.


251
00:08:53,646 --> 00:08:54,606
Good morning everyone.


252
00:08:54,736 --> 00:08:58,276
Welcome to the last day of WWDC.


253
00:08:58,436 --> 00:09:02,336
Now I'm super excited to give


254
00:09:02,336 --> 00:09:03,466
you a first look into the


255
00:09:03,466 --> 00:09:04,836
One-Shot Object Detector.


256
00:09:05,966 --> 00:09:08,616
The thing is, Sam and I play a


257
00:09:08,616 --> 00:09:10,206
lot of three card poker at work.


258
00:09:11,106 --> 00:09:12,706
And to be honest, I'm getting a


259
00:09:12,706 --> 00:09:14,096
little too tired of winning all


260
00:09:14,096 --> 00:09:14,526
the time.


261
00:09:15,126 --> 00:09:17,276
So I thought, you know today on


262
00:09:17,276 --> 00:09:18,796
stage, why don't we build an app


263
00:09:19,046 --> 00:09:21,486
for Sam that helps him, that


264
00:09:21,486 --> 00:09:23,916
tells him what his hand is, and


265
00:09:23,916 --> 00:09:24,736
you know, helps him make a


266
00:09:24,736 --> 00:09:25,446
better decision.


267
00:09:26,356 --> 00:09:28,326
Now to build an app like that,


268
00:09:28,326 --> 00:09:30,126
we'd need a Core ML model that


269
00:09:30,126 --> 00:09:32,136
can detect all the cards in your


270
00:09:32,136 --> 00:09:32,696
playing deck.


271
00:09:33,536 --> 00:09:35,076
So why don't we just go ahead


272
00:09:35,076 --> 00:09:36,006
and write some code to build


273
00:09:36,006 --> 00:09:36,786
that?


274
00:09:37,406 --> 00:09:39,866
Okay, so here I have a blank


275
00:09:39,866 --> 00:09:41,146
Jupyter Notebook which is an


276
00:09:41,146 --> 00:09:42,756
interactive Python environment


277
00:09:42,756 --> 00:09:44,286
to write some code and


278
00:09:44,286 --> 00:09:45,966
immediately see the output of


279
00:09:45,966 --> 00:09:47,786
your code after that.


280
00:09:47,786 --> 00:09:49,166
And we're going to use that to


281
00:09:49,166 --> 00:09:49,986
write some code today.


282
00:09:50,866 --> 00:09:52,376
Now the first line of code that


283
00:09:52,376 --> 00:09:54,096
we write, and this is our


284
00:09:54,096 --> 00:09:55,926
favorite line of code, it's


285
00:09:56,156 --> 00:09:59,586
import turicreate as tc.


286
00:10:00,046 --> 00:10:01,206
And I need to select the cell


287
00:10:01,206 --> 00:10:04,506
before I write that.


288
00:10:04,506 --> 00:10:06,706
And this will be your favorite


289
00:10:06,706 --> 00:10:09,236
line too after this session.


290
00:10:09,236 --> 00:10:10,506
Next, I'm going to switch to


291
00:10:10,616 --> 00:10:12,606
Finder to take a look at all our


292
00:10:12,876 --> 00:10:15,846
starter images and it looks like


293
00:10:15,846 --> 00:10:17,376
we have a bunch of cards here


294
00:10:17,376 --> 00:10:19,026
where the playing card spans the


295
00:10:19,026 --> 00:10:20,316
entire frame of the image.


296
00:10:20,316 --> 00:10:22,226
We have an Ace of Clubs, an Ace


297
00:10:22,226 --> 00:10:24,936
of Diamonds, Ace of Hearts, Five


298
00:10:24,936 --> 00:10:27,386
of Hearts, and we have a lot of


299
00:10:27,386 --> 00:10:27,916
images here.


300
00:10:29,026 --> 00:10:30,916
So why don't we go ahead and


301
00:10:30,916 --> 00:10:32,466
load this up into an SFrame?


302
00:10:33,446 --> 00:10:35,506
An SFrame is Turi Create's


303
00:10:35,706 --> 00:10:37,276
scalable data structure.


304
00:10:37,276 --> 00:10:38,706
It's tabular and it's to


305
00:10:38,806 --> 00:10:40,286
represent all the data that you


306
00:10:40,286 --> 00:10:40,476
have.


307
00:10:41,616 --> 00:10:42,766
So we're going to create a


308
00:10:42,766 --> 00:10:44,486
variable called starter images


309
00:10:44,806 --> 00:10:46,056
and Turi Create has this


310
00:10:46,056 --> 00:10:47,646
functionality to load images,


311
00:10:48,036 --> 00:10:49,846
where you just pass in the --


312
00:10:50,096 --> 00:10:51,786
directly that contains all your


313
00:10:51,786 --> 00:10:53,416
images and it builds an SFrame


314
00:10:53,416 --> 00:10:54,466
out of that on its own.


315
00:10:54,876 --> 00:10:57,556
Now let's take a look at what


316
00:10:57,556 --> 00:10:59,066
the starter image SFrame looks


317
00:10:59,066 --> 00:10:59,286
like.


318
00:11:00,376 --> 00:11:01,716
Alright, so there are two


319
00:11:01,716 --> 00:11:02,886
columns in this SFrame.


320
00:11:02,886 --> 00:11:04,336
There's a path column and an


321
00:11:04,336 --> 00:11:05,026
image column.


322
00:11:05,026 --> 00:11:07,386
The path column contains the


323
00:11:07,386 --> 00:11:08,876
relative path to the image that


324
00:11:08,876 --> 00:11:09,986
is in the image column.


325
00:11:10,986 --> 00:11:12,406
Looks good but the path column


326
00:11:12,406 --> 00:11:13,906
has this redundant .


327
00:11:14,616 --> 00:11:15,696
/ and .png.


328
00:11:16,016 --> 00:11:18,126
So let's write a quick code


329
00:11:18,126 --> 00:11:19,826
snippet to get rid of that.


330
00:11:20,476 --> 00:11:22,576
So we're going to create another


331
00:11:22,576 --> 00:11:24,436
column in the starter image's


332
00:11:24,486 --> 00:11:26,236
SFrame and call that label and


333
00:11:26,416 --> 00:11:27,736
we're going to write some code


334
00:11:27,736 --> 00:11:30,706
to extract the label out of the


335
00:11:31,376 --> 00:11:31,746
path.


336
00:11:31,746 --> 00:11:33,296
And we're going to use something


337
00:11:33,296 --> 00:11:35,206
like a Python slice applied to


338
00:11:35,206 --> 00:11:36,806
all the elements in the SFrame


339
00:11:37,106 --> 00:11:38,406
-- in the column of the SFrame.


340
00:11:39,506 --> 00:11:41,306
So we do an element slice from


341
00:11:41,306 --> 00:11:42,956
the second index to the negative


342
00:11:42,956 --> 00:11:44,666
four index similar to a Python


343
00:11:44,666 --> 00:11:45,016
slice.


344
00:11:46,606 --> 00:11:48,606
And next, let's explore this


345
00:11:48,606 --> 00:11:48,876
SFrame.


346
00:11:49,826 --> 00:11:51,166
Turi Create has an explore


347
00:11:51,166 --> 00:11:52,866
functionality on the SFrame,


348
00:11:52,976 --> 00:11:54,126
which we're going to take a look


349
00:11:54,126 --> 00:11:54,296
at.


350
00:11:54,996 --> 00:11:56,216
This pops up, a new


351
00:11:56,216 --> 00:11:57,866
visualization window, which


352
00:11:57,866 --> 00:11:59,716
gives us a way to interactively


353
00:11:59,716 --> 00:12:01,536
explore all the data that is in


354
00:12:01,536 --> 00:12:02,086
our SFrame.


355
00:12:03,196 --> 00:12:05,126
And as we can see, there's three


356
00:12:05,126 --> 00:12:05,726
column here.


357
00:12:05,906 --> 00:12:07,326
There's a path, image, and


358
00:12:07,326 --> 00:12:07,626
label.


359
00:12:08,096 --> 00:12:09,046
And it looks like we did


360
00:12:09,046 --> 00:12:10,736
successfully extract the label


361
00:12:10,736 --> 00:12:11,746
out of the path.


362
00:12:11,746 --> 00:12:13,306
We did get rid of the .


363
00:12:13,306 --> 00:12:13,776
/ and .png.


364
00:12:14,136 --> 00:12:15,336
We can also take a look at all


365
00:12:15,336 --> 00:12:16,816
the thumbnails of our images in


366
00:12:16,816 --> 00:12:18,116
this SFrame which we one day


367
00:12:18,116 --> 00:12:19,136
will do when we just printed it


368
00:12:19,136 --> 00:12:19,396
out.


369
00:12:20,316 --> 00:12:23,496
Great. How many rows are in this


370
00:12:23,536 --> 00:12:23,876
SFrame?


371
00:12:24,276 --> 00:12:26,696
Let's take a look at that.


372
00:12:26,696 --> 00:12:28,086
So it looks like there are 52


373
00:12:28,086 --> 00:12:31,186
rows and that's the number of


374
00:12:31,256 --> 00:12:32,546
cards in our playing card deck.


375
00:12:32,546 --> 00:12:33,566
So that looks good.


376
00:12:33,566 --> 00:12:36,486
But the important thing to note


377
00:12:36,486 --> 00:12:39,646
here is that it's one image per


378
00:12:39,646 --> 00:12:41,776
class of the object that we're


379
00:12:41,776 --> 00:12:42,416
trying to detect.


380
00:12:43,846 --> 00:12:45,476
Now we looked at the data.


381
00:12:45,476 --> 00:12:46,516
We've looked at the task.


382
00:12:46,516 --> 00:12:47,656
We know the task is One-Shot


383
00:12:47,656 --> 00:12:48,446
Object Detection.


384
00:12:49,006 --> 00:12:50,506
The next step in our five-step


385
00:12:50,556 --> 00:12:52,326
biplane is to take a look at the


386
00:12:52,326 --> 00:12:53,576
model creation process.


387
00:12:54,696 --> 00:12:56,206
And consistent with all our


388
00:12:56,206 --> 00:12:57,516
other toolkits, the model


389
00:12:57,516 --> 00:12:59,166
creation process looks something


390
00:12:59,166 --> 00:12:59,466
like


391
00:12:59,976 --> 00:13:02,186
tc.oneshotobjectdetector.create


392
00:13:03,656 --> 00:13:05,046
and we pass in the starter


393
00:13:05,046 --> 00:13:07,336
images SFrame as well as the


394
00:13:07,336 --> 00:13:08,576
target column, which is in this


395
00:13:08,576 --> 00:13:09,436
case, is label.


396
00:13:10,286 --> 00:13:11,336
But I won't run this line of


397
00:13:11,336 --> 00:13:13,996
code because this take a while


398
00:13:13,996 --> 00:13:15,566
and what it does behind the


399
00:13:15,566 --> 00:13:17,776
scenes is it not only generate


400
00:13:17,776 --> 00:13:19,596
all the synthetic data by


401
00:13:19,596 --> 00:13:21,306
applying different projections


402
00:13:21,306 --> 00:13:22,566
on your starter images,


403
00:13:22,916 --> 00:13:24,326
superimposing them on random


404
00:13:24,326 --> 00:13:25,586
backgrounds and applying color


405
00:13:25,586 --> 00:13:27,296
perturbations, but it also


406
00:13:27,296 --> 00:13:28,986
trains a model after that.


407
00:13:29,576 --> 00:13:31,586
So instead, we're going to


408
00:13:31,586 --> 00:13:33,256
switch to a Cooking Show Mode,


409
00:13:33,366 --> 00:13:34,456
where we're going to load a


410
00:13:34,456 --> 00:13:35,726
model that we've already baked


411
00:13:35,726 --> 00:13:37,456
in the oven sometime.


412
00:13:38,036 --> 00:13:39,696
So let's use the load model


413
00:13:39,696 --> 00:13:42,606
functionality and it's called


414
00:13:42,686 --> 00:13:43,996
carddetector.model.


415
00:13:43,996 --> 00:13:46,896
Let's see what this model looks


416
00:13:46,896 --> 00:13:47,186
like.


417
00:13:48,276 --> 00:13:49,606
So it looks like it's a One-Shot


418
00:13:49,606 --> 00:13:51,886
Object Detector trained on 52


419
00:13:51,886 --> 00:13:52,406
classes.


420
00:13:53,306 --> 00:13:54,246
But hold on.


421
00:13:54,386 --> 00:13:55,626
The number of synthetically


422
00:13:55,626 --> 00:13:58,616
generated examples is 104,000.


423
00:13:58,616 --> 00:14:00,696
That's strange.


424
00:14:00,846 --> 00:14:02,576
We just provided 52 images.


425
00:14:04,056 --> 00:14:06,636
The toolkit automatically


426
00:14:06,716 --> 00:14:08,876
synthetically generated 2,000


427
00:14:08,876 --> 00:14:12,506
images per class and created a


428
00:14:12,506 --> 00:14:14,836
training set of 104,000.


429
00:14:14,836 --> 00:14:16,556
And that's not it.


430
00:14:17,476 --> 00:14:19,466
It also synthetically generated


431
00:14:19,466 --> 00:14:21,406
bounding boxes for all the data


432
00:14:21,406 --> 00:14:22,876
that it generated because the


433
00:14:22,876 --> 00:14:24,256
toolkit generated the data


434
00:14:24,256 --> 00:14:24,616
itself.


435
00:14:25,786 --> 00:14:26,796
That's pretty insane.


436
00:14:27,516 --> 00:14:32,116
[ Applause ]


437
00:14:32,616 --> 00:14:35,146
So we've looked at our model.


438
00:14:35,296 --> 00:14:37,096
The next step is let's small


439
00:14:37,096 --> 00:14:39,056
test this model on an image that


440
00:14:39,056 --> 00:14:40,176
the model hasn't seen before.


441
00:14:41,506 --> 00:14:42,856
So I'm going to load up a test


442
00:14:42,856 --> 00:14:43,256
image.


443
00:14:43,566 --> 00:14:47,266
And I have a test directory


444
00:14:47,896 --> 00:14:49,316
which contains a test image.


445
00:14:49,826 --> 00:14:51,846
And it's definitely not Sam's


446
00:14:51,846 --> 00:14:53,146
hand and you'll see why that it


447
00:14:53,146 --> 00:14:54,946
is when I show you what this


448
00:14:54,946 --> 00:14:55,686
test image is.


449
00:14:56,176 --> 00:14:59,906
Yeah, Sam never gets this lucky.


450
00:14:59,906 --> 00:15:03,346
This is probably my hand.


451
00:15:03,666 --> 00:15:04,296
It's a Flush.


452
00:15:04,646 --> 00:15:05,786
So anyway, we can see that


453
00:15:05,786 --> 00:15:06,926
there's an Eight of Clubs, a


454
00:15:06,926 --> 00:15:08,066
Nine of Clubs, and a Ten of


455
00:15:08,116 --> 00:15:09,066
Clubs in this image.


456
00:15:09,936 --> 00:15:12,546
Let's see if the model agrees


457
00:15:12,546 --> 00:15:13,626
with us.


458
00:15:14,776 --> 00:15:16,286
So we're going to call the


459
00:15:16,286 --> 00:15:18,096
predict method on the model and


460
00:15:18,096 --> 00:15:19,576
pass in our test image.


461
00:15:19,756 --> 00:15:21,736
And let's save this result in


462
00:15:21,736 --> 00:15:23,016
variable called prediction.


463
00:15:25,106 --> 00:15:26,646
And next, let's print this


464
00:15:26,646 --> 00:15:28,746
prediction out.


465
00:15:29,016 --> 00:15:30,766
Okay. Let's take that in.


466
00:15:31,456 --> 00:15:33,166
So it looks like there are three


467
00:15:33,166 --> 00:15:35,326
dictionaries in this list and


468
00:15:35,376 --> 00:15:37,136
each dictionary represents a


469
00:15:37,136 --> 00:15:38,666
bounding box that is part of the


470
00:15:38,666 --> 00:15:39,286
prediction.


471
00:15:40,036 --> 00:15:41,096
Let's go through the fields in


472
00:15:41,096 --> 00:15:41,716
each prediction.


473
00:15:41,716 --> 00:15:42,376
It looks like there's a


474
00:15:42,376 --> 00:15:43,526
confidence, there's a


475
00:15:43,566 --> 00:15:45,996
coordinates, a label, and a


476
00:15:45,996 --> 00:15:46,216
type.


477
00:15:47,366 --> 00:15:49,116
Confidence represents how


478
00:15:49,116 --> 00:15:51,766
confident the model is in this


479
00:15:51,766 --> 00:15:52,416
bounding box.


480
00:15:52,916 --> 00:15:54,036
Coordinates represents the


481
00:15:54,036 --> 00:15:56,116
coordinates of the bounding box.


482
00:15:56,766 --> 00:15:58,886
Label is what class label


483
00:15:58,886 --> 00:16:00,366
belongs to this bounding box.


484
00:16:00,366 --> 00:16:01,366
And type is what type of


485
00:16:01,366 --> 00:16:02,426
bounding box it is, which it's


486
00:16:02,496 --> 00:16:02,996
rectangle.


487
00:16:03,256 --> 00:16:05,126
That looks great.


488
00:16:05,476 --> 00:16:07,286
And we can see that the model


489
00:16:07,286 --> 00:16:08,606
did detect the Ten of Clubs and


490
00:16:08,606 --> 00:16:09,606
Eight of Clubs and the Nine of


491
00:16:09,656 --> 00:16:09,956
Clubs.


492
00:16:10,676 --> 00:16:12,096
But it doesn't really tell us


493
00:16:12,316 --> 00:16:14,486
what location the model detected


494
00:16:14,486 --> 00:16:15,066
it in.


495
00:16:15,786 --> 00:16:17,686
So let's use a utility that the


496
00:16:17,686 --> 00:16:20,106
One-Shot Object Detector has to


497
00:16:20,106 --> 00:16:22,646
draw bounding boxes and we'll


498
00:16:22,646 --> 00:16:24,296
pass in the test image along


499
00:16:24,296 --> 00:16:25,636
with annotations, which in this


500
00:16:25,706 --> 00:16:26,716
case, is the prediction.


501
00:16:28,366 --> 00:16:30,646
And let's call this annotated


502
00:16:31,266 --> 00:16:31,766
image.


503
00:16:34,566 --> 00:16:36,756
And next, let's print this


504
00:16:36,756 --> 00:16:37,686
annotated image out.


505
00:16:38,516 --> 00:16:40,956
[ Applause ]


506
00:16:41,456 --> 00:16:42,546
Yeah that looks pretty good.


507
00:16:43,406 --> 00:16:44,876
On an image that the model has


508
00:16:44,876 --> 00:16:46,876
never seen before, an Eight of


509
00:16:46,876 --> 00:16:48,036
Clubs with 70 percent


510
00:16:48,036 --> 00:16:49,366
confidence, a Ten of Clubs with


511
00:16:49,366 --> 00:16:50,836
91 percent, and Nine of Clubs at


512
00:16:50,836 --> 00:16:51,676
69 percent.


513
00:16:52,256 --> 00:16:54,036
And notice how all the bounding


514
00:16:54,036 --> 00:16:57,016
boxes perfectly capture all the


515
00:16:57,016 --> 00:16:57,406
clubs.


516
00:17:00,146 --> 00:17:02,446
So we've small tested this model


517
00:17:02,656 --> 00:17:04,146
on a test image that the model


518
00:17:04,146 --> 00:17:05,066
never saw before.


519
00:17:05,606 --> 00:17:07,526
The last step is deployment on


520
00:17:07,526 --> 00:17:08,066
device.


521
00:17:08,566 --> 00:17:10,506
And like all our other toolkits,


522
00:17:10,566 --> 00:17:12,386
the model has a method to export


523
00:17:12,386 --> 00:17:12,976
Core ML.


524
00:17:13,516 --> 00:17:14,935
And let's call this Core ML


525
00:17:14,935 --> 00:17:17,986
model CardDetector.mlmodel.


526
00:17:20,316 --> 00:17:22,205
And next, let's open this


527
00:17:22,286 --> 00:17:27,935
CardDetector.mlmodel in XCode.


528
00:17:28,006 --> 00:17:30,496
Alright. So we can see that we


529
00:17:30,496 --> 00:17:32,386
have a CardDetector model which


530
00:17:32,386 --> 00:17:35,076
is trained by Turi Create 5.6.


531
00:17:35,886 --> 00:17:37,436
The inputs are image, which is a


532
00:17:37,436 --> 00:17:40,126
416 x 416 color image and


533
00:17:40,126 --> 00:17:42,146
confidence is representative of


534
00:17:42,146 --> 00:17:43,796
how many classes the model was


535
00:17:43,796 --> 00:17:45,506
trained on and coordinates


536
00:17:45,656 --> 00:17:46,776
represents the coordinates of


537
00:17:46,776 --> 00:17:48,436
the bounding box of the classes.


538
00:17:49,906 --> 00:17:50,526
This looks good.


539
00:17:50,526 --> 00:17:52,606
It looks like a very good Core


540
00:17:52,606 --> 00:17:53,326
ML model.


541
00:17:54,006 --> 00:17:56,246
But why don't we have some fun


542
00:17:56,306 --> 00:17:58,486
and put this into action in an


543
00:17:58,756 --> 00:18:00,626
app that Sam can use next time


544
00:18:00,626 --> 00:18:01,656
he plays three card poker


545
00:18:01,656 --> 00:18:02,806
against me.


546
00:18:03,976 --> 00:18:06,006
Alright. And here's my Three


547
00:18:06,006 --> 00:18:07,106
Card Poker app.


548
00:18:07,426 --> 00:18:08,946
So it says add an image to


549
00:18:08,946 --> 00:18:09,746
evaluate cards.


550
00:18:09,976 --> 00:18:11,246
Here I have a deck of cards and


551
00:18:11,246 --> 00:18:12,396
I'm just going to randomly draw


552
00:18:12,396 --> 00:18:12,836
from this.


553
00:18:12,986 --> 00:18:17,706
And this will be Sam's hand.


554
00:18:19,216 --> 00:18:20,876
So let's take a photo right


555
00:18:20,876 --> 00:18:21,146
here.


556
00:18:22,436 --> 00:18:24,776
So it looks like there's -- this


557
00:18:24,776 --> 00:18:26,126
looks like one of the best hands


558
00:18:26,126 --> 00:18:27,356
Sam has gotten in a while.


559
00:18:31,656 --> 00:18:33,196
Alright. So it looks like the


560
00:18:33,196 --> 00:18:34,426
model thinks there's a Five of


561
00:18:34,486 --> 00:18:35,826
Clubs, a Three of Hearts, and a


562
00:18:35,826 --> 00:18:36,426
King of Hearts.


563
00:18:36,936 --> 00:18:38,206
And it also detected it was a


564
00:18:38,206 --> 00:18:38,746
hard card.


565
00:18:38,786 --> 00:18:39,786
The probability of which is


566
00:18:39,786 --> 00:18:40,976
74.39 percent.


567
00:18:41,391 --> 00:18:43,391
[ Applause ]


568
00:18:43,766 --> 00:18:48,166
Yeah. Now given that it's a high


569
00:18:48,166 --> 00:18:50,146
card, Sam should probably fold


570
00:18:50,146 --> 00:18:51,396
because it's pretty likely to


571
00:18:51,396 --> 00:18:52,036
get a high card.


572
00:18:52,036 --> 00:18:53,526
But just for fun, let's see what


573
00:18:53,526 --> 00:18:54,026
I got.


574
00:18:59,056 --> 00:19:01,316
Yeah, that's -- well let's take


575
00:19:01,316 --> 00:19:02,486
a picture and then talk about my


576
00:19:02,516 --> 00:19:02,816
hand.


577
00:19:07,316 --> 00:19:08,616
I have a Flush.


578
00:19:08,686 --> 00:19:09,976
Nine of Hearts, Six of Hearts,


579
00:19:09,976 --> 00:19:13,066
and Four of Hearts.


580
00:19:13,066 --> 00:19:14,476
So even though we built this app


581
00:19:14,586 --> 00:19:17,786
for Sam, we do sort of -- I'm


582
00:19:17,786 --> 00:19:19,126
still reaping the benefits of


583
00:19:19,936 --> 00:19:20,056
it.


584
00:19:21,166 --> 00:19:22,746
Alright. So that was it for the


585
00:19:22,746 --> 00:19:23,826
Card Detector Demo.


586
00:19:23,826 --> 00:19:28,946
And to sort of recap, we started


587
00:19:28,946 --> 00:19:32,766
with one image per class.


588
00:19:33,976 --> 00:19:35,746
We just called one line of code


589
00:19:36,466 --> 00:19:37,606
that automatically,


590
00:19:37,696 --> 00:19:39,056
synthetically generated a


591
00:19:39,056 --> 00:19:40,166
training data set for us.


592
00:19:40,226 --> 00:19:41,006
Trained a model.


593
00:19:41,916 --> 00:19:44,196
We then small tested it on a


594
00:19:44,196 --> 00:19:45,456
random image the model had never


595
00:19:45,526 --> 00:19:46,176
seen before.


596
00:19:46,176 --> 00:19:49,346
And we then saw it in an app.


597
00:19:49,346 --> 00:19:51,126
And this is just one example of


598
00:19:51,126 --> 00:19:53,286
the kind of user experience that


599
00:19:53,286 --> 00:19:53,846
you can build.


600
00:19:54,966 --> 00:19:57,046
We were thrilled with the sort


601
00:19:57,046 --> 00:19:58,316
of stuff you built last year


602
00:19:58,316 --> 00:20:00,256
with the Object Detector and


603
00:20:00,496 --> 00:20:02,556
that sort of led us to build


604
00:20:02,556 --> 00:20:04,716
this toolkit because we wanted


605
00:20:04,716 --> 00:20:06,456
to reduce your overhead on data


606
00:20:06,456 --> 00:20:07,866
collection and annotation.


607
00:20:08,256 --> 00:20:09,316
That time has gone down from


608
00:20:09,316 --> 00:20:10,436
like, I don't know, a few days


609
00:20:10,436 --> 00:20:13,886
to like five minutes and only


610
00:20:13,886 --> 00:20:14,926
for 2D objects though.


611
00:20:15,916 --> 00:20:17,856
And we can't wait to see what


612
00:20:17,856 --> 00:20:18,786
you build with the One-Shot


613
00:20:18,786 --> 00:20:19,506
Object Detector.


614
00:20:19,966 --> 00:20:21,636
So feel free to come to our labs


615
00:20:21,666 --> 00:20:23,026
and try this demo out live.


616
00:20:23,196 --> 00:20:24,886
We will be really excited to


617
00:20:24,886 --> 00:20:25,936
have you.


618
00:20:25,936 --> 00:20:29,066
And with that, I'm going to move


619
00:20:29,066 --> 00:20:31,236
onto to our next toolkit for


620
00:20:32,796 --> 00:20:32,936
today.


621
00:20:33,106 --> 00:20:34,556
I'm really excited to talk to


622
00:20:34,556 --> 00:20:35,126
you about the Drawing


623
00:20:35,126 --> 00:20:35,656
Classifier.


624
00:20:37,516 --> 00:20:40,836
So far Turi Create has enabled


625
00:20:40,836 --> 00:20:42,726
you to build apps with sound


626
00:20:42,726 --> 00:20:46,686
input, raw sensor data input,


627
00:20:48,456 --> 00:20:49,456
and images.


628
00:20:52,116 --> 00:20:55,046
Today, we're adding a new form


629
00:20:55,046 --> 00:20:56,966
of input, the Apple Pencil.


630
00:20:57,516 --> 00:21:00,566
[ Applause ]


631
00:21:01,066 --> 00:21:03,076
Imagine building an app that


632
00:21:03,076 --> 00:21:04,676
let's your users create handsome


633
00:21:04,676 --> 00:21:06,656
greeting cards by recognizing


634
00:21:06,656 --> 00:21:08,706
their strokes and automatically


635
00:21:08,706 --> 00:21:10,156
replacing them with professional


636
00:21:10,156 --> 00:21:10,586
drawings.


637
00:21:11,876 --> 00:21:12,866
Power to the user.


638
00:21:14,246 --> 00:21:15,556
Or imagine building an app that


639
00:21:15,556 --> 00:21:17,826
breaks ground in education by


640
00:21:18,216 --> 00:21:19,926
helping professors grade their


641
00:21:19,926 --> 00:21:21,636
student's exams much faster by


642
00:21:21,636 --> 00:21:22,896
recognizing their strokes.


643
00:21:23,456 --> 00:21:25,436
We're actually going to build


644
00:21:25,436 --> 00:21:25,836
this app.


645
00:21:26,136 --> 00:21:28,396
But before that, let's talk


646
00:21:28,396 --> 00:21:29,736
about the data.


647
00:21:30,596 --> 00:21:32,556
The Drawing Classification task


648
00:21:32,676 --> 00:21:34,116
can accept bitmap-based


649
00:21:34,116 --> 00:21:36,336
drawings, represented as Turi


650
00:21:36,336 --> 00:21:39,116
Create images, but that's not


651
00:21:39,116 --> 00:21:39,326
all.


652
00:21:39,326 --> 00:21:44,346
The task can also accept


653
00:21:44,346 --> 00:21:45,996
stroke-based drawings, where


654
00:21:45,996 --> 00:21:47,746
every stroke is a time series


655
00:21:47,746 --> 00:21:50,336
data of x and y coordinates.


656
00:21:51,546 --> 00:21:53,086
We wanted to give you as much


657
00:21:53,126 --> 00:21:55,906
flexibility in your data as


658
00:21:57,696 --> 00:21:58,196
possible.


659
00:21:58,196 --> 00:21:59,776
Model creation follows an API


660
00:21:59,776 --> 00:22:01,086
consistent with all our other


661
00:22:01,086 --> 00:22:02,846
toolkits, turicreate


662
00:22:02,846 --> 00:22:04,846
drawingclassifier.create with


663
00:22:04,846 --> 00:22:06,376
the training SFrame and the


664
00:22:06,416 --> 00:22:07,046
target column.


665
00:22:07,046 --> 00:22:09,626
The model that you get out of


666
00:22:09,626 --> 00:22:10,656
here is state of the art.


667
00:22:11,386 --> 00:22:12,956
The Core ML model that you get


668
00:22:12,956 --> 00:22:14,746
is less than 500 kilobytes on


669
00:22:14,746 --> 00:22:15,156
device.


670
00:22:15,556 --> 00:22:17,826
And this is GPU accelerated.


671
00:22:18,516 --> 00:22:22,596
[ Applause ]


672
00:22:23,096 --> 00:22:24,286
But we didn't stop there.


673
00:22:25,556 --> 00:22:27,256
We trained a model on millions


674
00:22:27,256 --> 00:22:29,216
of drawings and published it to


675
00:22:29,216 --> 00:22:30,526
automatically one start your


676
00:22:30,526 --> 00:22:30,886
models.


677
00:22:31,136 --> 00:22:33,536
And not only does this help you


678
00:22:33,536 --> 00:22:36,366
create more accurate models, it


679
00:22:36,366 --> 00:22:38,126
also helps you train on as few


680
00:22:38,126 --> 00:22:39,796
as 30 drawings per class.


681
00:22:40,486 --> 00:22:42,236
Thirty. Let that sink in.


682
00:22:42,236 --> 00:22:46,296
So what does the code look like?


683
00:22:47,246 --> 00:22:48,826
Five lines of code, five steps.


684
00:22:49,176 --> 00:22:50,166
We start with importing


685
00:22:50,166 --> 00:22:50,986
turicreate.


686
00:22:50,986 --> 00:22:52,816
Looking at our data, calling


687
00:22:52,816 --> 00:22:54,796
model creation, evaluating our


688
00:22:54,796 --> 00:22:56,216
data, and then exploring to Core


689
00:22:56,216 --> 00:22:56,396
ML.


690
00:22:56,626 --> 00:22:59,776
And with that, remember that


691
00:22:59,776 --> 00:23:01,336
grading app that we saw which


692
00:23:01,336 --> 00:23:02,936
was like recognizing checks and


693
00:23:02,936 --> 00:23:04,406
crosses and doing some more


694
00:23:04,676 --> 00:23:05,736
fancy stuff?


695
00:23:06,466 --> 00:23:07,456
Why don't we go ahead and build


696
00:23:07,456 --> 00:23:07,926
that?


697
00:23:08,056 --> 00:23:10,096
So we're going to take a look at


698
00:23:10,686 --> 00:23:14,316
this app on the iPad, which


699
00:23:15,016 --> 00:23:16,436
helps us grade exams.


700
00:23:17,136 --> 00:23:18,806
So let's say I'm a professor and


701
00:23:18,806 --> 00:23:20,806
I have my Apple Pencil and I


702
00:23:20,806 --> 00:23:21,816
want to grade my students'


703
00:23:21,816 --> 00:23:23,586
exams, but I want to grade them


704
00:23:23,586 --> 00:23:24,246
really quickly.


705
00:23:25,096 --> 00:23:26,706
So let's add an image to begin


706
00:23:26,706 --> 00:23:27,086
grading.


707
00:23:27,086 --> 00:23:29,276
This is an exam of my student,


708
00:23:29,276 --> 00:23:31,366
Jane Appleseed and it's Math


709
00:23:31,366 --> 00:23:32,806
101, which is pretty hard.


710
00:23:35,886 --> 00:23:36,786
So let's take a look at the


711
00:23:36,786 --> 00:23:38,386
image and now let's start


712
00:23:38,386 --> 00:23:38,776
grading.


713
00:23:39,646 --> 00:23:41,476
So one plus one is two, right?


714
00:23:41,476 --> 00:23:42,546
Last I checked that was still


715
00:23:42,546 --> 00:23:42,866
true.


716
00:23:43,506 --> 00:23:44,706
So let's mark that as correct.


717
00:23:44,836 --> 00:23:46,336
And as you can see, the model


718
00:23:46,336 --> 00:23:48,416
detected the check and recorded


719
00:23:48,416 --> 00:23:49,596
ten points on the right-hand


720
00:23:49,596 --> 00:23:51,556
side, giving the student ten out


721
00:23:51,556 --> 00:23:52,696
of ten on this question.


722
00:23:53,766 --> 00:23:54,716
One plus two is four.


723
00:23:54,716 --> 00:23:57,056
That's correct too.


724
00:23:57,296 --> 00:23:58,246
Oh I guess it's not.


725
00:23:58,326 --> 00:24:01,236
So erase that.


726
00:24:01,236 --> 00:24:02,686
I think I should go back to Math


727
00:24:02,686 --> 00:24:03,466
101 maybe.


728
00:24:04,466 --> 00:24:05,806
So let's mark that incorrect


729
00:24:06,456 --> 00:24:07,766
because the model made a


730
00:24:07,766 --> 00:24:08,486
mistake.


731
00:24:08,486 --> 00:24:09,666
So let's erase that again.


732
00:24:10,186 --> 00:24:12,316
And to give you a preview into


733
00:24:12,316 --> 00:24:13,886
how you can improve your models,


734
00:24:13,886 --> 00:24:14,956
Abhishek is going to be up on


735
00:24:14,956 --> 00:24:16,036
stage in a few minutes.


736
00:24:16,616 --> 00:24:18,966
And this app is also designed to


737
00:24:18,966 --> 00:24:20,246
take care of models failing.


738
00:24:20,556 --> 00:24:21,676
So if you want, you can check


739
00:24:21,676 --> 00:24:22,946
out the 11:00 AM session on


740
00:24:22,946 --> 00:24:24,516
Designing Apps for Machine


741
00:24:24,516 --> 00:24:24,726
Learning.


742
00:24:25,266 --> 00:24:26,076
So let's keep grading.


743
00:24:26,616 --> 00:24:27,646
So one plus two is four.


744
00:24:27,646 --> 00:24:28,576
That's incorrect.


745
00:24:28,576 --> 00:24:31,196
And the model detected the cross


746
00:24:31,276 --> 00:24:31,976
as incorrect.


747
00:24:31,976 --> 00:24:33,566
And it's a pretty serious


748
00:24:33,566 --> 00:24:35,726
mistake for Math 101 in college.


749
00:24:36,186 --> 00:24:37,346
So let's give that a negative


750
00:24:37,446 --> 00:24:37,816
seven.


751
00:24:37,816 --> 00:24:40,176
And as you can see, the model


752
00:24:40,176 --> 00:24:41,766
registered the negative seven


753
00:24:42,016 --> 00:24:43,406
and gave the student three out


754
00:24:43,406 --> 00:24:44,766
of ten points on the right-hand


755
00:24:44,766 --> 00:24:44,996
side.


756
00:24:46,186 --> 00:24:47,126
Three plus two is five.


757
00:24:47,126 --> 00:24:48,786
That's correct.


758
00:24:49,646 --> 00:24:51,426
To give you an insight into what


759
00:24:51,426 --> 00:24:53,216
the model is that powers this


760
00:24:53,216 --> 00:24:55,386
app, this model is trained on


761
00:24:55,386 --> 00:24:58,316
check, cross, and ten negative


762
00:24:58,356 --> 00:24:59,796
scored deductions from negative


763
00:24:59,796 --> 00:25:00,716
one through negative ten.


764
00:25:01,466 --> 00:25:02,566
So let's keep grading.


765
00:25:03,226 --> 00:25:04,856
One plus 99 is.


766
00:25:06,686 --> 00:25:07,716
It's a hundred, okay.


767
00:25:08,356 --> 00:25:09,266
So that's incorrect.


768
00:25:09,266 --> 00:25:11,446
And that's another mistake the


769
00:25:11,446 --> 00:25:11,966
model made.


770
00:25:12,456 --> 00:25:14,496
So let's correct that and mark


771
00:25:14,496 --> 00:25:15,086
that incorrect.


772
00:25:16,126 --> 00:25:17,306
So let's give that maybe a


773
00:25:17,306 --> 00:25:19,836
negative five and the model


774
00:25:19,836 --> 00:25:21,376
registered the negative five and


775
00:25:21,376 --> 00:25:22,916
stored it on the right-hand


776
00:25:22,916 --> 00:25:23,146
side.


777
00:25:23,146 --> 00:25:25,946
And this last question is, it's


778
00:25:25,946 --> 00:25:29,926
hard but I don't know how the


779
00:25:29,926 --> 00:25:31,856
student this right, but they got


780
00:25:31,856 --> 00:25:32,886
one plus two wrong.


781
00:25:33,626 --> 00:25:34,526
Anyway, let's give them a


782
00:25:34,526 --> 00:25:35,346
correct for this.


783
00:25:36,476 --> 00:25:39,286
Okay. So this is the kind of


784
00:25:39,286 --> 00:25:41,146
experience that you can build


785
00:25:41,786 --> 00:25:43,186
with the Drawing Classifier.


786
00:25:43,186 --> 00:25:47,456
And why don't we go ahead and


787
00:25:47,456 --> 00:25:48,996
write some code to actually


788
00:25:48,996 --> 00:25:50,256
build a Core ML model that


789
00:25:50,256 --> 00:25:51,726
powered this app.


790
00:25:56,076 --> 00:25:58,096
So here I have another blank


791
00:25:58,096 --> 00:26:00,516
Jupyter Notebook and we're going


792
00:26:00,516 --> 00:26:01,516
to go through that five-step


793
00:26:01,516 --> 00:26:02,416
pipeline again.


794
00:26:03,136 --> 00:26:07,516
The first step being, the task.


795
00:26:07,516 --> 00:26:08,446
The task here is Drawing


796
00:26:08,446 --> 00:26:09,306
Classification.


797
00:26:09,436 --> 00:26:11,636
We've established that.


798
00:26:11,636 --> 00:26:13,196
So the next step is the data.


799
00:26:14,396 --> 00:26:15,886
But before that, let's write our


800
00:26:15,886 --> 00:26:19,096
favorite line of code which is


801
00:26:19,096 --> 00:26:20,806
import turicreate as tc.


802
00:26:22,026 --> 00:26:23,466
Now to look at the data, we're


803
00:26:23,466 --> 00:26:25,136
going to load up an SFrame of


804
00:26:25,346 --> 00:26:26,676
some data that we've already


805
00:26:26,676 --> 00:26:27,286
accumulated.


806
00:26:28,246 --> 00:26:32,006
Let's call it train.


807
00:26:32,136 --> 00:26:34,256
And it's called train.sframe.


808
00:26:34,726 --> 00:26:37,566
Next, let's use the explore


809
00:26:37,596 --> 00:26:39,136
functionality on the train


810
00:26:39,326 --> 00:26:41,636
SFrame and see what it looks


811
00:26:42,876 --> 00:26:43,226
like.


812
00:26:43,226 --> 00:26:44,876
Great. So it looks like we have


813
00:26:44,876 --> 00:26:46,706
a lot of data here.


814
00:26:46,706 --> 00:26:47,896
We have a negative three.


815
00:26:48,096 --> 00:26:49,156
That's labeled as a negative


816
00:26:49,156 --> 00:26:49,396
three.


817
00:26:49,736 --> 00:26:51,026
A check labeled as a check.


818
00:26:51,386 --> 00:26:52,816
Again, this SFrame has two


819
00:26:52,816 --> 00:26:54,446
columns, bitmap and label.


820
00:26:54,936 --> 00:26:56,216
And for this demo, we're going


821
00:26:56,216 --> 00:26:57,536
to be using bitmap-based


822
00:26:57,536 --> 00:26:58,916
drawings, but you can also have


823
00:26:58,916 --> 00:27:00,326
stroke-based drawings instead of


824
00:27:00,326 --> 00:27:01,026
the bitmap column.


825
00:27:02,516 --> 00:27:03,746
So we have a bunch of drawings


826
00:27:03,746 --> 00:27:04,086
here.


827
00:27:04,286 --> 00:27:05,946
If we scroll through it, we have


828
00:27:05,946 --> 00:27:07,526
a cross, another check, some


829
00:27:07,526 --> 00:27:08,696
negative score deductions.


830
00:27:09,096 --> 00:27:09,896
Looks pretty good.


831
00:27:09,896 --> 00:27:11,206
How many examples are there,


832
00:27:11,906 --> 00:27:13,466
4,436?


833
00:27:13,846 --> 00:27:15,246
Okay, that's quite a few


834
00:27:15,246 --> 00:27:16,666
examples.


835
00:27:16,836 --> 00:27:17,826
You might be wondering, "Well


836
00:27:17,826 --> 00:27:19,176
how did you collect all that


837
00:27:19,216 --> 00:27:19,586
data.


838
00:27:19,586 --> 00:27:20,966
How did you get all that data?"


839
00:27:21,506 --> 00:27:23,386
So three of us got into a


840
00:27:23,386 --> 00:27:25,226
conference room with iPads and


841
00:27:25,226 --> 00:27:27,146
Pencils and we just drew these


842
00:27:27,146 --> 00:27:28,676
strokes on our iPads for about


843
00:27:28,676 --> 00:27:31,286
an hour and then just converted


844
00:27:31,286 --> 00:27:32,146
it to an SFrame.


845
00:27:32,666 --> 00:27:34,656
So data collection overhead for


846
00:27:34,656 --> 00:27:36,376
this toolkit is also pretty low.


847
00:27:38,936 --> 00:27:40,006
So now that we've looked at our


848
00:27:40,006 --> 00:27:43,576
data, let's go ahead and look at


849
00:27:43,576 --> 00:27:44,976
what the model creation process


850
00:27:44,976 --> 00:27:46,026
looks like.


851
00:27:47,236 --> 00:27:48,346
So we have


852
00:27:48,716 --> 00:27:50,226
drawingclassifier.create.


853
00:27:50,226 --> 00:27:53,066
We pass in the training SFrame


854
00:27:53,066 --> 00:27:54,166
and we pass in the target


855
00:27:54,166 --> 00:27:55,506
column, which in this case, is


856
00:27:55,506 --> 00:27:55,826
label.


857
00:27:56,216 --> 00:27:57,756
And I'm also going to pass into


858
00:27:57,756 --> 00:27:59,586
a max iterations perimeter of


859
00:27:59,586 --> 00:28:02,006
one to just give you a feel of


860
00:28:02,006 --> 00:28:03,156
what the training process looks


861
00:28:03,206 --> 00:28:03,396
like.


862
00:28:04,876 --> 00:28:06,306
Behind the scenes what this is


863
00:28:06,306 --> 00:28:08,426
doing is it's resizing all our


864
00:28:08,426 --> 00:28:11,426
images down to 28 x 28 and then


865
00:28:11,476 --> 00:28:12,616
parsing them through the neural


866
00:28:12,616 --> 00:28:14,106
network for one iteration.


867
00:28:16,036 --> 00:28:17,736
And looks like that's done.


868
00:28:17,816 --> 00:28:19,066
But this model is not going to


869
00:28:19,066 --> 00:28:20,966
be good enough for our use case.


870
00:28:21,496 --> 00:28:24,096
So again, let's switch to


871
00:28:24,096 --> 00:28:25,686
Cooking Show Mode and open the


872
00:28:25,686 --> 00:28:26,926
door of the oven and take out a


873
00:28:26,926 --> 00:28:28,166
model from it.


874
00:28:29,276 --> 00:28:30,846
So we have the load model


875
00:28:30,846 --> 00:28:33,846
functionality and we load up the


876
00:28:33,906 --> 00:28:34,536
grading model.


877
00:28:34,996 --> 00:28:38,066
Alright. So if we take a look at


878
00:28:38,066 --> 00:28:40,106
this model, we have a Drawing


879
00:28:40,106 --> 00:28:42,136
Classifier model that's trained


880
00:28:42,136 --> 00:28:44,146
on 12 classes with the feature


881
00:28:44,146 --> 00:28:45,516
column being bitmap, the target


882
00:28:45,516 --> 00:28:47,036
column being label, and it's


883
00:28:47,036 --> 00:28:48,756
trained for 200 iterations and


884
00:28:48,756 --> 00:28:49,816
only for 30 minutes.


885
00:28:50,936 --> 00:28:53,506
So after training for only 30


886
00:28:53,506 --> 00:28:54,776
minutes we got a model with a


887
00:28:54,776 --> 00:28:56,096
pretty high training accuracy.


888
00:28:56,316 --> 00:28:56,976
That's pretty good.


889
00:28:56,976 --> 00:29:00,516
So now that we have the model,


890
00:29:00,516 --> 00:29:03,746
the next step is to evaluate


891
00:29:03,786 --> 00:29:04,276
this model.


892
00:29:05,416 --> 00:29:07,316
But I'm going to skip that


893
00:29:07,316 --> 00:29:08,426
because my colleague, Abhishek


894
00:29:08,426 --> 00:29:09,706
will be up here in a few minutes


895
00:29:10,126 --> 00:29:11,986
and not only will he show us how


896
00:29:11,986 --> 00:29:13,356
to visualize the model's


897
00:29:13,356 --> 00:29:15,726
mistakes, but he'll also show us


898
00:29:15,836 --> 00:29:17,546
how to establish a feedback loop


899
00:29:17,546 --> 00:29:19,576
of the model and improve it.


900
00:29:20,066 --> 00:29:22,436
So let's skip ahead to exporting


901
00:29:22,436 --> 00:29:23,716
to Core ML.


902
00:29:25,576 --> 00:29:28,016
And consistent with all our


903
00:29:28,016 --> 00:29:30,886
other toolkits, we have an


904
00:29:30,886 --> 00:29:32,426
export coreml method on the


905
00:29:32,426 --> 00:29:34,406
model and it's not CardDetector,


906
00:29:34,406 --> 00:29:35,106
it's Grading.


907
00:29:35,616 --> 00:29:37,506
So let's call it Grading.mlmodel


908
00:29:37,966 --> 00:29:39,436
and then let's take a look in


909
00:29:39,466 --> 00:29:39,796
XCode.


910
00:29:44,466 --> 00:29:48,496
Great. So this model has bitmap


911
00:29:48,596 --> 00:29:49,716
as its input which is a


912
00:29:49,716 --> 00:29:51,816
grayscale image of size 28 x 28


913
00:29:52,276 --> 00:29:53,346
and the outputs are label


914
00:29:53,346 --> 00:29:55,126
probabilities and class label.


915
00:29:55,486 --> 00:29:56,876
Label probabilities being the


916
00:29:56,876 --> 00:29:58,736
probabilities of all the classes


917
00:29:58,736 --> 00:30:00,056
that the model was trained on


918
00:30:00,386 --> 00:30:01,976
and class label being the class


919
00:30:01,976 --> 00:30:03,056
label of the top prediction.


920
00:30:04,536 --> 00:30:05,276
So this looks good.


921
00:30:06,766 --> 00:30:08,526
We worked really hard to bring


922
00:30:08,526 --> 00:30:10,946
the size of the Core ML down as


923
00:30:10,946 --> 00:30:12,496
much as we could because we


924
00:30:12,496 --> 00:30:14,466
wanted this model to be as


925
00:30:14,576 --> 00:30:15,826
portable as possible for your


926
00:30:15,826 --> 00:30:16,486
use case.


927
00:30:16,486 --> 00:30:20,316
And we brought it down to 396


928
00:30:20,406 --> 00:30:20,876
kilobytes.


929
00:30:20,876 --> 00:30:21,966
That's kilobytes.


930
00:30:22,516 --> 00:30:27,596
[ Applause ]


931
00:30:28,096 --> 00:30:29,716
So now that we've taken a look


932
00:30:29,716 --> 00:30:31,916
at the Core ML model and we've


933
00:30:31,916 --> 00:30:35,546
taken a look at what the final


934
00:30:35,546 --> 00:30:37,616
app that we had was, let's also


935
00:30:37,616 --> 00:30:39,306
take a look at what the Swift


936
00:30:39,306 --> 00:30:40,386
code you need to write to


937
00:30:40,386 --> 00:30:42,176
integrate this model into your


938
00:30:42,176 --> 00:30:42,556
apps.


939
00:30:43,806 --> 00:30:45,406
PencilKit released their API


940
00:30:45,406 --> 00:30:47,036
this past week and they have a


941
00:30:47,036 --> 00:30:49,076
Peek at Canvas view, which has a


942
00:30:49,076 --> 00:30:50,136
Peek at Drawing, which is the


943
00:30:50,136 --> 00:30:51,156
drawing data model.


944
00:30:51,536 --> 00:30:53,436
You can extract the drawing out


945
00:30:53,436 --> 00:30:55,816
of the Canvas view as a UI image


946
00:30:56,056 --> 00:30:57,506
using that line of code.


947
00:30:57,506 --> 00:31:02,176
And next, you can crop it using


948
00:31:02,436 --> 00:31:04,386
again, API from PencilKit to


949
00:31:04,386 --> 00:31:05,786
crop it down to the bounds of


950
00:31:05,786 --> 00:31:06,946
the drawing where the user drew


951
00:31:06,946 --> 00:31:07,666
their strokes.


952
00:31:08,136 --> 00:31:09,526
And now that you have this


953
00:31:09,656 --> 00:31:12,066
cropped, your image that is


954
00:31:12,126 --> 00:31:14,156
ready to be consumed by the Core


955
00:31:14,156 --> 00:31:16,406
ML model, you can use the Vision


956
00:31:16,406 --> 00:31:18,946
API and that's all you need.


957
00:31:19,876 --> 00:31:23,686
To recap, we started with some


958
00:31:23,686 --> 00:31:25,186
drawings and their labels.


959
00:31:25,876 --> 00:31:28,486
We interactively explored our


960
00:31:28,486 --> 00:31:28,866
data.


961
00:31:28,866 --> 00:31:30,226
We saw what the data looked


962
00:31:30,226 --> 00:31:30,496
like.


963
00:31:31,606 --> 00:31:33,016
Then we trained a model or


964
00:31:33,016 --> 00:31:34,196
loaded it from the oven,


965
00:31:35,676 --> 00:31:38,296
exported it to Core ML, and then


966
00:31:38,296 --> 00:31:39,746
deployed using PencilKit and


967
00:31:39,746 --> 00:31:40,016
Vision.


968
00:31:41,486 --> 00:31:42,786
But I did miss one thing.


969
00:31:43,096 --> 00:31:44,476
I did skip it on purpose.


970
00:31:45,456 --> 00:31:47,086
I did skip evaluation and that's


971
00:31:47,086 --> 00:31:49,576
a pretty important part of your


972
00:31:50,196 --> 00:31:50,786
workflow.


973
00:31:51,306 --> 00:31:52,576
And if you actually evaluate


974
00:31:52,576 --> 00:31:53,766
your models and make them


975
00:31:53,766 --> 00:31:55,146
better, you won't see errors


976
00:31:55,146 --> 00:31:56,216
like you saw in the app today.


977
00:31:57,006 --> 00:31:58,276
So with that, I'm going to


978
00:31:58,276 --> 00:31:59,986
invite my colleague, Abhishek to


979
00:31:59,986 --> 00:32:01,206
take us through an exciting


980
00:32:01,206 --> 00:32:02,356
model evaluation journey.


981
00:32:02,496 --> 00:32:02,976
Abhishek.


982
00:32:03,516 --> 00:32:08,226
[ Applause ]


983
00:32:08,726 --> 00:32:11,136
>> Thank you.


984
00:32:11,136 --> 00:32:12,396
So today I'd like to talk to you


985
00:32:12,396 --> 00:32:15,216
about Model Evaluation and why


986
00:32:15,216 --> 00:32:16,636
it's really important in


987
00:32:16,636 --> 00:32:18,416
building the best possible user


988
00:32:18,416 --> 00:32:19,206
experiences.


989
00:32:19,826 --> 00:32:23,856
But first, let's understand how


990
00:32:23,856 --> 00:32:25,656
evaluation works.


991
00:32:27,046 --> 00:32:28,036
Let's take the Drawing


992
00:32:28,036 --> 00:32:29,446
Classifier model we trained in


993
00:32:29,446 --> 00:32:30,276
the previous demo.


994
00:32:31,076 --> 00:32:32,586
And if we pass a drawing through


995
00:32:32,586 --> 00:32:34,006
it, we get a prediction.


996
00:32:35,546 --> 00:32:38,086
Using ground truth data, we can


997
00:32:38,086 --> 00:32:39,706
identify whether this prediction


998
00:32:39,706 --> 00:32:41,906
is correct or sometimes


999
00:32:42,466 --> 00:32:43,196
incorrect.


1000
00:32:43,876 --> 00:32:45,686
But using a single data point to


1001
00:32:45,686 --> 00:32:48,186
evaluate a model doesn't give us


1002
00:32:48,186 --> 00:32:49,716
a full picture of what the model


1003
00:32:49,716 --> 00:32:50,136
is doing.


1004
00:32:50,606 --> 00:32:51,606
So what do we do?


1005
00:32:52,506 --> 00:32:54,146
Well, we use more data.


1006
00:32:55,496 --> 00:32:57,046
This is our test data set.


1007
00:32:58,276 --> 00:33:00,206
We can run the model across the


1008
00:33:00,206 --> 00:33:02,766
data and get correct and


1009
00:33:02,766 --> 00:33:04,396
incorrect predictions for each


1010
00:33:04,396 --> 00:33:05,116
of the drawings.


1011
00:33:06,476 --> 00:33:07,776
By grouping the drawings


1012
00:33:07,846 --> 00:33:09,156
together in correct and


1013
00:33:09,156 --> 00:33:11,676
incorrect groups we get a sense


1014
00:33:11,676 --> 00:33:12,786
for how well the model is


1015
00:33:12,836 --> 00:33:13,296
performing.


1016
00:33:14,716 --> 00:33:16,516
This is analogous to the metric


1017
00:33:16,516 --> 00:33:18,436
of accuracy, a measure of the


1018
00:33:18,436 --> 00:33:21,096
correct predicted drawings over


1019
00:33:21,096 --> 00:33:22,406
the total number of drawings in


1020
00:33:22,406 --> 00:33:22,936
our data set.


1021
00:33:23,496 --> 00:33:25,906
And there are other metrics we


1022
00:33:25,906 --> 00:33:27,746
can use to help us quantify our


1023
00:33:27,746 --> 00:33:28,836
model's performance.


1024
00:33:30,256 --> 00:33:32,226
To access these in Turi Create,


1025
00:33:32,226 --> 00:33:33,996
simply call the evaluate method


1026
00:33:34,586 --> 00:33:35,906
available to use on the model


1027
00:33:35,906 --> 00:33:38,146
object and pass in that test


1028
00:33:38,186 --> 00:33:39,326
data set.


1029
00:33:39,996 --> 00:33:41,856
A dictionary of these metrics


1030
00:33:41,896 --> 00:33:43,866
will then be returned to now


1031
00:33:43,866 --> 00:33:47,976
evaluate our model.


1032
00:33:48,256 --> 00:33:51,196
But this actually doesn't tell


1033
00:33:51,196 --> 00:33:52,266
us the whole story.


1034
00:33:53,426 --> 00:33:55,786
For instance, take a model with


1035
00:33:55,786 --> 00:33:57,576
an accuracy of 85 percent.


1036
00:33:58,366 --> 00:33:59,586
Initially that seems pretty good


1037
00:33:59,586 --> 00:34:00,236
to us, doesn't it?


1038
00:34:01,486 --> 00:34:04,166
Well, if we dig down into the


1039
00:34:04,246 --> 00:34:06,996
per class accuracy, we see that


1040
00:34:06,996 --> 00:34:08,856
the class of four has a much


1041
00:34:08,856 --> 00:34:10,606
lower accuracy than the rest of


1042
00:34:10,606 --> 00:34:11,536
the other classes.


1043
00:34:12,116 --> 00:34:14,656
And this is a case that you


1044
00:34:14,656 --> 00:34:16,025
usually might run into.


1045
00:34:17,485 --> 00:34:19,755
Well, what's causing this low


1046
00:34:19,755 --> 00:34:20,335
accuracy?


1047
00:34:20,946 --> 00:34:22,596
One thing might be that there


1048
00:34:22,596 --> 00:34:24,436
might be a low number of


1049
00:34:24,436 --> 00:34:26,206
examples present for that


1050
00:34:26,206 --> 00:34:27,346
particular class.


1051
00:34:28,295 --> 00:34:30,146
To correct for this we may want


1052
00:34:30,146 --> 00:34:31,126
to add more examples.


1053
00:34:31,766 --> 00:34:34,226
But there are other things that


1054
00:34:34,226 --> 00:34:34,946
can be going on.


1055
00:34:36,085 --> 00:34:38,376
For instance, we've noticed that


1056
00:34:38,376 --> 00:34:40,186
in some data sets the


1057
00:34:40,186 --> 00:34:41,466
annotations are incorrect.


1058
00:34:42,116 --> 00:34:45,136
In the drawing to your left, you


1059
00:34:45,136 --> 00:34:46,556
see that the model has predicted


1060
00:34:46,876 --> 00:34:48,326
this drawing to be one, but the


1061
00:34:48,326 --> 00:34:49,446
annotation is seven.


1062
00:34:50,596 --> 00:34:52,016
And when visually inspecting


1063
00:34:52,016 --> 00:34:53,926
this drawing, we can see that


1064
00:34:53,926 --> 00:34:55,716
the annotation probably should


1065
00:34:55,716 --> 00:34:56,166
be one.


1066
00:34:57,276 --> 00:34:58,816
So we can go and correct the


1067
00:34:58,906 --> 00:34:59,596
annotation.


1068
00:35:00,666 --> 00:35:02,306
But in other instances such as


1069
00:35:02,306 --> 00:35:04,466
the one to your right, the model


1070
00:35:04,466 --> 00:35:05,906
has predicted it to be four and


1071
00:35:05,906 --> 00:35:08,106
the annotation is one but it's


1072
00:35:08,106 --> 00:35:10,386
unclear whether the annotation


1073
00:35:10,476 --> 00:35:11,996
or the model is incorrect.


1074
00:35:14,676 --> 00:35:16,256
There also may be systematic


1075
00:35:16,256 --> 00:35:17,776
biases present in your model.


1076
00:35:18,206 --> 00:35:19,886
For instance, in this example,


1077
00:35:20,506 --> 00:35:22,026
the model has predicted sevens


1078
00:35:22,026 --> 00:35:24,736
with bars to be incorrect as


1079
00:35:24,866 --> 00:35:27,586
three but correctly predicts the


1080
00:35:27,586 --> 00:35:28,646
sevens without bars.


1081
00:35:28,716 --> 00:35:33,566
And to help you identify these


1082
00:35:33,636 --> 00:35:35,766
issues, we've created an


1083
00:35:35,766 --> 00:35:37,436
interactive visualization tool.


1084
00:35:37,436 --> 00:35:40,546
Let me show you how it works.


1085
00:35:40,706 --> 00:35:42,806
Alright. So let's go back to the


1086
00:35:42,806 --> 00:35:44,266
Jupyter Notebook that Shantanu


1087
00:35:44,266 --> 00:35:46,256
was showing us and load in a


1088
00:35:46,366 --> 00:35:48,816
test data set that we can use to


1089
00:35:48,816 --> 00:35:49,736
evaluate our model.


1090
00:35:57,436 --> 00:35:58,846
Now that we've loaded in our


1091
00:35:58,846 --> 00:36:00,546
test data set, let's call that


1092
00:36:00,546 --> 00:36:06,816
evaluate method passing in that


1093
00:36:06,936 --> 00:36:11,696
test data set.


1094
00:36:11,916 --> 00:36:13,886
So now that we have our metrics


1095
00:36:13,976 --> 00:36:16,776
object, we can simply call the


1096
00:36:16,776 --> 00:36:18,856
explorer method on that metric's


1097
00:36:18,936 --> 00:36:21,766
object to now look at our


1098
00:36:21,766 --> 00:36:23,006
interactive visualization.


1099
00:36:23,636 --> 00:36:27,356
And as you can see, a window


1100
00:36:27,356 --> 00:36:30,736
popped up and it has three


1101
00:36:30,736 --> 00:36:33,666
distinct sections, an Overview


1102
00:36:33,666 --> 00:36:35,436
section, which gives us the


1103
00:36:35,436 --> 00:36:37,346
overall accuracy of the model as


1104
00:36:37,346 --> 00:36:38,916
well as the number of iterations


1105
00:36:39,456 --> 00:36:40,756
in the model that we've trained,


1106
00:36:40,856 --> 00:36:42,186
the Drawing Classifier model.


1107
00:36:43,396 --> 00:36:45,426
The second section is a Per


1108
00:36:45,426 --> 00:36:47,466
Class breakdown of the metrics


1109
00:36:47,786 --> 00:36:49,216
as well as a couple of example


1110
00:36:49,216 --> 00:36:51,396
images that have been correctly


1111
00:36:51,396 --> 00:36:52,596
been predicted by the model.


1112
00:36:53,596 --> 00:36:55,956
And lastly, there's an Error


1113
00:36:55,956 --> 00:36:57,826
section that shows us all of the


1114
00:36:57,826 --> 00:37:01,086
errors that the model has made.


1115
00:37:01,286 --> 00:37:02,926
So let's take a look at the


1116
00:37:03,016 --> 00:37:04,446
first class, negative four.


1117
00:37:04,776 --> 00:37:06,816
We see that class has an


1118
00:37:06,816 --> 00:37:08,466
accuracy of 20 percent.


1119
00:37:09,646 --> 00:37:11,486
If we click on it, we see that


1120
00:37:11,486 --> 00:37:13,286
there are actually four errors


1121
00:37:13,476 --> 00:37:14,636
that have been made by the


1122
00:37:14,636 --> 00:37:14,926
model.


1123
00:37:15,966 --> 00:37:17,276
But something else that we see


1124
00:37:17,276 --> 00:37:18,826
is that the number of elements


1125
00:37:18,826 --> 00:37:20,366
that we've tested is five.


1126
00:37:21,036 --> 00:37:22,706
And that's a pretty low number.


1127
00:37:23,306 --> 00:37:25,676
So to kind of determine whether


1128
00:37:25,676 --> 00:37:27,036
the model is performing


1129
00:37:27,036 --> 00:37:29,006
improperly on this class or


1130
00:37:29,006 --> 00:37:30,676
simply we have a low number of


1131
00:37:30,676 --> 00:37:33,126
examples that we're testing, we


1132
00:37:33,126 --> 00:37:34,466
might want to go back and add


1133
00:37:34,516 --> 00:37:36,136
more examples to this class to


1134
00:37:36,136 --> 00:37:38,026
get a better determination of


1135
00:37:38,026 --> 00:37:39,636
whether the model is performing


1136
00:37:39,636 --> 00:37:42,676
incorrectly or simply we don't


1137
00:37:42,706 --> 00:37:43,766
have enough examples.


1138
00:37:44,366 --> 00:37:48,006
Let's go to class of negative


1139
00:37:49,696 --> 00:37:49,786
two.


1140
00:37:50,006 --> 00:37:51,596
We see something that stands out


1141
00:37:51,596 --> 00:37:53,106
when we filter by this class.


1142
00:37:53,606 --> 00:37:55,506
There are 11 incorrect


1143
00:37:55,506 --> 00:37:57,156
predictions of the same type,


1144
00:37:58,176 --> 00:37:59,556
meaning that the actual


1145
00:37:59,556 --> 00:38:01,046
annotation is negative two, but


1146
00:38:01,046 --> 00:38:02,566
the model has predicted all of


1147
00:38:02,566 --> 00:38:04,026
these examples to be negative


1148
00:38:04,026 --> 00:38:04,316
seven.


1149
00:38:05,196 --> 00:38:06,396
But when we look through these


1150
00:38:06,396 --> 00:38:07,396
examples that have been


1151
00:38:07,396 --> 00:38:09,896
misclassified, we see that some


1152
00:38:09,896 --> 00:38:11,536
of these examples are, in fact,


1153
00:38:11,596 --> 00:38:12,216
negative seven.


1154
00:38:12,736 --> 00:38:14,116
And this is a case where the


1155
00:38:14,116 --> 00:38:16,006
data set has some misannotated


1156
00:38:16,046 --> 00:38:16,576
data points.


1157
00:38:17,306 --> 00:38:19,196
So we might want to go back and


1158
00:38:19,196 --> 00:38:21,036
correct those annotations to get


1159
00:38:21,036 --> 00:38:22,296
a better indication of our


1160
00:38:22,296 --> 00:38:23,426
model's performance.


1161
00:38:23,976 --> 00:38:27,956
We've also included a number of


1162
00:38:27,956 --> 00:38:30,546
other metrics such as F1 Score


1163
00:38:30,546 --> 00:38:32,266
Precision and Recall which may


1164
00:38:32,266 --> 00:38:33,986
be more relevant to your use


1165
00:38:33,986 --> 00:38:35,756
cases when evaluating your


1166
00:38:35,756 --> 00:38:36,126
models.


1167
00:38:38,536 --> 00:38:42,826
So, a recap.


1168
00:38:44,556 --> 00:38:45,776
We now allow you to


1169
00:38:45,776 --> 00:38:47,456
interactively visualize model


1170
00:38:47,506 --> 00:38:47,946
predictions.


1171
00:38:49,496 --> 00:38:51,256
This can help us easily spot


1172
00:38:51,556 --> 00:38:53,346
annotation errors as well as


1173
00:38:53,346 --> 00:38:55,336
identify those systematic biases


1174
00:38:55,336 --> 00:38:56,646
we talked about.


1175
00:38:57,936 --> 00:38:59,416
But now that we've identified


1176
00:38:59,416 --> 00:39:01,516
these issues, what steps can we


1177
00:39:01,586 --> 00:39:03,816
take to improve the model?


1178
00:39:03,816 --> 00:39:07,446
Well, let's take a look at our


1179
00:39:07,446 --> 00:39:07,876
pipeline.


1180
00:39:09,836 --> 00:39:12,336
First, we have our test data


1181
00:39:12,336 --> 00:39:12,586
set.


1182
00:39:14,006 --> 00:39:15,456
We've passed it through the


1183
00:39:15,456 --> 00:39:17,006
Drawing Classifier model and


1184
00:39:17,006 --> 00:39:18,586
used our interactive


1185
00:39:18,586 --> 00:39:20,316
visualization tool to identify


1186
00:39:20,406 --> 00:39:20,906
some issues.


1187
00:39:22,746 --> 00:39:25,416
And we may want to add more


1188
00:39:25,416 --> 00:39:27,426
examples to correct for some of


1189
00:39:27,426 --> 00:39:28,096
these issues.


1190
00:39:29,556 --> 00:39:31,136
We also may want to remove


1191
00:39:31,136 --> 00:39:34,236
incorrectly trained data as well


1192
00:39:34,236 --> 00:39:36,346
as maybe update incorrect


1193
00:39:36,346 --> 00:39:37,056
annotations.


1194
00:39:37,476 --> 00:39:39,856
In Turi Create, we enable you to


1195
00:39:39,856 --> 00:39:42,806
load data as well as sort and


1196
00:39:42,846 --> 00:39:44,576
filter data if you want to


1197
00:39:44,576 --> 00:39:46,716
remove incorrect training data.


1198
00:39:48,496 --> 00:39:50,196
If you want to add more data,


1199
00:39:51,046 --> 00:39:52,616
simply use the append command.


1200
00:39:53,266 --> 00:39:57,746
And new in Turi Create 6.0 we've


1201
00:39:57,746 --> 00:40:00,976
introduced an annotation tool.


1202
00:40:01,046 --> 00:40:03,176
To use it, pass in the data set


1203
00:40:03,176 --> 00:40:05,646
that you want to annotate, and a


1204
00:40:05,646 --> 00:40:07,426
GUI pops up with two distinct


1205
00:40:07,426 --> 00:40:07,856
sections.


1206
00:40:08,846 --> 00:40:10,576
To your left, you can see the


1207
00:40:10,576 --> 00:40:11,756
image that you want to annotate


1208
00:40:11,806 --> 00:40:13,336
and to your right you see a


1209
00:40:13,336 --> 00:40:14,066
labels column.


1210
00:40:15,466 --> 00:40:17,436
You can add labels and annotate


1211
00:40:17,436 --> 00:40:18,286
your data points.


1212
00:40:19,786 --> 00:40:21,576
But we also recognize that if


1213
00:40:21,576 --> 00:40:22,976
you're going through a large


1214
00:40:23,026 --> 00:40:25,796
data set it may be annoying to


1215
00:40:25,866 --> 00:40:29,366
kind of spend that time to go


1216
00:40:29,426 --> 00:40:30,546
through the entire data set.


1217
00:40:30,546 --> 00:40:31,426
So we've included image


1218
00:40:31,426 --> 00:40:32,366
similarity and we're going to


1219
00:40:32,406 --> 00:40:34,066
help you quickly go through your


1220
00:40:34,066 --> 00:40:34,526
data set.


1221
00:40:35,776 --> 00:40:37,996
We've also included a Table view


1222
00:40:38,066 --> 00:40:39,676
that allows you to scroll


1223
00:40:39,676 --> 00:40:41,336
through your data set, look at


1224
00:40:41,336 --> 00:40:43,376
annotations, maybe identify


1225
00:40:43,376 --> 00:40:44,806
those systematic biases we


1226
00:40:44,866 --> 00:40:47,076
talked about, and add multiple


1227
00:40:47,076 --> 00:40:48,936
annotations to multiple images.


1228
00:40:49,516 --> 00:40:57,546
[ Applause ]


1229
00:40:58,046 --> 00:40:59,546
So a summary of this session.


1230
00:41:00,206 --> 00:41:03,416
Sam and Shantanu showed us the


1231
00:41:03,416 --> 00:41:05,616
new One-Shot Object Detector


1232
00:41:05,616 --> 00:41:06,046
Toolkit.


1233
00:41:06,946 --> 00:41:08,616
Shantanu upped Sam's game with a


1234
00:41:08,616 --> 00:41:10,656
Three Card Poker app and was


1235
00:41:10,656 --> 00:41:12,586
able to build a robust model


1236
00:41:12,586 --> 00:41:16,566
with only one example per class.


1237
00:41:16,736 --> 00:41:18,086
Next, we looked at the new


1238
00:41:18,086 --> 00:41:19,896
Drawing Classifier ToolKit.


1239
00:41:20,516 --> 00:41:22,716
In it, we saw the new


1240
00:41:22,716 --> 00:41:24,076
integration with the Apple


1241
00:41:24,206 --> 00:41:24,536
Pencil.


1242
00:41:26,716 --> 00:41:28,986
The interactive visualization


1243
00:41:29,296 --> 00:41:32,216
tool showed us how to evaluate


1244
00:41:32,216 --> 00:41:34,886
models interactively and


1245
00:41:34,946 --> 00:41:37,046
hopefully showed us a process


1246
00:41:37,176 --> 00:41:38,966
for building better experiences


1247
00:41:39,166 --> 00:41:39,816
for our users.


1248
00:41:40,406 --> 00:41:43,326
And finally, we introduced a new


1249
00:41:43,326 --> 00:41:45,136
annotation tool that not only


1250
00:41:45,136 --> 00:41:46,876
allows you to label data, but


1251
00:41:46,876 --> 00:41:48,006
quickly go through your data


1252
00:41:48,006 --> 00:41:49,246
sets with the use of image


1253
00:41:49,246 --> 00:41:49,796
similarity.


1254
00:41:50,816 --> 00:41:52,656
Please install Turicreate.


1255
00:41:52,946 --> 00:41:54,016
We hope you've enjoyed this


1256
00:41:54,016 --> 00:41:56,156
session and join us in the labs


1257
00:41:56,246 --> 00:41:57,366
at 2:00 if you want to see any


1258
00:41:57,366 --> 00:41:58,776
of the demos or have any


1259
00:41:58,836 --> 00:41:59,456
questions.


1260
00:42:00,726 --> 00:42:01,886
We encourage you to check out


1261
00:42:01,886 --> 00:42:03,066
these related sessions.


1262
00:42:04,536 --> 00:42:05,426
Thank you for coming to WWDC


1263
00:42:05,426 --> 00:42:05,976
2019.


1264
00:42:06,516 --> 00:42:09,500
[ Applause ]

