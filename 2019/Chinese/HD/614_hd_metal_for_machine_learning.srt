1
00:00:01,176 --> 00:00:04,500
[音乐]


2
00:00:09,516 --> 00:00:15,546
[掌声]


3
00:00:16,046 --> 00:00:16,826
>> 下午好


4
00:00:17,536 --> 00:00:18,636
我叫 Justin


5
00:00:18,756 --> 00:00:20,376
我是 GPU 软件的一名工程师


6
00:00:20,376 --> 00:00:21,976
我要讲的是机器学习的 Metal


7
00:00:24,516 --> 00:00:25,946
今天我们要讨论的是


8
00:00:25,946 --> 00:00:26,896
Metal Performance Shaders


9
00:00:26,896 --> 00:00:28,466
框架 以及我们今年


10
00:00:28,466 --> 00:00:29,796
增加的新的机器学习功能


11
00:00:30,396 --> 00:00:33,096
Metal Performance Shaders 或


12
00:00:33,096 --> 00:00:35,156
MPS 是 GPU 加速的


13
00:00:35,156 --> 00:00:36,626
基元的集合


14
00:00:37,066 --> 00:00:38,006
它让你可以


15
00:00:38,006 --> 00:00:39,356
在 GPU 中利用 Metal


16
00:00:39,356 --> 00:00:40,476
高性能的能力


17
00:00:41,226 --> 00:00:43,326
MPS 为图像处理


18
00:00:43,356 --> 00:00:46,266
线性代数 光线追踪 机器学习


19
00:00:46,266 --> 00:00:48,486
提供内核 


20
00:00:49,066 --> 00:00:51,016
现在 机器学习内核


21
00:00:51,016 --> 00:00:52,826
支持推理和训练


22
00:00:52,826 --> 00:00:54,516
它们在 iOS macOS


23
00:00:54,516 --> 00:00:58,896
tvOS 中得到了优化


24
00:00:59,066 --> 00:01:00,446
MPS 还通过图表 API


25
00:01:00,446 --> 00:01:01,766
为构建神经网络


26
00:01:02,006 --> 00:01:07,646
提供了一个便捷的方式


27
00:01:07,876 --> 00:01:10,326
所以 我们现在可以看到


28
00:01:10,326 --> 00:01:11,826
MPS 是如何适应更大的


29
00:01:11,826 --> 00:01:12,436
Apple ML 生态系统的


30
00:01:13,646 --> 00:01:14,936
你有更高等级的框架


31
00:01:14,936 --> 00:01:17,806
如 Core ML 和 Create ML


32
00:01:17,806 --> 00:01:18,736
它们为你实施自己的网络


33
00:01:18,736 --> 00:01:20,386
提供了一个便捷的方式


34
00:01:20,916 --> 00:01:22,076
但是如果你想要在自己的项目上


35
00:01:22,076 --> 00:01:23,646
多一点弹性和控制


36
00:01:23,646 --> 00:01:25,086
你可以使用如 MPS 的


37
00:01:25,086 --> 00:01:27,186
更低等级框架


38
00:01:29,386 --> 00:01:32,266
今年 我们为机器学习支持


39
00:01:32,266 --> 00:01:33,696
添加了几个新功能


40
00:01:34,816 --> 00:01:36,356
我们增加了内核


41
00:01:36,396 --> 00:01:37,676
来支持比以往更多的网络


42
00:01:39,426 --> 00:01:41,256
我们提升了


43
00:01:41,256 --> 00:01:43,726
已存在的网络的性能


44
00:01:43,726 --> 00:01:47,176
我们也让 MPS 更易使用


45
00:01:47,176 --> 00:01:48,276
现在 随着我们检查这些新特征


46
00:01:48,276 --> 00:01:49,456
知道一些关于


47
00:01:49,456 --> 00:01:50,636
推理和训练如何在


48
00:01:50,636 --> 00:01:52,476
机器学习中运行


49
00:01:53,386 --> 00:01:54,546
是很有用的


50
00:01:54,546 --> 00:01:56,706
所以 让我们简单复习一下这些概念


51
00:01:59,156 --> 00:02:01,136
推理就是


52
00:02:01,136 --> 00:02:02,536
将网络运用到一个输入数值的过程


53
00:02:02,536 --> 00:02:04,196
在这个例子中就是个图片


54
00:02:04,196 --> 00:02:06,366
产生一个输出或者猜测它是什么


55
00:02:07,386 --> 00:02:09,066
现在 网络是由


56
00:02:09,066 --> 00:02:10,346
如卷积和神经元激活


57
00:02:10,346 --> 00:02:12,106
等多种功能组成


58
00:02:12,106 --> 00:02:16,456
这些层数都依赖于一组参数


59
00:02:16,696 --> 00:02:18,526
在推理中 这些参数


60
00:02:18,526 --> 00:02:20,246
都是固定的 但是它们的


61
00:02:20,246 --> 00:02:22,746
数值在训练过程中被确定


62
00:02:23,306 --> 00:02:26,266
那么 在训练中发生了什么呢


63
00:02:26,266 --> 00:02:28,146
在训练中 我们给予


64
00:02:28,146 --> 00:02:30,956
网络很多已知对象的图像


65
00:02:31,346 --> 00:02:32,506
训练过程包含


66
00:02:32,506 --> 00:02:34,016
不断地对这些图像进行分类


67
00:02:34,016 --> 00:02:35,926
正如我们所做的


68
00:02:35,926 --> 00:02:38,496
我们更新了我们的参数


69
00:02:38,496 --> 00:02:39,416
每一次网络的迭代


70
00:02:39,786 --> 00:02:40,676
都会产生一套更好的参数


71
00:02:40,736 --> 00:02:42,976
直到我们最终得到一套


72
00:02:42,976 --> 00:02:45,896
让我们能最好地分类图像的参数


73
00:02:46,406 --> 00:02:49,526
在我们停止


74
00:02:49,526 --> 00:02:50,726
训练过程的阶段


75
00:02:50,726 --> 00:02:51,716
我们的参数已经准备好


76
00:02:51,716 --> 00:02:56,036
在推理中使用了 我们来看看


77
00:02:56,036 --> 00:02:57,546
如何运用 MPS 来执行这些想法


78
00:02:58,186 --> 00:02:59,516
我还是想说


79
00:03:00,036 --> 00:03:00,966
与我们刚刚说到的相比


80
00:03:00,966 --> 00:03:02,536
还有更多的推理和训练


81
00:03:02,536 --> 00:03:03,956
所以如果你想要更多细节


82
00:03:04,296 --> 00:03:05,406
你可以看看我们过去几年的


83
00:03:05,406 --> 00:03:06,936
那些演讲


84
00:03:10,026 --> 00:03:11,256
现在 我们今年增加了


85
00:03:11,256 --> 00:03:12,256
几个新的功能


86
00:03:12,256 --> 00:03:13,456
以此来更好地支持


87
00:03:13,456 --> 00:03:14,636
广范围的推理和训练网络


88
00:03:15,556 --> 00:03:16,616
首先 通过支持你推理图表


89
00:03:16,616 --> 00:03:18,576
中的训练图表的隐式创建


90
00:03:18,576 --> 00:03:19,946
我们让你的网络的


91
00:03:19,946 --> 00:03:21,706
图表创建变得更加简单


92
00:03:22,206 --> 00:03:24,316
我们为可分离损耗层


93
00:03:24,316 --> 00:03:26,146
和随机数生成添加了内核


94
00:03:26,146 --> 00:03:28,426
以此来运行


95
00:03:28,426 --> 00:03:31,046
一系列的新网络


96
00:03:31,046 --> 00:03:33,366
我们为如预测和更好地控制 MPS 


97
00:03:33,366 --> 00:03:35,276
使其提升性能等


98
00:03:35,276 --> 00:03:37,276
增加了支持


99
00:03:37,826 --> 00:03:41,056
所以 让我们先从隐式图表创作开始吧


100
00:03:41,586 --> 00:03:44,866
通过隐式图表创作


101
00:03:44,866 --> 00:03:46,526
我们可以隐晦地从我们的推理图表中


102
00:03:46,526 --> 00:03:47,246
创建训练图表


103
00:03:48,466 --> 00:03:49,996
所以 我们先来复习一下


104
00:03:49,996 --> 00:03:52,266
如何为我们的网络创建一个图表


105
00:03:52,426 --> 00:03:54,306
这里我们有一个简单的推理网络


106
00:03:54,526 --> 00:03:55,836
它由一些卷积层组成


107
00:03:55,836 --> 00:03:58,756
一些池化层


108
00:03:58,756 --> 00:04:00,166
最后是一些完全相连的层


109
00:04:00,726 --> 00:04:03,306
所以 我们会通过


110
00:04:03,306 --> 00:04:04,596
为每个层创建节点


111
00:04:04,596 --> 00:04:06,006
来为网络创建一个图表


112
00:04:06,006 --> 00:04:07,556
我们将为


113
00:04:07,556 --> 00:04:09,106
每个卷积层创建一个


114
00:04:09,106 --> 00:04:11,706
卷积节点


115
00:04:11,706 --> 00:04:12,716
每个池化层创建一个


116
00:04:12,716 --> 00:04:14,876
池化节点 然后为完全连接层


117
00:04:14,876 --> 00:04:17,106
创建一个完全连接节点


118
00:04:17,685 --> 00:04:20,315
随着我们的推理图表被定义


119
00:04:20,315 --> 00:04:21,976
我们可以将其拓展为训练图表


120
00:04:25,276 --> 00:04:26,556
我们首先在推理图表的末端


121
00:04:26,556 --> 00:04:28,186
增加一个损耗节点


122
00:04:28,186 --> 00:04:30,616
然后我们在正向节点


123
00:04:30,616 --> 00:04:31,676
增加梯度节点


124
00:04:31,676 --> 00:04:34,946
方向和我们的推理图表正好相反


125
00:04:35,506 --> 00:04:37,256
现在我们可以看看


126
00:04:37,256 --> 00:04:37,806
这个部分的代码


127
00:04:38,606 --> 00:04:39,886
正如之前所说


128
00:04:39,886 --> 00:04:43,306
我们开始先是增加损耗节点


129
00:04:43,306 --> 00:04:44,956
然后增加梯度节点


130
00:04:44,956 --> 00:04:46,546
顺序就和我们之前提到的一样


131
00:04:47,146 --> 00:04:49,996
所以我们可以看到


132
00:04:49,996 --> 00:04:51,876
每一个梯度节点


133
00:04:51,876 --> 00:04:53,676
都可以很容易地从前面的节点中创造出来


134
00:04:53,676 --> 00:04:55,406
但是如果通过隐式


135
00:04:55,406 --> 00:04:56,786
图表创造 这一切会更简单


136
00:04:58,896 --> 00:05:00,116
现在 你一旦通过损耗节点


137
00:05:00,116 --> 00:05:01,046
初始化你的梯度图像


138
00:05:01,046 --> 00:05:03,216
我们可以自动地


139
00:05:03,216 --> 00:05:04,616
创建与推理图表


140
00:05:04,656 --> 00:05:05,946
相匹配的训练图表


141
00:05:07,646 --> 00:05:09,276
和之前一样 我们创建了损耗节点


142
00:05:09,846 --> 00:05:12,526
通过一行代码


143
00:05:12,786 --> 00:05:14,546
我们可以创建我们的训练图表


144
00:05:14,546 --> 00:05:17,126
在这个例子中


145
00:05:17,126 --> 00:05:18,846
我们会从损耗节点创建训练图表


146
00:05:18,846 --> 00:05:19,896
我们将为我们的


147
00:05:19,896 --> 00:05:20,886
资源梯度使用 nil 参数


148
00:05:20,886 --> 00:05:23,226
这将会告知损耗节点


149
00:05:23,226 --> 00:05:24,626
使用其结果


150
00:05:24,626 --> 00:05:25,686
来初始化梯度


151
00:05:26,086 --> 00:05:27,306
但是如果我们想的话


152
00:05:27,306 --> 00:05:27,786
可以使用另一个图像


153
00:05:28,336 --> 00:05:31,736
我们为第二个参数提供零点


154
00:05:31,736 --> 00:05:32,886
这个叫作节点处理器


155
00:05:33,426 --> 00:05:34,476
节点处理器会让你提供一个块


156
00:05:34,476 --> 00:05:36,006
你可以用它来


157
00:05:36,006 --> 00:05:37,526
实施一些自定义的代码


158
00:05:38,036 --> 00:05:39,976
在你的节点创建之后来配置它们


159
00:05:43,766 --> 00:05:44,716
我还想要提到另一个有用的


160
00:05:44,716 --> 00:05:47,176
功能 那就是停止梯度属性


161
00:05:48,116 --> 00:05:49,766
所以 一般来说


162
00:05:49,766 --> 00:05:50,986
当你生成你的训练序列时


163
00:05:50,986 --> 00:05:53,346
你所有的可训练层都会更新它们的权重


164
00:05:54,696 --> 00:05:55,776
在这例子中


165
00:05:55,776 --> 00:05:58,026
这些是卷积和完全连接层


166
00:05:58,556 --> 00:06:00,106
但是在一些例子中


167
00:06:00,106 --> 00:06:01,276
你可能只想更新


168
00:06:01,276 --> 00:06:02,086
网络中某些层的权重


169
00:06:02,086 --> 00:06:04,746
比如说 在转换学习中


170
00:06:05,116 --> 00:06:06,606
现在 在转换学习中


171
00:06:06,606 --> 00:06:07,686
我们将要对很多层


172
00:06:07,686 --> 00:06:09,036
使用事先训练好的权重


173
00:06:09,036 --> 00:06:09,896
我们只想训练


174
00:06:09,896 --> 00:06:10,876
某些层的权重


175
00:06:11,266 --> 00:06:13,666
比如说 最终完全连接层


176
00:06:15,576 --> 00:06:17,016
隐式图表创作同样支持


177
00:06:17,016 --> 00:06:18,266
通过停止梯度属性


178
00:06:18,266 --> 00:06:20,556
为这些网络类型创作图表


179
00:06:21,166 --> 00:06:24,176
所以 为了实现这个


180
00:06:24,176 --> 00:06:25,396
我们应该首先


181
00:06:25,396 --> 00:06:26,856
在那些我们想要更新权重的第一层


182
00:06:27,066 --> 00:06:28,986
设置停止梯度属性


183
00:06:29,956 --> 00:06:30,956
在这个例子中 


184
00:06:30,956 --> 00:06:31,526
就是完全连接层


185
00:06:32,056 --> 00:06:35,156
当图表生成时


186
00:06:35,156 --> 00:06:37,066
后来的梯度节点


187
00:06:37,066 --> 00:06:39,306
都不会被创建


188
00:06:39,886 --> 00:06:42,906
所以正如你们所见


189
00:06:42,906 --> 00:06:44,576
使用隐式图表创作


190
00:06:44,576 --> 00:06:46,726
是一个从你的推理图表


191
00:06:46,726 --> 00:06:47,666
生成训练图表的


192
00:06:47,666 --> 00:06:48,366
非常简单的方法


193
00:06:52,236 --> 00:06:53,496
让我们来看一个


194
00:06:53,496 --> 00:06:55,836
我们增加的用来支持新的网络的功能


195
00:06:56,576 --> 00:06:57,926
可分离损耗内核


196
00:06:59,676 --> 00:07:01,726
所以 早些时候 我们看到了


197
00:07:01,726 --> 00:07:04,836
如何使用损耗节点来使用


198
00:07:04,836 --> 00:07:05,276
MPS CNN 损耗


199
00:07:06,316 --> 00:07:07,966
MPS CNN 损耗消耗一个最终图像


200
00:07:07,966 --> 00:07:09,006
这通常都是如 Softmax 层


201
00:07:09,006 --> 00:07:10,456
和 Truth 数据


202
00:07:10,456 --> 00:07:12,116
为了计算梯度数值


203
00:07:12,116 --> 00:07:15,786
以开始反向传播过程的结果


204
00:07:16,476 --> 00:07:18,206
但是还有一些为了


205
00:07:18,206 --> 00:07:19,956
产生一个最终损耗


206
00:07:19,956 --> 00:07:22,456
而使用多重中间损耗数值的网络


207
00:07:22,926 --> 00:07:24,936
为了支持这个


208
00:07:24,986 --> 00:07:26,526
我们增加了分别的正向和


209
00:07:26,526 --> 00:07:27,186
梯度损耗内核


210
00:07:27,656 --> 00:07:29,256
所以 在这里


211
00:07:29,256 --> 00:07:31,256
我们使用了利用正向损耗节点


212
00:07:31,336 --> 00:07:33,506
进行运算的两个损耗数值


213
00:07:33,506 --> 00:07:34,746
然后我们得到了这些结果


214
00:07:34,746 --> 00:07:37,396
将它们加在一起来产生一个最终损耗


215
00:07:38,016 --> 00:07:41,236
现在 我们需要初始化


216
00:07:41,236 --> 00:07:43,286
梯度值来开始反向过程


217
00:07:44,926 --> 00:07:46,446
在它通过损耗节点


218
00:07:46,446 --> 00:07:47,566
隐式发生前


219
00:07:47,566 --> 00:07:49,066
我们需要增加一个初始的梯度内核


220
00:07:49,536 --> 00:07:51,126
这将会生成


221
00:07:51,126 --> 00:07:52,516
一个梯度图像


222
00:07:52,516 --> 00:07:53,716
它将会变成


223
00:07:53,716 --> 00:07:54,996
最终损耗计算的结果权重


224
00:07:55,606 --> 00:07:57,896
所以 随着梯度数值的初始化


225
00:07:57,896 --> 00:07:59,266
我们可以启动


226
00:07:59,266 --> 00:08:00,386
反向过程


227
00:08:00,686 --> 00:08:01,706
我们将会为


228
00:08:01,706 --> 00:08:02,736
我们拥有附加梯度的


229
00:08:02,736 --> 00:08:03,806
正向内核使用梯度内核


230
00:08:03,806 --> 00:08:06,586
也为正向损耗内核使用梯度


231
00:08:06,586 --> 00:08:09,706
现在 让我们看看


232
00:08:09,706 --> 00:08:12,726
使用可分离损耗的网络


233
00:08:13,266 --> 00:08:14,196
特别地 我们将看一下


234
00:08:14,196 --> 00:08:15,336
风格转换


235
00:08:15,926 --> 00:08:18,766
风格转换网络


236
00:08:18,766 --> 00:08:20,256
产生了融合


237
00:08:20,256 --> 00:08:23,176
风格和原始图像的图像


238
00:08:24,716 --> 00:08:26,286
我们会看到的模型


239
00:08:26,286 --> 00:08:27,276
是你可以找到并重新创作的


240
00:08:27,276 --> 00:08:28,646
它可以使用 MPS


241
00:08:28,646 --> 00:08:29,986
来实施


242
00:08:31,086 --> 00:08:32,466
在推理中 这个网络


243
00:08:32,466 --> 00:08:34,176
由转换节点构成


244
00:08:34,176 --> 00:08:35,405
如卷积和


245
00:08:35,405 --> 00:08:36,556
实例规范化层


246
00:08:36,556 --> 00:08:38,135
它们的权重构成了


247
00:08:38,135 --> 00:08:40,015
训练的参数


248
00:08:40,775 --> 00:08:42,566
这就是嵌入风格的地方


249
00:08:43,126 --> 00:08:44,766
它通过训练过程


250
00:08:44,866 --> 00:08:45,876
学习到参数内


251
00:08:46,716 --> 00:08:48,596
所以让我们来看看如何训练


252
00:08:49,186 --> 00:08:51,706
现在我们有一个关于网络的概览


253
00:08:53,546 --> 00:08:55,126
作为推理


254
00:08:55,126 --> 00:08:56,306
我们将应用转换器


255
00:08:56,926 --> 00:08:58,496
来生成一个风格化的图像


256
00:08:59,186 --> 00:09:00,216
现在 在这个例子中


257
00:09:00,216 --> 00:09:02,136
它将是网络目前


258
00:09:02,356 --> 00:09:04,516
关于最好的风格图像的猜测


259
00:09:04,516 --> 00:09:05,956
它结合了风格和内容


260
00:09:06,686 --> 00:09:08,726
因为网络的目标是


261
00:09:08,726 --> 00:09:10,286
匹配期望的风格


262
00:09:10,286 --> 00:09:11,726
和原始图像的内容


263
00:09:11,726 --> 00:09:12,846
我们将需要


264
00:09:12,846 --> 00:09:13,996
两个损耗数值


265
00:09:14,486 --> 00:09:18,116
所以 第一个损耗数值


266
00:09:18,116 --> 00:09:20,166
是由我们称之为风格损耗网络的数据网络


267
00:09:20,166 --> 00:09:21,096
进行计算的


268
00:09:22,316 --> 00:09:23,326
这个损耗数值


269
00:09:23,326 --> 00:09:25,756
将会保证网络收敛在一个结果上


270
00:09:25,756 --> 00:09:27,706
而这个结果会与我们期望的风格很匹配


271
00:09:28,316 --> 00:09:29,666
我们还想要保证


272
00:09:29,666 --> 00:09:32,036
生成的图像还能保持


273
00:09:32,776 --> 00:09:34,366
原始图像的特征


274
00:09:34,496 --> 00:09:35,346
所以 我们要对此


275
00:09:35,346 --> 00:09:36,236
使用第二个损耗网络


276
00:09:36,626 --> 00:09:37,846
那就是内容损耗


277
00:09:38,336 --> 00:09:41,896
我们可以为每个损耗计算


278
00:09:46,416 --> 00:09:48,716
但是让我们更仔细地看看


279
00:09:48,716 --> 00:09:49,766
风格损耗网络


280
00:09:50,786 --> 00:09:51,926
为了计算


281
00:09:51,926 --> 00:09:53,676
风格损耗 我们需要一个


282
00:09:53,916 --> 00:09:55,586
测量图像风格的方法


283
00:09:56,236 --> 00:09:57,086
为了实现这个


284
00:09:57,086 --> 00:09:58,306
我们需要为几个


285
00:09:58,306 --> 00:09:59,936
代表这个图像的中间特征


286
00:09:59,936 --> 00:10:00,976
计算我们所称的格兰姆矩阵


287
00:10:01,116 --> 00:10:04,766
今年 格兰姆矩阵计算


288
00:10:04,766 --> 00:10:05,946
在 MPS 中


289
00:10:05,946 --> 00:10:07,596
由正向和梯度内核


290
00:10:07,596 --> 00:10:08,996
本机支持


291
00:10:09,606 --> 00:10:11,476
所以 让我们迅速来看一下 


292
00:10:11,656 --> 00:10:12,686
格兰姆矩阵以及


293
00:10:12,686 --> 00:10:13,116
它是如何运算的


294
00:10:13,666 --> 00:10:15,286
格兰姆矩阵代表了


295
00:10:15,286 --> 00:10:16,626
特征向量间的


296
00:10:16,716 --> 00:10:17,856
非居中的关联


297
00:10:18,396 --> 00:10:20,296
现在 每个特征向量


298
00:10:20,296 --> 00:10:21,296
都是从空间扁平化一个单一的特征通道中的


299
00:10:21,296 --> 00:10:23,926
一个单一的图像所获得的结果


300
00:10:24,536 --> 00:10:26,926
为了创作一个格兰姆矩阵


301
00:10:26,926 --> 00:10:29,146
我们在特征向量间计算点积


302
00:10:29,916 --> 00:10:31,216
我们来看看这是如何使用的


303
00:10:32,036 --> 00:10:34,586
在我们得到格兰姆矩阵前


304
00:10:34,586 --> 00:10:35,906
我们将使用 VGG


305
00:10:35,906 --> 00:10:37,466
图像分类网络


306
00:10:37,466 --> 00:10:38,986
来从我们的风格和


307
00:10:38,986 --> 00:10:41,366
风格化的输入图像来提取特征


308
00:10:41,366 --> 00:10:43,896
现在 正如我们之前描述的


309
00:10:43,896 --> 00:10:45,106
格兰姆矩阵


310
00:10:45,106 --> 00:10:46,526
给了我们特征向量之间的关联


311
00:10:47,586 --> 00:10:48,906
现在 当我们采用这些


312
00:10:48,906 --> 00:10:49,986
从风格提取的特征


313
00:10:49,986 --> 00:10:52,776
这为我们想要应用的


314
00:10:52,776 --> 00:10:54,376
风格提供了真值


315
00:10:54,376 --> 00:10:56,216
我们还要为


316
00:10:56,216 --> 00:10:57,946
关于最好的风格图像的


317
00:10:57,946 --> 00:11:00,496
现存猜测做同样的事情


318
00:11:01,506 --> 00:11:02,706
现在 我们用这两个数值一起


319
00:11:02,706 --> 00:11:06,306
来形成我们的风格损耗


320
00:11:08,916 --> 00:11:10,196
所以 现在让我们看看


321
00:11:10,196 --> 00:11:11,216
我们如何计算两个损耗中的第二个


322
00:11:11,216 --> 00:11:12,746
内容损耗


323
00:11:13,306 --> 00:11:15,326
和之前一样


324
00:11:15,326 --> 00:11:17,576
我们将使用 VGG 提取特征


325
00:11:17,686 --> 00:11:19,026
然后使用这些特征计算损耗


326
00:11:19,026 --> 00:11:21,426
以及我们风格化的图像的特征


327
00:11:22,396 --> 00:11:23,556
网络的最终损耗


328
00:11:23,556 --> 00:11:25,386
将是内容损耗和


329
00:11:25,386 --> 00:11:27,066
风格损耗的总和


330
00:11:28,206 --> 00:11:29,256
所以 现在让我们看看


331
00:11:29,256 --> 00:11:30,966
我们如何使用 MPS 来计算这些数值


332
00:11:30,966 --> 00:11:32,046
和初始化梯度


333
00:11:32,606 --> 00:11:36,086
首先 让我们假设


334
00:11:36,086 --> 00:11:37,426
我们有特征代表


335
00:11:37,426 --> 00:11:38,326
由 VGG 生成


336
00:11:39,306 --> 00:11:40,326
首先 我们要为了


337
00:11:40,326 --> 00:11:42,876
风格和风格化图像


338
00:11:42,946 --> 00:11:44,266
增加格兰姆矩阵计算节点


339
00:11:44,266 --> 00:11:46,376
来计算格兰姆矩阵


340
00:11:49,546 --> 00:11:50,526
我们将把这些结果


341
00:11:50,526 --> 00:11:52,206
注入正向损耗节点


342
00:11:52,806 --> 00:11:54,626
以此来计算我们风格的损耗


343
00:11:55,886 --> 00:11:57,536
这里的源图像是格兰姆矩阵


344
00:11:57,536 --> 00:11:58,626
对我们的网络风格化的图像的


345
00:11:58,626 --> 00:12:00,756
计算结果


346
00:12:03,416 --> 00:12:04,646
对于引用风格图像的


347
00:12:04,646 --> 00:12:06,566
格兰姆矩阵


348
00:12:06,566 --> 00:12:07,926
将会用在标签参数中


349
00:12:09,256 --> 00:12:10,126
现在它展示了一个


350
00:12:10,126 --> 00:12:12,096
新的正向损耗内核的重要特征


351
00:12:12,356 --> 00:12:13,656
之前 你必须使用 MPS 状态对象


352
00:12:13,656 --> 00:12:15,276
来传递聚类


353
00:12:15,826 --> 00:12:20,866
但是现在 你可以使用 MPS 图像


354
00:12:21,036 --> 00:12:22,256
现在我们可以使用


355
00:12:22,256 --> 00:12:23,996
风格化的图像和原始图像


356
00:12:24,036 --> 00:12:25,206
来为内容损耗


357
00:12:25,206 --> 00:12:27,326
增加损耗节点


358
00:12:27,326 --> 00:12:28,816
我们可以将其相结合


359
00:12:28,816 --> 00:12:29,686
来获得我们总共的损耗数值


360
00:12:30,276 --> 00:12:32,466
现在我们需要初始化


361
00:12:32,466 --> 00:12:34,066
最终的损耗梯度


362
00:12:34,066 --> 00:12:35,246
来启动反向过程


363
00:12:36,636 --> 00:12:38,256
我们使用


364
00:12:38,256 --> 00:12:39,506
之前提到过的初始化梯度节点


365
00:12:43,236 --> 00:12:44,316
我们之前已经看到了


366
00:12:44,316 --> 00:12:46,316
损耗节点的结果是


367
00:12:46,316 --> 00:12:47,956
如何用来隐式生成训练图表的


368
00:12:48,276 --> 00:12:49,826
这是因为它生成了


369
00:12:49,826 --> 00:12:50,496
初始的梯度


370
00:12:51,266 --> 00:12:52,856
但是现在 正如我之前提到的


371
00:12:52,856 --> 00:12:54,976
通过可分离损耗内核


372
00:12:54,976 --> 00:12:56,326
我们可以使用初始梯度节点


373
00:12:56,326 --> 00:12:57,216
来明确地完成这个


374
00:12:57,586 --> 00:12:58,696
所以 这就是


375
00:12:58,696 --> 00:12:59,976
我们用来生成训练图表的节点


376
00:13:02,536 --> 00:13:03,586
随着图表的生成


377
00:13:03,966 --> 00:13:05,626
我们可以看看


378
00:13:05,626 --> 00:13:07,156
这个网络在活动中做什么


379
00:13:10,836 --> 00:13:12,236
所以 我们可以看到


380
00:13:12,236 --> 00:13:13,876
在 GPU 上运行的使用 MPS 的


381
00:13:13,876 --> 00:13:14,766
风格转换网络


382
00:13:14,766 --> 00:13:17,106
它在拥有 AMD Radeon pro 560


383
00:13:17,176 --> 00:13:20,266
图表卡的 Mac Book Pro 上运行


384
00:13:20,866 --> 00:13:22,986
这个展示了


385
00:13:22,986 --> 00:13:24,336
风格转换训练在运行过程中


386
00:13:24,336 --> 00:13:26,106
在每个迭代的结果


387
00:13:26,576 --> 00:13:28,866
正如你所见


388
00:13:28,866 --> 00:13:30,996
风格在日益增多地被运用


389
00:13:30,996 --> 00:13:31,916
但是图像的内容


390
00:13:31,916 --> 00:13:32,506
却被保留了


391
00:13:32,506 --> 00:13:34,156
我还想提到的是


392
00:13:34,156 --> 00:13:35,746
这些迭代在这个视频中


393
00:13:35,746 --> 00:13:37,776
被加速了


394
00:13:37,776 --> 00:13:38,906
以此来更好地展示


395
00:13:38,906 --> 00:13:40,976
训练网络的进程


396
00:13:47,266 --> 00:13:49,576
所以现在我要看一看


397
00:13:49,576 --> 00:13:50,566
我们今年增加的另一个功能


398
00:13:50,566 --> 00:13:52,146
随机数生成


399
00:13:54,596 --> 00:13:56,016
今年 我们为 MPS 中的


400
00:13:56,016 --> 00:13:57,026
两种随机数生成


401
00:13:57,026 --> 00:13:58,116
增加了支持


402
00:13:58,816 --> 00:13:59,586
我们有一个名为 MTGP32 的


403
00:13:59,586 --> 00:14:01,656
梅森旋转算法的变量


404
00:14:01,656 --> 00:14:03,806
以及一个名为 Philox 的


405
00:14:03,806 --> 00:14:04,416
基于计数的生成器


406
00:14:05,596 --> 00:14:06,676
这些生成器之所以被选择


407
00:14:06,676 --> 00:14:07,806
是因为它们的算法


408
00:14:07,806 --> 00:14:08,706
很适合 GPU 体系结构


409
00:14:08,706 --> 00:14:10,086
它们也会提供


410
00:14:10,086 --> 00:14:12,046
拥有很好的统计属性的


411
00:14:12,046 --> 00:14:13,896
随机数的序列


412
00:14:14,316 --> 00:14:16,566
现在 你们可以使用这些内核


413
00:14:16,566 --> 00:14:18,126
来生成大的使用


414
00:14:18,126 --> 00:14:21,056
缓冲和 GPU 内存的随机数序列


415
00:14:21,626 --> 00:14:22,606
既然在 GPU 内存上


416
00:14:22,606 --> 00:14:24,496
这个结果可用


417
00:14:24,496 --> 00:14:25,476
你可以避免同步大的


418
00:14:25,476 --> 00:14:26,766
射线和 CPU 的数字


419
00:14:27,796 --> 00:14:29,176
生成像这样的随机数


420
00:14:29,696 --> 00:14:30,576
对于机器学习 App


421
00:14:30,576 --> 00:14:32,056
非常重要


422
00:14:32,756 --> 00:14:33,986
它们被要求


423
00:14:33,986 --> 00:14:35,536
比如说 初始化


424
00:14:35,536 --> 00:14:37,636
你用于训练的网络的权重


425
00:14:37,636 --> 00:14:39,376
同时也在训练生成


426
00:14:39,376 --> 00:14:40,836
对抗的网络 或简称为 GAN


427
00:14:40,836 --> 00:14:41,946
创建输入


428
00:14:43,076 --> 00:14:44,016
GAN 是随机数生成器


429
00:14:44,016 --> 00:14:46,366
的一个非常重要的使用例子


430
00:14:46,636 --> 00:14:47,626
你需要在你的训练的


431
00:14:47,626 --> 00:14:50,016
每个迭代


432
00:14:50,016 --> 00:14:50,336
生成随机输入


433
00:14:50,956 --> 00:14:53,576
如果你要从 CPU


434
00:14:53,576 --> 00:14:55,026
同步一个阵列的数字


435
00:14:55,456 --> 00:14:57,186
每一个迭代


436
00:14:57,186 --> 00:14:58,196
都可以训练你的网络


437
00:14:58,236 --> 00:14:59,216
过分昂贵


438
00:15:00,636 --> 00:15:01,946
所以 让我们进一步看看


439
00:15:01,946 --> 00:15:03,206
这些网络和


440
00:15:03,206 --> 00:15:04,346
我们如何使用新的


441
00:15:04,346 --> 00:15:04,866
随机数生成器


442
00:15:07,016 --> 00:15:09,436
生成对抗网络或 GAN


443
00:15:09,436 --> 00:15:10,666
一般都在


444
00:15:10,666 --> 00:15:11,566
两个网络中构建


445
00:15:11,566 --> 00:15:12,706
我们有一个生成器网络


446
00:15:12,706 --> 00:15:13,756
和一个鉴别器网络


447
00:15:14,726 --> 00:15:15,576
我们这里有一个生成器的例子


448
00:15:15,576 --> 00:15:17,416
它只会生成


449
00:15:17,416 --> 00:15:18,526
手写数字的图像


450
00:15:19,106 --> 00:15:21,506
和训练中的


451
00:15:21,506 --> 00:15:22,766
图像分类相似


452
00:15:22,766 --> 00:15:25,876
我们将会提供有手写数字的很多例子的网络


453
00:15:25,876 --> 00:15:27,046
然而 网络并没有试着对它们分类


454
00:15:27,046 --> 00:15:29,236
而是试着从


455
00:15:29,236 --> 00:15:31,296
从随机初始数据集


456
00:15:31,296 --> 00:15:34,676
生成新的图像 以此与训练集


457
00:15:34,676 --> 00:15:35,216
看起来相似


458
00:15:35,746 --> 00:15:39,326
为了执行


459
00:15:39,326 --> 00:15:41,886
训练过程 我们需要


460
00:15:41,886 --> 00:15:43,836
一些决定这些图像


461
00:15:44,236 --> 00:15:45,046
将如何相似的方法


462
00:15:45,626 --> 00:15:46,676
所以 针对这第二个网络


463
00:15:46,806 --> 00:15:48,016
我们将使用


464
00:15:48,016 --> 00:15:48,726
我们称之为鉴别器的东西


465
00:15:50,576 --> 00:15:52,356
正如这个名字所展示的


466
00:15:52,356 --> 00:15:54,426
它将用来鉴别


467
00:15:54,426 --> 00:15:57,056
训练图像和那些


468
00:15:57,056 --> 00:15:58,486
由生成器模拟的图像


469
00:15:59,206 --> 00:16:00,406
在这个例子中


470
00:16:00,406 --> 00:16:01,416
它表现为图像分类网络


471
00:16:01,416 --> 00:16:02,726
但是只有两个可能性


472
00:16:03,426 --> 00:16:05,496
输入要么是从训练集中的真实的图像


473
00:16:05,496 --> 00:16:06,596
或者它可能是生成的


474
00:16:06,596 --> 00:16:08,016
是一个假图像


475
00:16:08,326 --> 00:16:10,596
所以你们可以看到


476
00:16:10,596 --> 00:16:11,996
这就是鉴别器


477
00:16:11,996 --> 00:16:13,966
正在查询数字


478
00:16:13,966 --> 00:16:15,606
是真还是假


479
00:16:17,946 --> 00:16:19,066
现在 典型的生成器和鉴别器


480
00:16:19,066 --> 00:16:20,916
都是一起训练的


481
00:16:21,646 --> 00:16:23,206
我们训练生成器


482
00:16:23,206 --> 00:16:24,586
来产生更多真实的图像


483
00:16:25,066 --> 00:16:25,626
我们训练鉴别器


484
00:16:25,626 --> 00:16:27,976
来更好地分辨合成的图像


485
00:16:28,186 --> 00:16:29,136
与训练图像


486
00:16:29,876 --> 00:16:31,466
所以 我们这里有一个


487
00:16:31,466 --> 00:16:32,626
针对你的训练网络的


488
00:16:32,626 --> 00:16:33,786
节点的高层次的概览


489
00:16:34,416 --> 00:16:35,706
这就是我们的鉴别器训练


490
00:16:35,706 --> 00:16:36,766
训练网络


491
00:16:37,656 --> 00:16:39,426
它由两个损耗计算组成


492
00:16:39,536 --> 00:16:40,486
所以 我们刚刚谈到的


493
00:16:40,486 --> 00:16:41,626
是关于你在哪里能使用


494
00:16:41,626 --> 00:16:42,486
可分离损耗节点的例子


495
00:16:43,636 --> 00:16:46,176
我们还有一个损耗


496
00:16:46,176 --> 00:16:47,766
通过它我们试图保证


497
00:16:47,766 --> 00:16:48,756
鉴别器正确地


498
00:16:48,756 --> 00:16:50,656
将模拟图像分类为假


499
00:16:50,656 --> 00:16:52,816
我们还有第二个损耗


500
00:16:52,816 --> 00:16:55,356
通过它我们可以训练


501
00:16:55,356 --> 00:16:56,596
鉴别器将从训练集中的真实图像


502
00:16:56,596 --> 00:16:58,546
分类为真


503
00:16:59,086 --> 00:17:02,696
计算完这些分离损耗数值后


504
00:17:02,696 --> 00:17:04,346
我们可以使用


505
00:17:04,346 --> 00:17:06,306
一个初始化梯度节点


506
00:17:06,306 --> 00:17:07,256
来初始化你的训练图表


507
00:17:07,866 --> 00:17:10,906
第二 我们在这里有


508
00:17:10,906 --> 00:17:11,856
生成器训练网络


509
00:17:12,516 --> 00:17:13,596
这个稍微简单一点


510
00:17:13,596 --> 00:17:14,856
它只有一个损耗数值


511
00:17:15,756 --> 00:17:18,496
但是在这个例子中


512
00:17:18,496 --> 00:17:20,026
我们使用一个真实的聚类数值


513
00:17:20,026 --> 00:17:21,886
来保证我们的生成器可以生成


514
00:17:21,886 --> 00:17:22,715
鉴别器随后会分类为


515
00:17:22,715 --> 00:17:23,965
真的图像


516
00:17:24,856 --> 00:17:26,016
正如我之前提到的


517
00:17:26,016 --> 00:17:27,076
生成器网络开始时伴随着


518
00:17:27,076 --> 00:17:28,926
一套随机的数据


519
00:17:28,926 --> 00:17:29,806
我们将会使用随机数生成器


520
00:17:29,806 --> 00:17:30,596
来生成这些数


521
00:17:31,256 --> 00:17:32,476
所以 让我们仔细看看


522
00:17:33,196 --> 00:17:34,246
随机数字生成器


523
00:17:34,826 --> 00:17:37,206
现在 随机数生成器内核


524
00:17:37,206 --> 00:17:39,446
属于 MPSMatrix 副框架


525
00:17:39,446 --> 00:17:41,196
它们通过


526
00:17:41,196 --> 00:17:42,506
MPSMatrix 随机类


527
00:17:42,506 --> 00:17:43,866
被接入


528
00:17:44,806 --> 00:17:46,206
所以它们在 MPSMatrix


529
00:17:46,206 --> 00:17:47,356
和 MPSVector 对象上运转


530
00:17:47,356 --> 00:17:48,226
这意味着它们与


531
00:17:48,226 --> 00:17:51,096
metal 缓冲器一起运行


532
00:17:51,096 --> 00:17:53,476
它们也与潜在的生成器一起


533
00:17:53,476 --> 00:17:54,576
支持生成随机整数


534
00:17:54,576 --> 00:17:55,566
或者你可以使用一个


535
00:17:55,566 --> 00:17:57,126
统一的分布来生成浮点值


536
00:17:57,726 --> 00:17:59,996
在这里 我们将为数值在 0 和 1 之间的


537
00:17:59,996 --> 00:18:01,706
统一分配


538
00:18:01,706 --> 00:18:04,676
创建一个分配描述符


539
00:18:05,226 --> 00:18:07,896
然后我们将创建我们的生成器


540
00:18:07,896 --> 00:18:12,246
测试合适的数据类型 


541
00:18:12,246 --> 00:18:13,006
然后给它一个初始种子


542
00:18:15,976 --> 00:18:17,366
最后 我们为了保存结果


543
00:18:17,366 --> 00:18:19,276
创建了一个矩阵


544
00:18:19,276 --> 00:18:21,496
我们将运算编码至指令缓冲


545
00:18:21,496 --> 00:18:23,426
所以 现在让我们回到网络


546
00:18:23,426 --> 00:18:25,106
然后看看我们如何使用它


547
00:18:25,756 --> 00:18:27,226
这是生成器网络的


548
00:18:27,226 --> 00:18:27,926
更进一步的视图


549
00:18:27,926 --> 00:18:30,246
我们有一些卷积层


550
00:18:30,466 --> 00:18:31,786
一些 ReLu 层


551
00:18:31,786 --> 00:18:33,026
双曲正切神经元


552
00:18:33,646 --> 00:18:36,256
现在 输入图像将


553
00:18:36,256 --> 00:18:37,706
成为我们随机数生成器的结果


554
00:18:39,046 --> 00:18:40,046
正如我们之前看的


555
00:18:40,046 --> 00:18:41,266
随机数生成器


556
00:18:41,266 --> 00:18:43,406
与矩阵一起运行 但是图表


557
00:18:43,406 --> 00:18:44,416
和所有神经网络内核


558
00:18:44,416 --> 00:18:45,216
都需要图像


559
00:18:45,576 --> 00:18:47,186
所以 我们将使用我们的


560
00:18:47,186 --> 00:18:48,646
MPS 复制内核


561
00:18:49,106 --> 00:18:50,926
来将矩阵上的数据复制至一个图像上


562
00:18:53,436 --> 00:18:54,676
所以 首先我们要创建一个矩阵


563
00:18:54,676 --> 00:18:55,836
来保存我们的随机数值


564
00:18:57,576 --> 00:18:58,996
然后我们会创建一个图像


565
00:18:58,996 --> 00:19:00,606
它将会作为我们网络的输入


566
00:19:04,616 --> 00:19:05,766
我们将初始化一个


567
00:19:05,766 --> 00:19:07,706
复制内核来运行这个复制


568
00:19:09,246 --> 00:19:10,946
然后我们将编码我们的


569
00:19:10,946 --> 00:19:12,436
随机数字生成器


570
00:19:12,436 --> 00:19:13,386
来生成数值


571
00:19:13,386 --> 00:19:14,446
我们将会编码复制


572
00:19:14,726 --> 00:19:16,556
把它们复制成图像


573
00:19:16,556 --> 00:19:19,556
然后我们会使用图像


574
00:19:20,146 --> 00:19:21,226
编码网络


575
00:19:21,826 --> 00:19:25,376
现在 想要获得关于这个网络


576
00:19:25,376 --> 00:19:27,246
和使用 MPSMatrix 随机数生成器内核


577
00:19:27,246 --> 00:19:28,426
的更多细节


578
00:19:28,426 --> 00:19:30,766
请查看我们网上的文档


579
00:19:30,766 --> 00:19:31,796
这里还有一些代码样例


580
00:19:36,046 --> 00:19:36,766
现在我们增加了一些特征


581
00:19:36,766 --> 00:19:38,296
来帮助提升使用 MPS 的


582
00:19:38,296 --> 00:19:40,336
网络性能和效率


583
00:19:41,136 --> 00:19:42,006
所以 让我们来看看


584
00:19:42,006 --> 00:19:43,396
它们中的一个 预测


585
00:19:43,966 --> 00:19:46,176
通过预测 你可以


586
00:19:46,216 --> 00:19:47,966
有条件地实行 MPS 内核


587
00:19:48,836 --> 00:19:50,376
内核的实施


588
00:19:50,416 --> 00:19:52,196
在存在于 GPU 内存的


589
00:19:52,196 --> 00:19:53,736
数值上被预测


590
00:19:53,736 --> 00:19:54,976
它们在内核实施的时候被引用


591
00:19:58,226 --> 00:19:58,966
所以 让我们看一眼网络


592
00:19:58,966 --> 00:20:01,026
它说明了这个是如何使用的


593
00:20:01,846 --> 00:20:02,876
这是一个图片说明


594
00:20:03,256 --> 00:20:04,526
这是我们几年前


595
00:20:04,526 --> 00:20:06,336
展示的一个网络


596
00:20:06,336 --> 00:20:07,556
它会使用卷积神经网络


597
00:20:07,556 --> 00:20:08,756
和常返的神经网络


598
00:20:08,756 --> 00:20:11,186
来生成图片说明


599
00:20:13,116 --> 00:20:14,496
卷积网络是


600
00:20:14,496 --> 00:20:15,596
普通的分类网络


601
00:20:15,596 --> 00:20:16,976
在这个例子中 我们会使用 Inception V3


602
00:20:16,976 --> 00:20:18,946
它将会用来从


603
00:20:18,946 --> 00:20:20,136
源图像提取特征


604
00:20:20,666 --> 00:20:23,286
然后我们使用这些特征示意图


605
00:20:23,456 --> 00:20:24,686
我们把它们注入一个


606
00:20:24,686 --> 00:20:26,136
小的以 LSTM 为基础的网络


607
00:20:26,136 --> 00:20:27,226
在那里图片说明从提取的


608
00:20:27,226 --> 00:20:28,196
特征中生成


609
00:20:28,926 --> 00:20:30,026
现在 我们迭代这个网络


610
00:20:30,026 --> 00:20:31,586
来生成图片说明


611
00:20:32,216 --> 00:20:35,856
在这个例子中 我们需要知道


612
00:20:36,646 --> 00:20:38,206
在这个例子中 我们需要


613
00:20:38,206 --> 00:20:39,696
运行以 LSTM 为基础的网络


614
00:20:39,696 --> 00:20:41,486
以获得一些迭代


615
00:20:41,486 --> 00:20:42,676
它将会被修复


616
00:20:42,676 --> 00:20:43,836
我们至少需要一直这样做


617
00:20:43,836 --> 00:20:44,986
直到我们相信这样


618
00:20:44,986 --> 00:20:46,676
可以生成图片说明


619
00:20:47,926 --> 00:20:48,936
在这个例子中 比如说


620
00:20:48,936 --> 00:20:50,566
我们运行 20 次


621
00:20:50,566 --> 00:20:51,046
以 LSTM 为基础的网络


622
00:20:51,586 --> 00:20:53,956
每个迭代通过


623
00:20:53,956 --> 00:20:55,416
在之前的迭代中


624
00:20:55,416 --> 00:20:56,776
为图片说明增加一个新的词


625
00:20:56,776 --> 00:20:57,516
来计算出最好的图片说明


626
00:20:58,046 --> 00:21:00,546
但如果图片说明只要求


627
00:21:00,546 --> 00:21:02,896
五个词 那我们需要


628
00:21:02,896 --> 00:21:04,236
运行超过


629
00:21:04,236 --> 00:21:05,326
我们需要的迭代


630
00:21:06,356 --> 00:21:08,906
通过预测 我们可以早点


631
00:21:08,906 --> 00:21:09,656
结束这个执行


632
00:21:09,956 --> 00:21:12,466
在这个例子中 就是在五个单词的图片说明生成之后


633
00:21:13,466 --> 00:21:14,716
所以 让我们看看


634
00:21:14,716 --> 00:21:15,466
如何在 MPS 中使用它


635
00:21:16,206 --> 00:21:17,406
为了实现它 我们首先需要


636
00:21:17,406 --> 00:21:19,476
讨论我们是如何为 MPS 命令


637
00:21:19,476 --> 00:21:22,826
提供预测数值的


638
00:21:22,826 --> 00:21:24,356
针对这个 我们引入了


639
00:21:24,356 --> 00:21:25,236
MPSCommandBuffer


640
00:21:25,776 --> 00:21:29,536
现在 MPSCommandBuffer 


641
00:21:29,536 --> 00:21:30,216
是一个遵循 MTLCommandBuffer 协议的类


642
00:21:30,216 --> 00:21:31,426
但是它增加了


643
00:21:31,426 --> 00:21:32,836
更多一点的弹性


644
00:21:33,656 --> 00:21:34,546
它可以在任何


645
00:21:34,546 --> 00:21:36,506
你正在使用 metal 命令缓冲的地方被使用


646
00:21:36,506 --> 00:21:37,926
正如一个 MTLCommandBuffer


647
00:21:37,926 --> 00:21:39,216
它由 MTLCommandQueue 构建而成


648
00:21:39,216 --> 00:21:42,036
现在 它提供了好几个重要的好处


649
00:21:42,696 --> 00:21:43,776
它允许你预测


650
00:21:43,776 --> 00:21:46,146
MPS 内核的实施


651
00:21:46,146 --> 00:21:47,296
我们之后也会讨论到


652
00:21:47,296 --> 00:21:48,446
随着你编码你的 MPS 工作


653
00:21:48,446 --> 00:21:49,686
你可以简单地运行一些


654
00:21:49,686 --> 00:21:51,436
中间事务


655
00:21:51,436 --> 00:21:52,706
并使用一个名为 commitAndContinue 的方法


656
00:21:52,706 --> 00:21:53,766
但是我们之后再谈这个


657
00:21:54,256 --> 00:21:55,706
首先 让我们看看


658
00:21:55,706 --> 00:21:57,546
如何使用 MPSCommandBuffers


659
00:21:57,546 --> 00:21:58,766
将预测运用到 MPS 内核上


660
00:21:59,216 --> 00:22:01,836
所以一个 MPS 预测对象


661
00:22:01,836 --> 00:22:03,146
包含一个 metal 缓冲


662
00:22:03,146 --> 00:22:04,346
这个缓冲内包含了 32 位的


663
00:22:04,346 --> 00:22:05,666
整数预测数值


664
00:22:05,666 --> 00:22:06,096
它们处在偏移位置


665
00:22:07,276 --> 00:22:08,166
随着实施预测


666
00:22:08,166 --> 00:22:09,476
我们在偏移位置


667
00:22:09,476 --> 00:22:10,386
在 metal 缓冲内获得数值


668
00:22:10,576 --> 00:22:12,656
数值 0 代表


669
00:22:12,656 --> 00:22:13,916
我们不想实施这个内核


670
00:22:14,116 --> 00:22:16,336
而非零数值则意味正常实施


671
00:22:16,846 --> 00:22:18,736
在这个图表中


672
00:22:18,736 --> 00:22:19,736
我们通过在偏移位置


673
00:22:19,736 --> 00:22:21,276
将数值设定为 0 


674
00:22:21,276 --> 00:22:22,896
避开了这个内核的实施


675
00:22:23,436 --> 00:22:25,246
这个偏移很重要


676
00:22:25,246 --> 00:22:26,186
它让你可以在


677
00:22:26,186 --> 00:22:27,556
众多 MPS 预测对象中


678
00:22:27,556 --> 00:22:28,986
分享一个单一的 metal 缓冲


679
00:22:28,986 --> 00:22:29,966
这样你就可以


680
00:22:29,966 --> 00:22:30,726
向多个内核发送预测


681
00:22:31,206 --> 00:22:33,326
每个预测数值


682
00:22:33,416 --> 00:22:34,456
将会由一个不同的偏移指定


683
00:22:35,006 --> 00:22:38,106
为了使用一个


684
00:22:38,106 --> 00:22:39,826
预测数值 我们需要把它附加到


685
00:22:39,826 --> 00:22:40,686
MPSCommandBuffer


686
00:22:41,236 --> 00:22:42,576
这种情况下


687
00:22:42,576 --> 00:22:43,826
我们编码到命令缓冲的任何 MPS 内核


688
00:22:43,826 --> 00:22:45,326
都会获得预测数值


689
00:22:45,976 --> 00:22:47,096
让我们看看


690
00:22:47,096 --> 00:22:49,096
我们如何创建一个预测


691
00:22:49,096 --> 00:22:50,156
并在一个 MPSCommandBuffer 上设置


692
00:22:50,706 --> 00:22:53,976
首先 我们创建了


693
00:22:53,976 --> 00:22:56,966
一个 MPSPredicate 对象


694
00:22:57,186 --> 00:22:58,666
我们把预测附加到


695
00:22:58,666 --> 00:22:59,406
我们的 MPSCommandBuffer


696
00:22:59,966 --> 00:23:01,226
现在 我们会编码一个操作


697
00:23:01,936 --> 00:23:03,526
来修改预测数值


698
00:23:04,206 --> 00:23:06,146
因为现存的 metal 缓冲


699
00:23:06,146 --> 00:23:08,286
我们需要一个内核在 metal 缓冲中产生结果


700
00:23:08,546 --> 00:23:10,516
你可以使用你自己的内核


701
00:23:10,516 --> 00:23:11,516
或者也可以使用


702
00:23:11,516 --> 00:23:13,016
MPSMatrix 内核之一


703
00:23:13,016 --> 00:23:13,786
这就是接下来我们要做的


704
00:23:14,496 --> 00:23:16,686
我们首先要将预测包含在一个


705
00:23:16,686 --> 00:23:17,616
MPSMatrix 对象中


706
00:23:18,026 --> 00:23:19,156
然后我们将编码一个内核


707
00:23:19,156 --> 00:23:20,616
以修改预测数值


708
00:23:22,106 --> 00:23:23,106
所以 这里 我们将使用一个


709
00:23:23,106 --> 00:23:24,506
线性神经元内核


710
00:23:24,506 --> 00:23:25,926
我们将用它来做一些简单的事


711
00:23:25,926 --> 00:23:27,526
我们将要缩减预测的数值


712
00:23:28,046 --> 00:23:29,846
最后 我们将会


713
00:23:29,846 --> 00:23:31,796
编码一个 cnnKernel


714
00:23:31,796 --> 00:23:33,656
在实施之前读取预测的数值


715
00:23:37,256 --> 00:23:38,866
所以 在 MPSCommandBuffers 中


716
00:23:38,866 --> 00:23:40,716
使用预测是一个


717
00:23:40,946 --> 00:23:42,996
消除你网络中不必要工作的简单方法


718
00:23:43,666 --> 00:23:45,026
如果你有可以被避开的


719
00:23:45,026 --> 00:23:46,086
内核 你可以使用预测


720
00:23:46,086 --> 00:23:48,066
来利用减少的工作量


721
00:23:48,416 --> 00:23:49,926
如果有应用的


722
00:23:49,926 --> 00:23:51,336
多个内核


723
00:23:51,816 --> 00:23:53,136
你可以使用多个预测


724
00:23:53,376 --> 00:23:54,416
并只通过设定独特的偏移数


725
00:23:54,416 --> 00:23:56,166
值使用一个单一的 metal 缓冲


726
00:23:56,166 --> 00:23:58,916
所以 现在让我们来谈谈


727
00:23:58,916 --> 00:24:00,826
MPSCommandBuffers 的其他特征


728
00:24:01,126 --> 00:24:01,806
commitAndContinue


729
00:24:02,406 --> 00:24:05,206
这是一个可以让你


730
00:24:05,206 --> 00:24:07,126
在实施工作的时候


731
00:24:07,126 --> 00:24:09,956
更简单地获得更好的


732
00:24:09,956 --> 00:24:10,846
GPU 利用的方法


733
00:24:11,776 --> 00:24:12,936
所以 为了看看这个是如何有益的


734
00:24:12,936 --> 00:24:14,406
我们首先来复习一下


735
00:24:14,406 --> 00:24:15,356
一个典型的工作量是如何实施的


736
00:24:16,326 --> 00:24:18,046
一般实施 MPS 内核的方法是


737
00:24:18,046 --> 00:24:19,336
将你的工作编码至一个


738
00:24:19,336 --> 00:24:20,386
命令缓冲之后


739
00:24:20,386 --> 00:24:21,476
交付实施


740
00:24:21,966 --> 00:24:22,956
所以 这里我们有一个


741
00:24:22,956 --> 00:24:24,246
关于单一命令缓冲的例子


742
00:24:24,246 --> 00:24:25,246
你编码一些工作


743
00:24:25,246 --> 00:24:26,286
之后我们来实施


744
00:24:27,216 --> 00:24:28,606
现在 在实际中


745
00:24:28,606 --> 00:24:29,506
CPU 的编码时间


746
00:24:29,506 --> 00:24:31,066
将比 GPU 的实施时间


747
00:24:31,066 --> 00:24:33,316
更少 但是我们想要避免


748
00:24:33,396 --> 00:24:35,696
因为节流和类似这样的事情的


749
00:24:35,696 --> 00:24:36,846
空闲时间


750
00:24:37,966 --> 00:24:39,346
所以你可以看到


751
00:24:39,346 --> 00:24:42,956
我们将在 CPU 和 GPU 之间得到一些失速


752
00:24:43,546 --> 00:24:45,776
现在 解决这个问题的一个办法


753
00:24:45,776 --> 00:24:46,816
是使用双重缓冲


754
00:24:47,286 --> 00:24:48,976
使用双重缓冲


755
00:24:48,976 --> 00:24:49,936
我们可以保持两个


756
00:24:49,936 --> 00:24:51,156
命令缓冲 


757
00:24:51,156 --> 00:24:53,036
我们将在对一个工作进行编码的同时实施另一个


758
00:24:53,866 --> 00:24:54,746
现在 这个可以


759
00:24:55,406 --> 00:24:56,896
消除我们之前看到的空闲


760
00:24:56,896 --> 00:24:59,256
不过这个也有一些限制


761
00:24:59,686 --> 00:25:00,546
首先 正如我提到的


762
00:25:00,546 --> 00:25:01,416
你需要保留两套工作


763
00:25:01,416 --> 00:25:03,216
这意味着 你需要找到一个方法


764
00:25:03,216 --> 00:25:04,696
将你的工作划分为两个


765
00:25:04,696 --> 00:25:05,836
独立的工作量


766
00:25:06,286 --> 00:25:07,586
结果 你可以有


767
00:25:07,586 --> 00:25:09,486
大量增加的内存需求


768
00:25:11,336 --> 00:25:12,646
然而 commitAndContinue 方法


769
00:25:12,646 --> 00:25:13,986
我们可以通过将工作量


770
00:25:13,986 --> 00:25:15,046
分成更小的部分


771
00:25:15,046 --> 00:25:16,726
而获得这个性能的


772
00:25:16,726 --> 00:25:18,276
很多好处


773
00:25:19,456 --> 00:25:20,366
所以 我们将通过


774
00:25:20,366 --> 00:25:21,556
在每个命令缓冲内


775
00:25:21,556 --> 00:25:23,816
利用每层的独立来分解工作


776
00:25:24,906 --> 00:25:25,876
然后我们会使用双重缓冲


777
00:25:25,876 --> 00:25:28,046
来交付更小的组的工作


778
00:25:28,626 --> 00:25:30,596
现在 commitAndContinue


779
00:25:30,596 --> 00:25:31,676
将自动处理这个


780
00:25:31,676 --> 00:25:32,836
内部工作分配


781
00:25:32,836 --> 00:25:34,646
同时也保证


782
00:25:34,646 --> 00:25:35,826
你分配在命令缓冲上的


783
00:25:35,826 --> 00:25:37,056
临时对象都会


784
00:25:37,056 --> 00:25:39,026
对之后编码的工作保持有效


785
00:25:39,536 --> 00:25:42,226
而与双重缓冲一起


786
00:25:42,226 --> 00:25:43,576
它会保证你在 GPU


787
00:25:43,576 --> 00:25:44,856
实施工作同时


788
00:25:44,856 --> 00:25:45,706
继续在 CPU 上编码


789
00:25:46,506 --> 00:25:47,646
通过简单地允许你


790
00:25:47,646 --> 00:25:49,116
分配工作量


791
00:25:49,116 --> 00:25:50,306
你可以避免增加的对于


792
00:25:50,306 --> 00:25:51,656
双重缓冲的内存需求


793
00:25:51,766 --> 00:25:52,716
同时还可以获得


794
00:25:52,766 --> 00:25:54,016
很多提升的 GPU 使用


795
00:25:54,946 --> 00:25:55,856
所以让我们看看


796
00:25:55,856 --> 00:25:56,896
你如何在你自己的代码中将其利用


797
00:25:58,356 --> 00:26:00,316
现在我们有四个


798
00:26:00,316 --> 00:26:00,926
编码于 MTLCommandBuffer 的


799
00:26:00,926 --> 00:26:01,676
MPS 内核


800
00:26:02,246 --> 00:26:05,266
最后 我们指派实施的工作


801
00:26:06,556 --> 00:26:08,046
正如我们之前展示的


802
00:26:08,046 --> 00:26:09,636
这将会给你我们


803
00:26:09,636 --> 00:26:11,206
之前看到的停顿


804
00:26:11,446 --> 00:26:12,236
然而 通过使用


805
00:26:12,236 --> 00:26:13,886
MPSCommandBuffers 和新的


806
00:26:13,886 --> 00:26:15,166
CommitAndContinue 方法


807
00:26:15,166 --> 00:26:16,106
我们可以轻易地将其提升


808
00:26:17,226 --> 00:26:18,226
所以 我们将创建一个


809
00:26:18,226 --> 00:26:19,156
MPSCommandBuffer


810
00:26:20,476 --> 00:26:21,406
我们将编码我们的


811
00:26:21,406 --> 00:26:21,836
前两个内核


812
00:26:23,306 --> 00:26:23,936
然后我们会调用


813
00:26:23,936 --> 00:26:24,606
commitAndContinue


814
00:26:25,146 --> 00:26:27,176
它会指派我们已经编码的工作


815
00:26:27,176 --> 00:26:29,966
将任何分配


816
00:26:29,966 --> 00:26:31,136
向前发展


817
00:26:31,136 --> 00:26:32,236
并允许我们立刻继续


818
00:26:32,236 --> 00:26:33,936
对另外两个内核进行编码


819
00:26:34,696 --> 00:26:35,826
最后 我们可以使用一个


820
00:26:35,826 --> 00:26:37,196
定期的指派来指派剩下的工作


821
00:26:37,196 --> 00:26:39,896
所以你可以看到


822
00:26:39,896 --> 00:26:41,426
使用 commitAndContinue 需要


823
00:26:41,426 --> 00:26:43,676
你代码的变化是很少的


824
00:26:43,676 --> 00:26:44,596
但是如果你要利用图表


825
00:26:44,596 --> 00:26:46,426
那就更简单了


826
00:26:47,846 --> 00:26:49,206
当你使用 MPSCommandBuffe


827
00:26:49,206 --> 00:26:51,326
在一个图表中编码 MPS


828
00:26:51,326 --> 00:26:52,106
它会自动使用


829
00:26:52,106 --> 00:26:52,866
commitAndContinue


830
00:26:52,866 --> 00:26:53,956
来定期在编码过程中


831
00:26:54,346 --> 00:26:55,596
提交工作


832
00:26:56,346 --> 00:26:57,516
不需要更深一步的变化


833
00:26:57,886 --> 00:26:59,416
只是简单的使用 MPSCommandBuffer


834
00:26:59,546 --> 00:27:00,806
而不是 MTLCommandBuffer 即可


835
00:27:01,356 --> 00:27:04,076
最后 我想要指出


836
00:27:04,076 --> 00:27:05,516
你还是可以将 commitAndContinue


837
00:27:05,556 --> 00:27:06,786
与双重缓冲相结合


838
00:27:06,786 --> 00:27:09,656
同时也可以得到更好的性能


839
00:27:09,656 --> 00:27:10,816
所以正如你所见


840
00:27:10,816 --> 00:27:12,216
它允许你缩减


841
00:27:12,216 --> 00:27:14,026
我们看到的与 commitAndContinue 一起的小停顿


842
00:27:14,606 --> 00:27:16,606
所以我们有很多


843
00:27:16,606 --> 00:27:18,226
指派工作实施的选择


844
00:27:18,226 --> 00:27:20,326
你可以使用一个


845
00:27:20,326 --> 00:27:22,426
单一的命令缓冲 一次执行一个工作


846
00:27:23,186 --> 00:27:24,326
为了更好的性能


847
00:27:24,386 --> 00:27:25,786
潜在地与增加的


848
00:27:25,786 --> 00:27:26,866
内存消耗一起


849
00:27:26,866 --> 00:27:27,516
你可以使用双重缓冲


850
00:27:28,966 --> 00:27:30,906
现在 通过 MPSCommandBuffer


851
00:27:31,386 --> 00:27:32,746
你可以实现和使用 commitAndContinue


852
00:27:34,696 --> 00:27:36,766
如果你还是想要更好的性能


853
00:27:36,766 --> 00:27:39,586
你可以使用 commitAndContinue 和双重缓冲


854
00:27:39,846 --> 00:27:42,256
所以让我们看看


855
00:27:42,256 --> 00:27:44,326
这些途径如何在现实世界的网络上运行


856
00:27:44,326 --> 00:27:47,006
针对这个例子


857
00:27:47,006 --> 00:27:48,326
我们将会看看在 CIFAR-10 数据集上的


858
00:27:48,326 --> 00:27:50,076
ResNet 50 网络


859
00:27:50,746 --> 00:27:52,226
现在这个数据


860
00:27:52,226 --> 00:27:54,446
通过使用外部 AMD Radeon Pro Vega


861
00:27:54,446 --> 00:27:55,336
64 GPU 来被测算


862
00:27:56,336 --> 00:27:56,926
这是一个拥有多层的


863
00:27:56,926 --> 00:27:58,416
普通图像分类网络


864
00:27:58,416 --> 00:27:59,696
所以这是一个


865
00:27:59,696 --> 00:28:00,956
我们可以看到与 commitAndContinue 一起的好例子


866
00:28:01,146 --> 00:28:03,426
我将会把单一缓冲的例子


867
00:28:03,426 --> 00:28:05,106
作为我们的基线


868
00:28:05,436 --> 00:28:06,476
我们在垂直轴上


869
00:28:06,476 --> 00:28:08,036
有性能和内存消耗


870
00:28:08,426 --> 00:28:09,096
让我们看看


871
00:28:09,096 --> 00:28:10,016
双重缓冲是什么样的


872
00:28:10,016 --> 00:28:11,356
现在我们提升了一点性能


873
00:28:11,356 --> 00:28:12,586
但是我们同样


874
00:28:12,926 --> 00:28:14,116
提升了一点


875
00:28:14,116 --> 00:28:15,306
内存消耗


876
00:28:16,156 --> 00:28:17,146
这是因为我们可以


877
00:28:17,146 --> 00:28:18,356
通过在特定时间的飞行状态维持两倍的工作


878
00:28:18,356 --> 00:28:19,886
来实现双重缓冲


879
00:28:20,556 --> 00:28:21,486
所以 让我们来看看使用


880
00:28:21,486 --> 00:28:22,176
CommitAndContinue


881
00:28:23,296 --> 00:28:24,306
因为我们在性能上


882
00:28:24,306 --> 00:28:25,926
非常接近


883
00:28:25,926 --> 00:28:26,996
而却少了很多的内存负担


884
00:28:26,996 --> 00:28:31,186
在这里我们可以看到


885
00:28:31,186 --> 00:28:32,236
与双重缓冲一起的


886
00:28:32,236 --> 00:28:32,816
CommitAndContinue


887
00:28:33,716 --> 00:28:34,646
我们还有一些更好的性能


888
00:28:34,646 --> 00:28:37,006
但我们也同时使用


889
00:28:37,006 --> 00:28:37,856
更多的内存


890
00:28:37,856 --> 00:28:40,526
所以你可以看到


891
00:28:40,526 --> 00:28:42,316
使用 CommitAndContinue


892
00:28:42,316 --> 00:28:43,316
是一个增加最少的内存压力


893
00:28:43,316 --> 00:28:45,266
同时实现更好性能的


894
00:28:45,266 --> 00:28:46,166
非常简单的方法


895
00:28:46,786 --> 00:28:49,266
现在 让我们通过另一个机器学习的 App


896
00:28:49,266 --> 00:28:50,896
也就是去噪


897
00:28:50,896 --> 00:28:51,806
来把所有这些途径


898
00:28:51,806 --> 00:28:53,096
放在一起


899
00:28:53,096 --> 00:28:56,136
正如这个名字所示


900
00:28:56,136 --> 00:28:58,806
去噪将去除充满噪点的图像上的噪点


901
00:28:58,806 --> 00:28:59,976
并生成一个干净的图像


902
00:29:02,116 --> 00:29:03,056
我们将在光线追踪的环境中


903
00:29:03,056 --> 00:29:04,426
来看看这个例子


904
00:29:05,036 --> 00:29:07,446
如果你看了之前的


905
00:29:07,446 --> 00:29:08,796
光线追踪 metal 的视频


906
00:29:08,796 --> 00:29:09,956
你会看到降噪的另一个例子


907
00:29:09,996 --> 00:29:12,016
一个使用图像处理技术的例子


908
00:29:12,096 --> 00:29:13,176
在这里 我们将会在机器学习基础上


909
00:29:13,176 --> 00:29:15,016
看一下解决方案


910
00:29:15,586 --> 00:29:18,606
针对这个例子


911
00:29:18,606 --> 00:29:19,356
我们会看到三个阶段


912
00:29:19,356 --> 00:29:20,396
我们将创建一个


913
00:29:20,396 --> 00:29:21,236
离线训练过程


914
00:29:21,236 --> 00:29:22,526
我们将运行训练网络


915
00:29:22,526 --> 00:29:24,166
最后我们将


916
00:29:24,166 --> 00:29:25,226
把推理图表部署至


917
00:29:25,226 --> 00:29:26,346
滤波新图像


918
00:29:28,286 --> 00:29:29,916
首先 我们需要创建图表


919
00:29:30,496 --> 00:29:32,266
我们来仔细看看这个结构


920
00:29:32,866 --> 00:29:35,316
这里我们将


921
00:29:35,606 --> 00:29:38,066
开始于我们的输入图像


922
00:29:38,066 --> 00:29:39,746
也就是噪点图像


923
00:29:39,746 --> 00:29:40,946
是由我们的光线追踪产生的


924
00:29:41,556 --> 00:29:44,006
我们将会把这个图像


925
00:29:44,006 --> 00:29:45,196
注入编码的阶段


926
00:29:45,346 --> 00:29:46,436
编码器是在空间上压缩图像时


927
00:29:46,436 --> 00:29:48,276
提取更高等级的


928
00:29:48,276 --> 00:29:51,446
特征代表的小的子网络


929
00:29:51,996 --> 00:29:53,716
我们将会把这些结果


930
00:29:53,716 --> 00:29:55,286
逐渐加入我们的解码器阶段


931
00:29:55,856 --> 00:29:57,406
现在这些展示了反转过程


932
00:29:57,606 --> 00:29:58,506
它们将重新构建


933
00:29:58,506 --> 00:29:59,636
特征图中的图像


934
00:30:00,206 --> 00:30:03,646
我们还将使用跳跃连接


935
00:30:03,726 --> 00:30:05,246
它们将特征从


936
00:30:05,246 --> 00:30:07,126
编码的图像支援到


937
00:30:07,126 --> 00:30:07,576
每个解码阶段


938
00:30:08,456 --> 00:30:09,536
将每个编码器的结果转发至


939
00:30:09,536 --> 00:30:11,176
解码器就可以完成这个


940
00:30:11,986 --> 00:30:14,146
最后 降噪的图像


941
00:30:14,146 --> 00:30:14,966
是完全被重建的


942
00:30:16,086 --> 00:30:17,426
所以 让我们仔细看看


943
00:30:17,696 --> 00:30:18,796
编码器阶段


944
00:30:19,476 --> 00:30:21,386
编码器阶段在学习


945
00:30:21,386 --> 00:30:23,336
如何保留特征的同时


946
00:30:23,336 --> 00:30:24,506
压缩图像


947
00:30:24,566 --> 00:30:25,786
特征由三对卷积层


948
00:30:25,786 --> 00:30:27,586
ReLu 层


949
00:30:27,586 --> 00:30:28,756
和一个大的池化层组成


950
00:30:29,696 --> 00:30:30,676
让我们来看一下这个代码


951
00:30:31,556 --> 00:30:32,686
正如我们之前所见


952
00:30:32,686 --> 00:30:33,596
我们可以把每个节点


953
00:30:33,596 --> 00:30:35,886
按照它们在网络中的顺序进行构建


954
00:30:36,366 --> 00:30:39,316
我们也会用相同的方法构建解码器


955
00:30:39,316 --> 00:30:41,596
你可以先从一个不抽样层开始


956
00:30:42,696 --> 00:30:43,846
之后 我们通过跳跃连接


957
00:30:43,846 --> 00:30:45,056
增加对应的编码器结果


958
00:30:45,056 --> 00:30:48,046
最后


959
00:30:48,046 --> 00:30:49,286
我们有两对


960
00:30:49,286 --> 00:30:50,976
卷积层和 ReLu 层


961
00:30:53,996 --> 00:30:55,106
再次和之前一样


962
00:30:55,106 --> 00:30:56,266
我们将嵌入和网络中的每层


963
00:30:56,266 --> 00:30:57,136
对应的节点


964
00:30:58,306 --> 00:31:00,146
现在我们可以把编码器和解码器阶段


965
00:31:00,146 --> 00:31:01,566
放在一起了


966
00:31:04,916 --> 00:31:06,096
所以 首先我们将


967
00:31:06,096 --> 00:31:06,916
连接我们的编码器节点


968
00:31:09,536 --> 00:31:10,746
在我们进一步行动


969
00:31:10,746 --> 00:31:11,776
连接我们的解码节点时


970
00:31:11,776 --> 00:31:12,876
我们需要加放一个编码节点


971
00:31:12,876 --> 00:31:14,566
我们将这个节点称之为瓶颈节点


972
00:31:15,026 --> 00:31:16,266
除了它没有


973
00:31:16,266 --> 00:31:17,696
最终的大型池化层外


974
00:31:17,696 --> 00:31:18,406
它与编码器是一致的


975
00:31:18,956 --> 00:31:21,056
在瓶颈节点之后


976
00:31:21,296 --> 00:31:22,806
我们将会连接解码器节点


977
00:31:23,486 --> 00:31:25,236
通过从对应的编码器节点


978
00:31:25,266 --> 00:31:26,306
传递结果图像


979
00:31:26,306 --> 00:31:28,656
我们将满足跳跃连接


980
00:31:30,636 --> 00:31:31,876
所以现在我们有推理图表


981
00:31:32,226 --> 00:31:32,976
我们来看看训练阶段


982
00:31:35,496 --> 00:31:37,006
为了开始训练阶段


983
00:31:37,006 --> 00:31:38,086
我们需要计算损耗数值


984
00:31:38,146 --> 00:31:39,196
我们需要与推理一起启动


985
00:31:39,196 --> 00:31:40,546
我们需要与推理图表的结果


986
00:31:40,546 --> 00:31:41,416
一起启动


987
00:31:41,416 --> 00:31:43,586
对于训练迭代来说


988
00:31:43,586 --> 00:31:44,796
现在是我们的网络


989
00:31:44,866 --> 00:31:46,876
对于现有的降噪图像的最好猜测


990
00:31:47,446 --> 00:31:49,246
我们还将把干净的 RGB 图像


991
00:31:49,246 --> 00:31:51,156
作为真值


992
00:31:51,156 --> 00:31:53,076
我们将会用它来计算一个损耗数值


993
00:31:53,076 --> 00:31:55,066
我们还想要


994
00:31:55,066 --> 00:31:56,076
计算第二个损耗


995
00:31:56,566 --> 00:31:58,206
我们将运行一些边缘检测


996
00:31:58,286 --> 00:31:59,356
我们将使用


997
00:31:59,356 --> 00:32:00,706
高斯滤波器的拉普拉斯


998
00:32:01,616 --> 00:32:03,026
现在 我们想这样做是因为


999
00:32:03,546 --> 00:32:04,576 
我们想要自己的网络


1000
00:32:04,576 --> 00:32:06,096
学习如何降噪图像


1001
00:32:06,096 --> 00:32:07,086
但与此同时我们还想要


1002
00:32:07,086 --> 00:32:08,516
保证它保留了


1003
00:32:08,516 --> 00:32:09,396
原始图像的边缘


1004
00:32:10,536 --> 00:32:12,436
我们将实施


1005
00:32:12,436 --> 00:32:14,026
高斯滤波器的拉普拉斯


1006
00:32:14,026 --> 00:32:15,976
或者 LoG 滤波器使用卷积


1007
00:32:17,396 --> 00:32:19,326
最后 我们将结合这两个损耗


1008
00:32:19,486 --> 00:32:20,426
第一个损耗是 RGB 损耗


1009
00:32:20,426 --> 00:32:22,956
第二个则是 LoG 损耗


1010
00:32:22,956 --> 00:32:24,336
我们将把两者


1011
00:32:24,336 --> 00:32:25,916
结合为一个最终的损耗


1012
00:32:28,476 --> 00:32:29,956
让我们来仔细看看


1013
00:32:29,956 --> 00:32:30,666
如何做到这一点


1014
00:32:30,796 --> 00:32:32,456
我们将使用


1015
00:32:32,456 --> 00:32:34,546
推理图表的结果


1016
00:32:34,546 --> 00:32:35,796
和真值 RGB 图像


1017
00:32:35,796 --> 00:32:37,086
来创建我们的 RGB 损耗节点


1018
00:32:37,196 --> 00:32:39,476
正如你之前提到的


1019
00:32:39,476 --> 00:32:40,876
我们将使用可分离的损耗内核


1020
00:32:41,246 --> 00:32:44,316
我们将传递图像至我们的


1021
00:32:44,316 --> 00:32:45,656
源和我们的聚类


1022
00:32:46,166 --> 00:32:49,256
对于我们的 LoG 损耗


1023
00:32:49,256 --> 00:32:50,656
我们需要将 LoG 滤波器


1024
00:32:50,656 --> 00:32:52,346
应用至目标 RGB 图像


1025
00:32:52,346 --> 00:32:52,976
和推理图表的结果


1026
00:32:56,476 --> 00:32:57,676
所以我们将使用卷积节点


1027
00:32:57,676 --> 00:32:58,976
实施 LoG 滤波器


1028
00:33:02,136 --> 00:33:03,576
我们将使用卷积的结果


1029
00:33:03,576 --> 00:33:04,916
运算 LoG 损耗


1030
00:33:04,916 --> 00:33:08,116
最后 随着两个损耗都被计算


1031
00:33:08,116 --> 00:33:09,386
我们可以加它们加在一起


1032
00:33:09,386 --> 00:33:11,606
并产生最后的损耗


1033
00:33:12,186 --> 00:33:15,216
有了最后的损耗数值


1034
00:33:15,346 --> 00:33:15,876
我们可以开始


1035
00:33:15,876 --> 00:33:17,206
反向传播阶段


1036
00:33:17,206 --> 00:33:17,946
同时看一看训练图表


1037
00:33:18,976 --> 00:33:20,466
所以 我们要通过计算初始梯度


1038
00:33:20,756 --> 00:33:22,896
来实现这一点


1039
00:33:22,896 --> 00:33:25,166
初始的梯度数值


1040
00:33:25,166 --> 00:33:26,246
可以让我们开启训练图表


1041
00:33:27,316 --> 00:33:28,576
所以这包含的几个梯度节点


1042
00:33:28,576 --> 00:33:29,546
首先是为了伴随着


1043
00:33:29,546 --> 00:33:31,266
对每个正向损耗的梯度节点的增加


1044
00:33:31,266 --> 00:33:33,386
然后就是编码器和


1045
00:33:33,456 --> 00:33:35,136
解码器阶段


1046
00:33:35,926 --> 00:33:36,966
现在 为了每层实施


1047
00:33:36,966 --> 00:33:38,346
图表节点


1048
00:33:38,346 --> 00:33:39,526
将需要很多代码


1049
00:33:39,526 --> 00:33:41,526
同时为错误


1050
00:33:41,526 --> 00:33:42,626
引入很多机会


1051
00:33:43,176 --> 00:33:44,706
然而 通过隐式图表创建


1052
00:33:44,706 --> 00:33:46,396
我们可以让图表


1053
00:33:46,566 --> 00:33:47,886
为我们做所有的工作


1054
00:33:48,426 --> 00:33:51,096
所以这就是所有


1055
00:33:51,096 --> 00:33:51,976
我们需要写来生成训练图表的东西


1056
00:33:55,156 --> 00:33:56,206
首先 我们使用最后损耗的结果


1057
00:33:56,206 --> 00:33:59,046
增加初始梯度节点


1058
00:34:00,496 --> 00:34:01,686
然后使用隐式图表创建


1059
00:34:01,686 --> 00:34:03,656
我们生成所有


1060
00:34:03,656 --> 00:34:05,266
剩余的梯度节点


1061
00:34:07,436 --> 00:34:08,616
现在我们创建了我们的图表


1062
00:34:08,616 --> 00:34:10,746
我们可以开始训练它了


1063
00:34:11,295 --> 00:34:12,826
首先 让我们讨论一下


1064
00:34:12,826 --> 00:34:13,536
我们的输入训练数据


1065
00:34:14,045 --> 00:34:15,246
输入是我们知道


1066
00:34:15,246 --> 00:34:16,376
期望的结果的图像


1067
00:34:16,926 --> 00:34:17,795
在这个情况下我们有充满噪点的图像


1068
00:34:17,795 --> 00:34:19,886
同时也有相对应的干净的图像


1069
00:34:20,856 --> 00:34:22,056
现在两个图像都是熟练掌握 MPS


1070
00:34:22,056 --> 00:34:23,876
使用光线追踪器生成的


1071
00:34:23,876 --> 00:34:26,315
我们通过让


1072
00:34:26,315 --> 00:34:27,545
光线追踪器只运行短时间


1073
00:34:27,545 --> 00:34:28,716
来生成有噪点的图像


1074
00:34:29,275 --> 00:34:31,226
然后通过让光线追踪器


1075
00:34:31,226 --> 00:34:32,376
运行更长的时间


1076
00:34:32,376 --> 00:34:35,045
来获得干净的图像


1077
00:34:35,266 --> 00:34:36,045
现在 通过训练这些图像


1078
00:34:36,045 --> 00:34:37,786
我们希望我们的网络


1079
00:34:37,786 --> 00:34:38,876
会学习如何从有噪点的图像


1080
00:34:38,876 --> 00:34:40,056
接近干净的图像


1081
00:34:40,396 --> 00:34:42,025
我们还将通过一些其他图像


1082
00:34:42,025 --> 00:34:43,346
增大我们的输入数据


1083
00:34:43,346 --> 00:34:45,775
同时通过光线追踪器


1084
00:34:45,775 --> 00:34:48,826
生成曲面法线和反射率


1085
00:34:50,085 --> 00:34:51,556
反射率图像是一个


1086
00:34:51,556 --> 00:34:52,786
三通道图像 它包含着


1087
00:34:52,786 --> 00:34:55,596
反射光数量的数值


1088
00:34:55,596 --> 00:34:58,366
曲面法线


1089
00:34:58,366 --> 00:34:59,316
是一个三通道图像


1090
00:34:59,316 --> 00:35:00,556
每个通道都包含了


1091
00:35:00,556 --> 00:35:03,686
曲面法线向量的一个成分


1092
00:35:04,286 --> 00:35:06,446
现在 在我们开始训练


1093
00:35:06,446 --> 00:35:07,976
之前 我们需要做一些


1094
00:35:08,196 --> 00:35:09,926
预处理的工作


1095
00:35:09,926 --> 00:35:12,706
正如我所提到的


1096
00:35:12,706 --> 00:35:14,166
这些数据都包含在三个通道中


1097
00:35:15,336 --> 00:35:17,436
然而 MPS 网络和 MPS 


1098
00:35:17,436 --> 00:35:20,586
cnnKernels 使用它们的图像


1099
00:35:20,726 --> 00:35:21,986
作为四通道纹理


1100
00:35:22,546 --> 00:35:23,266
所以我们要


1101
00:35:23,266 --> 00:35:24,836
把这些值关联起来


1102
00:35:25,506 --> 00:35:28,186
现在 因为每个图像是


1103
00:35:28,186 --> 00:35:30,246
三个通道 我们需要将它们


1104
00:35:30,246 --> 00:35:31,136
关联到一个 metal


1105
00:35:31,136 --> 00:35:33,626
纹理数组中 我们不能


1106
00:35:33,826 --> 00:35:35,436
使用 MPS cnn 关联法 


1107
00:35:35,516 --> 00:35:38,816
因为它需要四个通道的特征通道


1108
00:35:39,636 --> 00:35:40,756
但是 我们可以编写一个


1109
00:35:40,756 --> 00:35:42,656
简单的内核来实现这一点


1110
00:35:43,646 --> 00:35:45,006
这里有一个简单的 metal 计算着色器


1111
00:35:45,006 --> 00:35:46,866
将这些图像关联在一起


1112
00:35:46,866 --> 00:35:49,306
我们将开始使用一个


1113
00:35:49,306 --> 00:35:51,276
线程栅格映射到结果的


1114
00:35:51,276 --> 00:35:52,686
每个四通道像素


1115
00:35:52,686 --> 00:35:55,026
我们的参数将作为


1116
00:35:55,026 --> 00:35:56,276
保持图像 RGB 输入


1117
00:35:56,276 --> 00:36:00,036
反照率输入和正常图像关联的结果


1118
00:36:00,586 --> 00:36:02,586
我们要让每个线程


1119
00:36:02,586 --> 00:36:04,956
从网格中每个输入的位置


1120
00:36:04,956 --> 00:36:07,166
读取一个像素


1121
00:36:08,056 --> 00:36:09,286
我们将把这些值关联


1122
00:36:09,286 --> 00:36:11,476
在一起 然后用 0 填充


1123
00:36:11,476 --> 00:36:12,926
剩余的未使用的通道


1124
00:36:17,216 --> 00:36:19,896
最后 我们要把结果写在网格中


1125
00:36:19,896 --> 00:36:21,856
相同的位置


1126
00:36:21,906 --> 00:36:23,676
现在我们有了一个着色器


1127
00:36:23,676 --> 00:36:26,076
它可以将这些值关联到


1128
00:36:26,076 --> 00:36:27,436
一个单一的 MPS 图像中 我们来看看


1129
00:36:27,436 --> 00:36:28,176
如何把它传递到图表上


1130
00:36:29,246 --> 00:36:31,086
或者 让我们先看看如何编码


1131
00:36:31,086 --> 00:36:33,536
下面是一个例子 它告诉我们如何


1132
00:36:33,536 --> 00:36:34,616
编码内核并将结果封装


1133
00:36:34,616 --> 00:36:35,696
到 MPS 图像中


1134
00:36:36,896 --> 00:36:37,856
我们的输入


1135
00:36:37,856 --> 00:36:40,326
是包含数据的图像 我们要


1136
00:36:40,496 --> 00:36:42,496
用结果作为图表的输入


1137
00:36:42,496 --> 00:36:44,006
因此我们需要构造一个 MPS 图像


1138
00:36:44,346 --> 00:36:45,506
我们将使用它的纹理


1139
00:36:45,646 --> 00:36:47,446
保存关联内核的结果


1140
00:36:47,926 --> 00:36:50,336
接下来 我们将把每个参数


1141
00:36:50,336 --> 00:36:51,856
绑定到适当的位置


1142
00:36:53,026 --> 00:36:54,976
我们将分派线程


1143
00:36:54,976 --> 00:36:56,416
然后最终传回


1144
00:36:56,626 --> 00:36:58,086
准备传递到网络中的图像


1145
00:36:58,706 --> 00:36:59,726
所以 现在输入已经


1146
00:36:59,726 --> 00:37:01,326
准备好了 我们来看看


1147
00:37:01,326 --> 00:37:02,476
执行训练图


1148
00:37:02,526 --> 00:37:04,436
在训练期间


1149
00:37:04,436 --> 00:37:06,416
我们将执行多次迭代的图表


1150
00:37:06,416 --> 00:37:07,936
我们将在每个训练集中


1151
00:37:08,006 --> 00:37:09,526
执行多个批次


1152
00:37:09,526 --> 00:37:11,016
然后每个期


1153
00:37:11,016 --> 00:37:13,976
执行多个批次


1154
00:37:16,596 --> 00:37:18,886
这里我们要对


1155
00:37:18,886 --> 00:37:19,986
训练图表进行一次迭代


1156
00:37:20,496 --> 00:37:22,956
我们将使用刚才显示的内核将


1157
00:37:22,956 --> 00:37:24,266
除了批处理中的每个图像外的


1158
00:37:24,266 --> 00:37:24,976
所有图像关联在一起 


1159
00:37:27,076 --> 00:37:28,046
我们将把这些关联放入


1160
00:37:28,046 --> 00:37:29,746
阵列中 因为


1161
00:37:29,956 --> 00:37:31,726
这个图表需要一个图像阵列


1162
00:37:31,726 --> 00:37:33,076
一个用于源图像


1163
00:37:33,076 --> 00:37:34,376
一个用于聚类


1164
00:37:34,926 --> 00:37:37,306
现在我们将在这里使用


1165
00:37:37,306 --> 00:37:38,646
MPSCommandBuffers 因为


1166
00:37:38,646 --> 00:37:39,766
正如我们前面看到的 


1167
00:37:39,766 --> 00:37:41,066
这是提高 GPU 利用率的一种


1168
00:37:41,066 --> 00:37:41,706
简单方法


1169
00:37:43,006 --> 00:37:43,946
最后 我们将


1170
00:37:43,946 --> 00:37:45,766
对图像进行编码


1171
00:37:45,766 --> 00:37:46,396
然后提交执行


1172
00:37:47,006 --> 00:37:49,136
现在 让我们仔细看看


1173
00:37:49,136 --> 00:37:49,896
每个训练期


1174
00:37:50,216 --> 00:37:51,526
在这个方案中 我们要


1175
00:37:51,526 --> 00:37:52,626
处理完整的训练


1176
00:37:52,626 --> 00:37:54,156
数据集 每个期 以便


1177
00:37:54,156 --> 00:37:55,106
更好地收敛


1178
00:37:55,796 --> 00:37:57,106
我们还会每隔几个期


1179
00:37:57,106 --> 00:37:59,476
更新一次训练集


1180
00:37:59,476 --> 00:38:00,636
这里是每 100 个期


1181
00:38:00,636 --> 00:38:04,156
此时 我们还会执行网络校验


1182
00:38:04,976 --> 00:38:06,356
最后 在每千分之一期


1183
00:38:06,356 --> 00:38:07,126
我们都要降低


1184
00:38:07,126 --> 00:38:08,386
优化器的学习率


1185
00:38:08,526 --> 00:38:10,606
这也将有助于提高收敛性


1186
00:38:10,656 --> 00:38:12,346
我们来看看它的代码


1187
00:38:12,386 --> 00:38:13,116
首先 我们要先每个期一次


1188
00:38:13,116 --> 00:38:14,496
处理一次


1189
00:38:14,496 --> 00:38:15,856
整个训练集


1190
00:38:15,856 --> 00:38:18,546
我们在这里看到的是每一个


1191
00:38:18,546 --> 00:38:18,736
第一百的期


1192
00:38:18,736 --> 00:38:19,876
我们要更新


1193
00:38:19,876 --> 00:38:21,026
我们的训练数据集


1194
00:38:21,026 --> 00:38:22,136
我们要运行校验


1195
00:38:23,416 --> 00:38:24,676
最后 每第一千的期


1196
00:38:24,676 --> 00:38:25,786
我们的学习率


1197
00:38:25,786 --> 00:38:28,936
会下降 2 倍


1198
00:38:29,166 --> 00:38:30,146
所以 现在我们已经训练了


1199
00:38:30,146 --> 00:38:32,466
这个图表 我们可以降噪新的图像


1200
00:38:33,016 --> 00:38:34,596
现在 由于 MPS 可以


1201
00:38:34,596 --> 00:38:36,006
跨多个平台使用和优化


1202
00:38:36,006 --> 00:38:38,276
我们可以轻松地


1203
00:38:38,276 --> 00:38:39,906
在不同的设备上部署训练网络


1204
00:38:40,106 --> 00:38:41,916
例如 你可能希望


1205
00:38:41,916 --> 00:38:43,366
在 Mac 上执行


1206
00:38:43,366 --> 00:38:44,816
计算开销较大的训练


1207
00:38:44,816 --> 00:38:46,636
然后使用训练网络


1208
00:38:46,636 --> 00:38:49,236
在 iPad 过滤图像


1209
00:38:49,776 --> 00:38:51,086
首先 让我们看看


1210
00:38:51,086 --> 00:38:52,546
MPS 中的串行化支持


1211
00:38:52,546 --> 00:38:55,356
现在所有 MPS 内核


1212
00:38:55,356 --> 00:38:56,616
以及图表都支持安全编码


1213
00:38:57,116 --> 00:38:58,386
这允许你轻松地


1214
00:38:58,386 --> 00:38:59,996
保存网络到磁盘上和从磁盘上恢复网络


1215
00:39:01,166 --> 00:39:02,306
对于从数据源


1216
00:39:02,306 --> 00:39:03,036
加载权重的网络


1217
00:39:03,036 --> 00:39:04,286
你必须自己在数据源上


1218
00:39:04,286 --> 00:39:06,976
实现安全编码支持


1219
00:39:07,806 --> 00:39:09,946
现在 这需要支持


1220
00:39:09,946 --> 00:39:11,016
SecureCoding 属性


1221
00:39:11,136 --> 00:39:13,016
和 init 和 encode(coder) 方法


1222
00:39:13,166 --> 00:39:14,506
现在 一旦你的数据源


1223
00:39:14,506 --> 00:39:16,246
符合安全编码


1224
00:39:16,246 --> 00:39:18,716
就很容易序列化和保存图表


1225
00:39:19,276 --> 00:39:20,576
首先 我们要创建


1226
00:39:20,576 --> 00:39:22,086
一个编码器编码图表


1227
00:39:22,816 --> 00:39:23,776
然后我们会调用


1228
00:39:23,776 --> 00:39:24,606
图表上的 encode(with:coder)


1229
00:39:24,606 --> 00:39:25,886
当这种情况发生时


1230
00:39:25,886 --> 00:39:27,116
它会序列化每个


1231
00:39:27,116 --> 00:39:28,376
单独的内核 如果这些


1232
00:39:28,376 --> 00:39:30,196
内核有数据源


1233
00:39:30,196 --> 00:39:31,406
它也会序列化它们


1234
00:39:31,716 --> 00:39:33,676
这样 生成的存档文件


1235
00:39:33,676 --> 00:39:36,996
包含恢复和初始化图表所需的所有信息


1236
00:39:38,156 --> 00:39:40,666
最后 我们可以将数据保存到文件夹中


1237
00:39:41,266 --> 00:39:43,966
现在我们来看看加载它


1238
00:39:44,746 --> 00:39:45,896
因此 为了确保


1239
00:39:45,896 --> 00:39:47,436
在未存档的内核上


1240
00:39:47,436 --> 00:39:49,266
初始化正确的 metal 设备


1241
00:39:49,266 --> 00:39:50,146
我们提供给你们


1242
00:39:50,146 --> 00:39:51,076
MPSKeyedUnarchiver


1243
00:39:51,726 --> 00:39:52,926
它就像一个常规的解压缩工具


1244
00:39:52,926 --> 00:39:54,206
只是你用一个 metal 设备


1245
00:39:54,206 --> 00:39:55,606
初始化它 然后它会在


1246
00:39:55,606 --> 00:39:56,936
所有内核初始化时


1247
00:39:56,936 --> 00:39:58,086
提供这个设备


1248
00:39:58,536 --> 00:39:59,796
因此 在加载数据之后


1249
00:39:59,796 --> 00:40:01,286
我们将使用设备创建一个


1250
00:40:01,286 --> 00:40:01,896
解压缩工具


1251
00:40:02,386 --> 00:40:03,336
我们将在新设备上


1252
00:40:03,336 --> 00:40:06,736
恢复该图 用现在初始化了的训练网络


1253
00:40:06,736 --> 00:40:09,296
可以使用该图对新图像进行降噪


1254
00:40:09,626 --> 00:40:10,536
那么 让我们来看看


1255
00:40:10,536 --> 00:40:11,386
这个网络是如何运作的


1256
00:40:11,986 --> 00:40:15,086
这里我们把我们的降噪器


1257
00:40:15,166 --> 00:40:15,676
应用了场景中


1258
00:40:16,506 --> 00:40:17,626
顶部区域显示了


1259
00:40:17,626 --> 00:40:19,236
输入噪点图像的场景


1260
00:40:19,236 --> 00:40:19,566
是什么样的


1261
00:40:20,066 --> 00:40:21,006
中心区域显示了


1262
00:40:21,006 --> 00:40:23,486
我们降噪的结果


1263
00:40:23,486 --> 00:40:24,536
你可以看到底部区域显示了


1264
00:40:24,536 --> 00:40:25,546
真值的图像


1265
00:40:26,236 --> 00:40:27,686
正如你所看到的 降噪区域


1266
00:40:27,686 --> 00:40:29,056
看起来几乎和干净的目标


1267
00:40:29,056 --> 00:40:30,956
一样好 除了我们


1268
00:40:30,956 --> 00:40:31,846
用更少的工作


1269
00:40:31,976 --> 00:40:33,086
来实现这一点 因为


1270
00:40:33,086 --> 00:40:34,356
我们没有运行完整的光线跟踪器


1271
00:40:34,946 --> 00:40:37,846
正如你所看到的 使用 MPS


1272
00:40:37,916 --> 00:40:39,156
我们可以很容易地实现复杂的网络


1273
00:40:39,156 --> 00:40:41,066
比如降噪和风格转换


1274
00:40:42,506 --> 00:40:44,206
今年我们将对


1275
00:40:44,716 --> 00:40:46,086
推理和训练的支持


1276
00:40:46,086 --> 00:40:47,086
扩展到一类新的网络


1277
00:40:47,086 --> 00:40:49,146
特征 比如可分耗损和


1278
00:40:49,146 --> 00:40:50,136
随机数字生成


1279
00:40:50,706 --> 00:40:52,856
通过 MPSCommandBuffering


1280
00:40:52,856 --> 00:40:54,136
我们现在支持通过预测和


1281
00:40:54,136 --> 00:40:55,696
commitAndContinue 改进性能和


1282
00:40:55,696 --> 00:40:57,036
获得更好的利用率


1283
00:40:57,036 --> 00:41:00,426
并且我们通过隐式图表创建


1284
00:41:00,426 --> 00:41:01,576
使所有这些特征


1285
00:41:01,576 --> 00:41:01,996
更容易使用


1286
00:41:02,566 --> 00:41:04,946
因此 有关 MPS 和 metal 的


1287
00:41:04,946 --> 00:41:06,556
更多信息 请参见


1288
00:41:06,556 --> 00:41:09,326
在线文档和我们的示例代码


1289
00:41:09,526 --> 00:41:10,706
有关 MPS 和光线跟踪的


1290
00:41:10,706 --> 00:41:12,496
更多信息 请参见前面的


1291
00:41:12,496 --> 00:41:14,976
metal 光线跟踪视频 谢谢


1292
00:41:15,516 --> 00:41:20,500
[掌声]

