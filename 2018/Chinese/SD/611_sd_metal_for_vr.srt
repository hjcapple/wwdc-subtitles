1
00:00:07,516 --> 00:00:15,500
[ 音乐 ]


2
00:00:17,516 --> 00:00:23,336
[ 掌声 ]


3
00:00:23,836 --> 00:00:24,826
>> 大家早上好


4
00:00:25,046 --> 00:00:26,676
我叫 Karol Gasinski 我是


5
00:00:26,676 --> 00:00:29,566
GPU 软件架构组的成员


6
00:00:29,566 --> 00:00:32,836
在本次会议的开头


7
00:00:32,836 --> 00:00:35,186
我们将简单概括


8
00:00:35,286 --> 00:00:38,196
macOS 中的新功能 主要和 VR 的应用有关


9
00:00:38,946 --> 00:00:40,826
然后 我们将深入探讨


10
00:00:41,046 --> 00:00:42,906
Metal 2 的新特性


11
00:00:43,136 --> 00:00:45,016
它是今年


12
00:00:45,016 --> 00:00:45,476
专为 VR 而设计的


13
00:00:46,756 --> 00:00:48,576
最后 在本次会议的结尾


14
00:00:48,576 --> 00:00:50,466
我们将讨论


15
00:00:50,626 --> 00:00:52,236
开发 VR App 的先进技术


16
00:00:53,856 --> 00:00:56,026
近来 我们推出了全新的 iMac 和 iMac Pro


17
00:00:56,116 --> 00:00:57,976
这两款产品使用了强大的


18
00:00:57,976 --> 00:01:00,776
图形处理器


19
00:01:00,776 --> 00:01:01,936
iMac 如今配有基于 ARM 的


20
00:01:01,936 --> 00:01:05,636
图形处理器 并且拥有最高 8 GB


21
00:01:05,636 --> 00:01:06,976
的视频存储器


22
00:01:07,716 --> 00:01:09,946
而 iMac Pro 配有


23
00:01:09,946 --> 00:01:11,786
更先进且更大的


24
00:01:11,786 --> 00:01:15,586
图形处理器 视频存储器容量最高可达 16 GB


25
00:01:16,546 --> 00:01:18,636
这是多么强大的功能


26
00:01:18,636 --> 00:01:19,536
现在就掌握在大家的手中


27
00:01:20,386 --> 00:01:21,516
但我们并没有


28
00:01:21,516 --> 00:01:23,406
将服务限制在 iMac 上


29
00:01:24,166 --> 00:01:25,976
我们最近宣布


30
00:01:25,976 --> 00:01:28,456
扩展了图形处理器支持 这能让你


31
00:01:28,456 --> 00:01:30,816
将任何一台 Mac 变成强大的工作站


32
00:01:30,936 --> 00:01:34,376
它将赋予你超过


33
00:01:34,376 --> 00:01:35,116
10 倍更强大的


34
00:01:35,176 --> 00:01:36,376
处理能力


35
00:01:37,126 --> 00:01:37,886
我们做的还不止这些


36
00:01:39,106 --> 00:01:40,786
今天我们介绍的是


37
00:01:40,786 --> 00:01:43,276
HTC Vive 这款头戴式显示器


38
00:01:43,406 --> 00:01:44,406
的即插即用支持


39
00:01:45,196 --> 00:01:48,966
它有两块 1440x1600


40
00:01:48,966 --> 00:01:54,826
AMOLED 的屏幕和每英寸 615 像素


41
00:01:54,956 --> 00:01:58,366
和 Vive 相比


42
00:01:58,366 --> 00:02:01,516
分辨率提高了百分之 78


43
00:02:01,566 --> 00:02:03,616
像素密度提高了百分之 57


44
00:02:03,746 --> 00:02:06,676
更强大的屏幕


45
00:02:06,786 --> 00:02:09,086
为它的新前置双摄像头系统


46
00:02:09,186 --> 00:02:11,266
提供了支持


47
00:02:11,666 --> 00:02:13,526
这样 开发者们就可以


48
00:02:13,526 --> 00:02:14,886
用这些摄像头


49
00:02:14,956 --> 00:02:16,386
在 Mac 上


50
00:02:16,386 --> 00:02:18,036
尝试直通视频


51
00:02:18,236 --> 00:02:19,486
同时加上 Vive Pro 的支持


52
00:02:19,486 --> 00:02:21,966
就得到了更加先进的跟踪系统


53
00:02:23,456 --> 00:02:25,186
那么 你现在可能想知道如何


54
00:02:25,186 --> 00:02:26,426
在 macOS 上


55
00:02:26,426 --> 00:02:28,036
开始 VR App 的开发


56
00:02:28,906 --> 00:02:32,506
HTC Vive 和 Vive Pro


57
00:02:32,506 --> 00:02:34,526
同时能和 Valve 的


58
00:02:34,826 --> 00:02:37,456
SteamVR Runtime 一起运行 这能提供


59
00:02:37,456 --> 00:02:40,226
大量的服务 其中就包括 VR 生成器


60
00:02:40,676 --> 00:02:43,936
Valve 也能让开放的 VR


61
00:02:43,936 --> 00:02:46,016
框架运行于 macOS 上 


62
00:02:46,016 --> 00:02:49,576
这样你就能通过 SteamVR 建立地图


63
00:02:50,626 --> 00:02:54,876
我们一直和 Valve 以及 HTC 紧密合作


64
00:02:54,876 --> 00:02:57,516
确保 Vive Pro 在 macOS 上的


65
00:02:57,676 --> 00:03:00,356
SteamVR Runtime 中获得支持


66
00:03:03,006 --> 00:03:04,796
那么 接下来我们来了解一下


67
00:03:04,796 --> 00:03:06,486
我们现在正在介绍的 Metal 新功能


68
00:03:06,486 --> 00:03:09,786
会如何开发 macOS Mojave 可以用来


69
00:03:09,786 --> 00:03:11,946
优化你的 VR App 的品质


70
00:03:12,036 --> 00:03:14,356
为了帮助大家回忆 让我们


71
00:03:15,086 --> 00:03:16,736
回顾一下当下


72
00:03:16,736 --> 00:03:18,786
App 和 VR 生成器之间的交互


73
00:03:18,896 --> 00:03:21,386
App 在启动时会


74
00:03:21,386 --> 00:03:23,106
将针对左眼和右眼的图像


75
00:03:23,106 --> 00:03:26,026
转换为 30 个多样本纹理


76
00:03:26,776 --> 00:03:28,306
然后它会将这些图像分解成


77
00:03:28,306 --> 00:03:30,556
iOS 表面背景纹理


78
00:03:30,726 --> 00:03:32,456
它可以进一步


79
00:03:32,456 --> 00:03:33,816
传递给 VR 生成器


80
00:03:33,816 --> 00:03:37,926
VR 生成器将会执行最终


81
00:03:37,986 --> 00:03:39,476
处理步骤


82
00:03:39,556 --> 00:03:42,446
其中包括镜头失真校正


83
00:03:42,446 --> 00:03:44,356
色差调整以及排序操作


84
00:03:44,986 --> 00:03:47,026
简单来说就是变形


85
00:03:48,426 --> 00:03:49,866
最终图像一旦生成


86
00:03:49,956 --> 00:03:52,066
就会被发送到


87
00:03:52,066 --> 00:03:53,846
头戴式设备或呈现的画面之中


88
00:03:54,936 --> 00:03:56,856
这里涉及的很多操作


89
00:03:56,916 --> 00:03:59,446
会发生两次 让我们来看一下


90
00:03:59,446 --> 00:04:02,456
你可不可以对此做些什么


91
00:04:02,766 --> 00:04:04,126
看 如今有了 VR App 


92
00:04:04,126 --> 00:04:06,656
它想要从多样本中获益


93
00:04:07,236 --> 00:04:08,806
它需要针对每只眼睛使用


94
00:04:08,976 --> 00:04:12,016
专用纹理 或者都使用


95
00:04:12,016 --> 00:04:13,666
单一的共享纹理


96
00:04:13,716 --> 00:04:15,726
但是这些布局都并不完美


97
00:04:16,576 --> 00:04:18,386
专用纹理需要


98
00:04:18,386 --> 00:04:20,505
独立的绘图调用和通道


99
00:04:20,886 --> 00:04:21,846
这正如我们所见


100
00:04:23,166 --> 00:04:25,246
而直接纹理可以


101
00:04:25,246 --> 00:04:27,296
在单一渲染和结果通道中


102
00:04:27,656 --> 00:04:30,456
进行双眼的渲染


103
00:04:30,456 --> 00:04:32,206
这些纹理在


104
00:04:32,276 --> 00:04:34,196
后期处理和效果方面会产生一些问题


105
00:04:34,736 --> 00:04:36,986
对于分层纹理拥有


106
00:04:36,986 --> 00:04:38,956
专用纹理和共享布局


107
00:04:39,126 --> 00:04:41,556
的全部优势 但是


108
00:04:41,646 --> 00:04:44,056
当下它们不能和多重采样抗锯齿一起使用


109
00:04:45,816 --> 00:04:47,506
这促使 App 开发者们


110
00:04:47,566 --> 00:04:48,826
使用不同的渲染兼用布局


111
00:04:48,936 --> 00:04:50,876
具体取决于


112
00:04:51,096 --> 00:04:54,406
他们是否想使用多重采样抗锯齿


113
00:04:54,936 --> 00:04:57,646
或使用不同诀窍来解决这一问题


114
00:04:57,866 --> 00:04:59,416
那么我们就来看看 我们可以如何优化


115
00:04:59,466 --> 00:05:00,116
这一渲染


116
00:05:02,166 --> 00:05:03,966
今天我们要介绍


117
00:05:04,056 --> 00:05:06,026
一个新的纹理


118
00:05:06,026 --> 00:05:07,396
2DMultisampleArray 纹理


119
00:05:08,366 --> 00:05:10,726
这一纹理类型拥有


120
00:05:10,726 --> 00:05:13,166
上述类型的所有优点


121
00:05:13,266 --> 00:05:15,336
而没有上述类型的任何缺点


122
00:05:15,476 --> 00:05:17,806
多亏有了它


123
00:05:17,806 --> 00:05:19,606
现在可以区分每一


124
00:05:19,606 --> 00:05:22,516
渲染空间


125
00:05:22,516 --> 00:05:24,696
这简化了后期处理


126
00:05:24,696 --> 00:05:28,286
效果 视图数


127
00:05:28,286 --> 00:05:30,016
这样 App 就可以


128
00:05:30,016 --> 00:05:33,536
轻松地返回单视场渲染


129
00:05:33,536 --> 00:05:35,406
并能控制抗锯齿模式


130
00:05:36,436 --> 00:05:38,786
作为结果 App 就能


131
00:05:38,786 --> 00:05:40,956
拥有单一渲染文件


132
00:05:40,956 --> 00:05:43,456
可以轻松运用于任何情形之中


133
00:05:43,556 --> 00:05:46,056
最重要的是


134
00:05:46,056 --> 00:05:48,206
在每种情景中 App 可以


135
00:05:48,206 --> 00:05:50,736
通过单一绘图和渲染通道


136
00:05:50,736 --> 00:05:51,056
被渲染


137
00:05:53,936 --> 00:05:55,686
那么这里我们可以看到


138
00:05:55,686 --> 00:05:57,916
创建上述 2DMultisampleArray


139
00:05:57,916 --> 00:05:59,126
纹理的代码片段


140
00:06:01,146 --> 00:06:03,446
我们将样本数设置为 4


141
00:06:03,446 --> 00:06:05,386
这样就能在质量和性能之间


142
00:06:05,426 --> 00:06:07,486
达到最佳平衡


143
00:06:07,486 --> 00:06:09,736
与此同时 我们将


144
00:06:09,826 --> 00:06:12,436
其他长度设置为 2 因为我们想


145
00:06:12,436 --> 00:06:16,346
将每只眼睛的图像存储为


146
00:06:16,446 --> 00:06:17,226
独立的切片


147
00:06:18,676 --> 00:06:21,776
那么让我们让来看看 管线会怎样


148
00:06:21,776 --> 00:06:22,376
发生变化


149
00:06:23,606 --> 00:06:25,126
我们现在可以将那些 2D


150
00:06:25,126 --> 00:06:27,396
多样本纹理用


151
00:06:27,396 --> 00:06:29,596
单一 2D 多样本阵列纹理


152
00:06:32,066 --> 00:06:32,156
纹理进行替换


153
00:06:33,136 --> 00:06:34,856
那么现在 App 就能


154
00:06:34,966 --> 00:06:38,396
在单一渲染通道进行双眼渲染


155
00:06:38,396 --> 00:06:40,686
而且如果它使用实例化


156
00:06:40,976 --> 00:06:42,356
它甚至可以在单一绘图代码中


157
00:06:42,356 --> 00:06:42,596
做到这一点


158
00:06:42,596 --> 00:06:45,606
这已经看起来很不错了


159
00:06:45,606 --> 00:06:47,266
但是我们仍然需要将那些


160
00:06:47,726 --> 00:06:49,976
2D 多样本阵列纹理切片


161
00:06:49,976 --> 00:06:52,346
变为独立的 iOS


162
00:06:52,406 --> 00:06:54,636
面部图像在我们将其传递到


163
00:06:54,636 --> 00:06:55,716
生成器之前


164
00:06:56,936 --> 00:06:59,156
那么让我们专注于我们自己的方式


165
00:06:59,156 --> 00:07:01,276
App 和生成器


166
00:07:01,306 --> 00:07:01,746
共享纹理


167
00:07:01,746 --> 00:07:04,676
那么现在 为了共享纹理


168
00:07:04,676 --> 00:07:05,826
我们使用 IOSurface


169
00:07:06,786 --> 00:07:08,316
它们在不同的进程空间


170
00:07:08,426 --> 00:07:10,086
和不同的图形处理器之间


171
00:07:10,796 --> 00:07:14,086
共享纹理 但是有着这样的


172
00:07:14,186 --> 00:07:15,466
灵活性会产生代价


173
00:07:16,436 --> 00:07:19,466
IOSurface 只可用于


174
00:07:19,466 --> 00:07:22,316
共享简单的 2D 纹理


175
00:07:22,316 --> 00:07:23,876
所以如果你有多样本纹理


176
00:07:24,266 --> 00:07:25,996
存储困难或者拥有


177
00:07:26,806 --> 00:07:27,736
复杂的纹理 它们不能被共享


178
00:07:29,046 --> 00:07:30,706
这就是为什么我们今天要介绍


179
00:07:30,706 --> 00:07:32,836
可共享的 Metal 纹理


180
00:07:32,836 --> 00:07:34,676
他们能让你的 App 


181
00:07:34,806 --> 00:07:36,486
在进程空间之间共享


182
00:07:36,796 --> 00:07:39,736
任意一种 Metal 纹理


183
00:07:39,836 --> 00:07:42,046
只要这些纹理位于


184
00:07:42,046 --> 00:07:43,106
单一图形处理器之中


185
00:07:43,996 --> 00:07:46,726
这个文件的特色是


186
00:07:46,856 --> 00:07:49,116
这些案例的高级视图


187
00:07:49,636 --> 00:07:51,956
例如 将场景的深度


188
00:07:52,036 --> 00:07:53,946
和 VR 生成器进行共享


189
00:07:54,486 --> 00:07:56,446
但是 当然并不仅限于此


190
00:07:57,256 --> 00:07:59,016
现在让我们看看如何


191
00:07:59,086 --> 00:08:00,236
来创建那些纹理


192
00:08:02,636 --> 00:08:03,906
因为可共享的纹理


193
00:08:03,996 --> 00:08:06,316
能让我们在进程之间


194
00:08:06,366 --> 00:08:08,296
传递复杂纹理 所以我们


195
00:08:08,296 --> 00:08:10,676
会创建 2D 阵列纹理


196
00:08:10,676 --> 00:08:12,936
我们会将其传递给 VR 生成器


197
00:08:13,216 --> 00:08:16,116
如你所见 我们为此


198
00:08:16,226 --> 00:08:18,126
使用了新方式


199
00:08:18,206 --> 00:08:19,426
用这个创建工具创建了新的共享纹理


200
00:08:19,976 --> 00:08:22,986
与此同时


201
00:08:23,056 --> 00:08:24,926
你必须记得使用


202
00:08:25,096 --> 00:08:27,036
Private 存储模式


203
00:08:27,036 --> 00:08:29,286
这一纹理仅能通过将其创建出来的


204
00:08:29,706 --> 00:08:33,126
图形处理器获得


205
00:08:33,876 --> 00:08:35,996
现在我们可以看到一个代码片段


206
00:08:36,456 --> 00:08:38,546
向我们展示了以前我们的 VR


207
00:08:38,546 --> 00:08:41,416
App 会如何将 IOSurface


208
00:08:41,556 --> 00:08:44,186
发送到 VR 生成器


209
00:08:44,186 --> 00:08:45,526
我们现在来看看这个代码片段


210
00:08:45,526 --> 00:08:47,656
看看需要做出哪些改变


211
00:08:47,746 --> 00:08:50,676
从而可以从使用 IOSurface 


212
00:08:50,676 --> 00:08:53,516
转变为共享的 Metal 纹理


213
00:08:54,976 --> 00:08:56,166
所以我们无须再使用这两个


214
00:08:56,166 --> 00:08:59,366
IOSurface 而且由它们


215
00:08:59,426 --> 00:09:01,006
支持的两种纹理


216
00:09:01,006 --> 00:09:03,256
现在可以被替换为


217
00:09:03,256 --> 00:09:05,686
单一可共享 Metal 纹理


218
00:09:05,976 --> 00:09:08,246
这就是目前的 2D 阵列纹理


219
00:09:09,236 --> 00:09:11,956
然后我们会将这一纹理分配给


220
00:09:12,146 --> 00:09:15,136
来自开放式 VRSDK


221
00:09:15,176 --> 00:09:19,116
的两个纹理描述器 并将它的类型


222
00:09:19,526 --> 00:09:21,416
从 IOSurface 改变为 Metal


223
00:09:21,526 --> 00:09:25,076
在完成这几项改变之后


224
00:09:25,836 --> 00:09:27,826
我们可以将针对


225
00:09:27,826 --> 00:09:31,606
左眼和右眼的图像 提交至生成器


226
00:09:32,346 --> 00:09:35,666
然后生成器就会知道 我们已经传递了


227
00:09:35,666 --> 00:09:37,446
拥有高级布局的 Metal 纹理


228
00:09:37,686 --> 00:09:40,366
而非 IOSurface 而且当我们


229
00:09:40,366 --> 00:09:42,526
查看的时候 如果它的类型是 2D 阵列纹理


230
00:09:42,856 --> 00:09:44,596
或者 2D 多样本阵列纹理


231
00:09:45,246 --> 00:09:47,336
如果是这样 那么生成器将


232
00:09:47,416 --> 00:09:49,736
自动认定


233
00:09:49,736 --> 00:09:51,546
对于左眼的图像存储于


234
00:09:51,546 --> 00:09:54,266
切片 0 之中 对于右眼的图像


235
00:09:54,266 --> 00:09:55,876
存储于 切片 1 之中


236
00:09:56,536 --> 00:09:57,916
这样你的 App 就无须


237
00:09:57,966 --> 00:09:59,396
再对此做任何其他操作


238
00:09:59,396 --> 00:10:03,326
当然 在 App


239
00:10:03,326 --> 00:10:05,266
和生成器之间


240
00:10:05,266 --> 00:10:06,806
共享 Metal


241
00:10:06,856 --> 00:10:08,636
并非是 Metal 纹理的唯一用法


242
00:10:09,436 --> 00:10:11,126
这里有几个简单的例子


243
00:10:11,126 --> 00:10:12,506
展现了你可以如何


244
00:10:12,506 --> 00:10:14,156
在任意两个进程之间


245
00:10:14,156 --> 00:10:14,956
传递 Metal 纹理


246
00:10:15,816 --> 00:10:17,766
那么我们完全按照同样的方式开始


247
00:10:18,046 --> 00:10:19,326
我们创建我们的可共享 Metal 纹理


248
00:10:19,326 --> 00:10:23,206
但如今我们从这一纹理中


249
00:10:23,286 --> 00:10:25,136
创建出了可以在


250
00:10:25,286 --> 00:10:27,456
进程空间之间传递的


251
00:10:27,456 --> 00:10:29,726
特殊共享纹理句柄


252
00:10:30,136 --> 00:10:31,176
可以通过跨进程


253
00:10:31,246 --> 00:10:32,556
通信连接


254
00:10:33,236 --> 00:10:36,056
一旦这一句柄被传递至


255
00:10:36,056 --> 00:10:39,306
其他进程 它就可以用于


256
00:10:39,306 --> 00:10:41,496
重新创建纹理对象


257
00:10:42,346 --> 00:10:44,906
但在做此的同时 你必须


258
00:10:45,006 --> 00:10:46,936
记得在与其他进程空间中


259
00:10:47,016 --> 00:10:49,096
进行创建时


260
00:10:49,096 --> 00:10:51,616
所使用的相同设备上


261
00:10:51,666 --> 00:10:53,326
重新创建你的纹理对象


262
00:10:53,896 --> 00:10:56,176
因为这一纹理不能脱离


263
00:10:56,176 --> 00:10:57,666
图形处理器的范围


264
00:10:58,266 --> 00:11:02,476
现在我们再回过来看我们的管线


265
00:11:02,716 --> 00:11:05,576
看看会发生什么变化


266
00:11:05,606 --> 00:11:07,806
现在 App 可以


267
00:11:07,806 --> 00:11:10,466
用一个 2D 阵列纹理


268
00:11:10,466 --> 00:11:13,096
替换那些分离的 IOSurface


269
00:11:13,096 --> 00:11:14,256
将针对双眼的图像存储起来


270
00:11:15,346 --> 00:11:17,406
这能够促成进一步的优化


271
00:11:18,026 --> 00:11:20,166
因为原始的 2D 多样本


272
00:11:20,166 --> 00:11:21,876
阵列纹理现在也可以


273
00:11:21,876 --> 00:11:24,236
在一个通道中加以解决


274
00:11:24,606 --> 00:11:25,906
只需通过阵列纹理


275
00:11:25,906 --> 00:11:26,736
将其创建成可共享的类型即可


276
00:11:27,706 --> 00:11:28,716
而且不止如此


277
00:11:29,486 --> 00:11:30,786
让我们来看一下生成器


278
00:11:32,286 --> 00:11:33,196
一旦我们在 App 上


279
00:11:33,196 --> 00:11:35,006
完成了渲染部件的简化


280
00:11:35,006 --> 00:11:36,596
就没有什么


281
00:11:36,716 --> 00:11:38,176
可以阻止生成器


282
00:11:38,406 --> 00:11:40,596
从这些新特性中获益


283
00:11:41,246 --> 00:11:45,056
所以生成器现在可以使用


284
00:11:45,126 --> 00:11:47,826
这些即将发布的 2D 阵列纹理


285
00:11:47,826 --> 00:11:50,086
并能在单一渲染通道中


286
00:11:50,086 --> 00:11:51,576
针对双眼执行操作


287
00:11:51,736 --> 00:11:54,836
正如你所见 我们刚刚完成了


288
00:11:54,836 --> 00:11:56,396
整条管线的简化


289
00:11:57,816 --> 00:11:59,246
那么让我们来总结一下


290
00:11:59,246 --> 00:11:59,766
我们刚刚了解到的内容


291
00:12:01,776 --> 00:12:03,266
我们刚刚描述了两种新的


292
00:12:03,266 --> 00:12:04,236
Metal 纹理


293
00:12:04,576 --> 00:12:07,846
可共享 Metal 纹理以及


294
00:12:07,846 --> 00:12:09,746
2D 多样本阵列纹理


295
00:12:09,746 --> 00:12:12,356
以及用他们来


296
00:12:12,406 --> 00:12:14,246
进一步优化你的渲染管线


297
00:12:14,326 --> 00:12:14,856
的方式


298
00:12:16,026 --> 00:12:17,406
这两种纹理马上就会


299
00:12:17,406 --> 00:12:19,326
在即将推出的 SteamVR


300
00:12:19,326 --> 00:12:20,836
Runtime 更新中获得支持


301
00:12:22,016 --> 00:12:23,686
那么现在让我们把注意力集中在


302
00:12:23,686 --> 00:12:25,166
那些可以将你 App 的


303
00:12:25,166 --> 00:12:27,376
中央处理器和图形处理器的使用


304
00:12:27,376 --> 00:12:28,736
最大化的技术之上


305
00:12:29,796 --> 00:12:32,276
这一部分我们会分为


306
00:12:32,366 --> 00:12:34,696
两个小节 先进的帧同步技术


307
00:12:34,696 --> 00:12:36,656
以及不断降低的空闲率


308
00:12:38,386 --> 00:12:40,436
我们先来讲讲帧同步技术


309
00:12:41,276 --> 00:12:43,426
在这一小节中


310
00:12:43,426 --> 00:12:45,446
我们将分析 App 的帧同步技术


311
00:12:45,536 --> 00:12:47,266
以及如何为了 VR 优化帧同步技术


312
00:12:48,306 --> 00:12:49,936
那么我们先从简单的


313
00:12:50,146 --> 00:12:52,096
单线程 App 入手


314
00:12:52,096 --> 00:12:53,646
它们在执行所有操作时都会


315
00:12:53,646 --> 00:12:54,476
采取串口监视的方式


316
00:12:55,406 --> 00:12:57,336
这样的 App 会通过调用 WaitGet 停顿


317
00:12:57,336 --> 00:12:59,816
开始处理其中的画面


318
00:13:00,866 --> 00:13:03,256
从而接收停顿


319
00:13:03,256 --> 00:13:05,866
并将其执行情况同步到


320
00:13:05,866 --> 00:13:07,256
头戴式设备的帧率之中


321
00:13:09,026 --> 00:13:11,506
Vive 和 Vive Pro 都拥有


322
00:13:11,506 --> 00:13:13,286
每秒 90 帧的刷新率


323
00:13:13,286 --> 00:13:14,936
这就意味着


324
00:13:14,986 --> 00:13:17,096
App 只需要 11.1


325
00:13:17,096 --> 00:13:19,316
毫秒就能处理一帧


326
00:13:20,086 --> 00:13:22,496
对比之下 眨一下眼


327
00:13:22,746 --> 00:13:24,756
大约需要 300 毫秒


328
00:13:25,536 --> 00:13:27,286
那么在这一时间里


329
00:13:27,286 --> 00:13:28,666
App 就能渲染 50 帧画面


330
00:13:30,326 --> 00:13:32,436
所以一旦 App 收到了


331
00:13:32,616 --> 00:13:34,736
来自 WaitGet 停顿的停顿


332
00:13:34,806 --> 00:13:37,636
它就能开始模拟你的试验


333
00:13:38,816 --> 00:13:39,886
一旦完成模拟


334
00:13:39,956 --> 00:13:41,676
也就知道了


335
00:13:41,676 --> 00:13:43,756
所有对象的状态


336
00:13:43,756 --> 00:13:46,076
App 就能继续对


337
00:13:46,206 --> 00:13:48,286
命令缓冲区进行编码


338
00:13:48,286 --> 00:13:50,386
然后将其发送至图形处理器 以实现执行目的


339
00:13:51,886 --> 00:13:54,786
一旦图形处理器完成操作


340
00:13:54,786 --> 00:13:57,416
针对双眼的图像 也就渲染完成了


341
00:13:57,416 --> 00:13:59,906
它可以被发送至 VR 生成器


342
00:13:59,906 --> 00:14:01,426
进行我们在前几张幻灯片中所讲的


343
00:14:01,516 --> 00:14:02,706
最终后期处理


344
00:14:02,706 --> 00:14:07,316
然后再从存储器中


345
00:14:07,646 --> 00:14:09,466
将各帧图像扫描到 头戴式设备的面板中


346
00:14:09,596 --> 00:14:12,266
这一传输需要额外的帧


347
00:14:12,266 --> 00:14:15,226
因为在呈现图像之前


348
00:14:15,376 --> 00:14:17,986
所有像素必须完成更新


349
00:14:19,296 --> 00:14:23,436
一旦所有像素完成更新


350
00:14:23,566 --> 00:14:25,686
头戴式设备的面板中和用户 可以看到


351
00:14:25,686 --> 00:14:26,106
一帧图像


352
00:14:27,246 --> 00:14:28,346
所以你可以看到


353
00:14:28,346 --> 00:14:29,846
从 App 收到停顿的那一刻起


354
00:14:29,926 --> 00:14:32,036
到图像真正投射出来


355
00:14:32,036 --> 00:14:35,896
的那一刻为止 一共历时 25 毫秒


356
00:14:35,976 --> 00:14:39,556
这就是为什么 App 要接收


357
00:14:39,686 --> 00:14:41,346
已经预测到


358
00:14:41,346 --> 00:14:43,296
会在未来发生的停顿


359
00:14:43,546 --> 00:14:45,116
到了发射光子的那一刻


360
00:14:45,116 --> 00:14:47,806
就可以使被渲染的


361
00:14:47,896 --> 00:14:49,946
图像可以和用户的停顿相匹配


362
00:14:50,066 --> 00:14:54,336
而这一连串


363
00:14:54,416 --> 00:14:56,046
与上一帧以及下一帧


364
00:14:56,046 --> 00:14:58,486
重叠的事件创建了我们的


365
00:14:58,516 --> 00:14:59,436
帧基础图


366
00:14:59,436 --> 00:15:02,096
如你所见


367
00:15:02,096 --> 00:15:04,966
在单线程 App 中 图形处理器


368
00:15:04,966 --> 00:15:06,446
在大部分时间中都是空闲的


369
00:15:07,826 --> 00:15:08,816
那就让我们来看看


370
00:15:08,816 --> 00:15:10,346
是否可以对此做些什么


371
00:15:11,776 --> 00:15:13,606
我们现在切换到了


372
00:15:13,606 --> 00:15:15,216
多线程 App


373
00:15:15,716 --> 00:15:17,746
它将视觉环境的模拟


374
00:15:17,776 --> 00:15:20,416
和针对图形处理器的编码操作


375
00:15:20,446 --> 00:15:22,656
分离开来


376
00:15:23,496 --> 00:15:24,996
对于这些操作的编码


377
00:15:24,996 --> 00:15:26,596
现在会在独立的


378
00:15:26,596 --> 00:15:27,356
渲染线程中进行


379
00:15:28,796 --> 00:15:29,766
因为我们已将模拟


380
00:15:29,866 --> 00:15:31,216
和编码分离开来


381
00:15:31,766 --> 00:15:33,596
所以对于帧的模拟


382
00:15:33,696 --> 00:15:36,786
可与图形处理器操作


383
00:15:36,786 --> 00:15:38,636
的上一帧编码


384
00:15:38,636 --> 00:15:39,336
同时进行


385
00:15:40,636 --> 00:15:43,316
这意味着编码现在


386
00:15:43,316 --> 00:15:45,746
已经在时间上发生了变化


387
00:15:45,796 --> 00:15:47,596
在我们收到预测的停顿之后


388
00:15:47,706 --> 00:15:48,656
编码会立即开始


389
00:15:49,216 --> 00:15:50,846
这意味着你的 App


390
00:15:50,846 --> 00:15:52,436
现在可以有更多时间


391
00:15:52,436 --> 00:15:54,736
对图形处理器进行编码


392
00:15:54,736 --> 00:15:56,666
并且图形处理器也可以有更多时间


393
00:15:56,746 --> 00:15:57,406
来处理它


394
00:15:57,406 --> 00:16:00,436
这样一来 你的 App 可以拥有更好的


395
00:16:00,436 --> 00:16:01,096
视觉化效果


396
00:16:02,856 --> 00:16:04,216
但这里有一点要注意


397
00:16:05,436 --> 00:16:07,386
因为现在模拟


398
00:16:07,386 --> 00:16:09,256
会在上一帧就开始


399
00:16:09,956 --> 00:16:12,196
所以需要独立的一组


400
00:16:12,286 --> 00:16:13,326
预测停顿


401
00:16:14,066 --> 00:16:16,586
这一组可以预测到


402
00:16:16,586 --> 00:16:18,956
未来的 56 毫秒


403
00:16:18,956 --> 00:16:20,276
这样就能和针对渲染线程


404
00:16:20,366 --> 00:16:21,886
进行预测的小组相匹配


405
00:16:22,416 --> 00:16:24,176
而且这两组会


406
00:16:24,206 --> 00:16:25,266
和发射光子的时刻相匹配


407
00:16:27,126 --> 00:16:28,646
这张图从中央处理器来看


408
00:16:28,646 --> 00:16:31,056
已经很不错了 正如我们所见


409
00:16:31,056 --> 00:16:32,276
App 在中央处理器中


410
00:16:32,276 --> 00:16:35,236
很好的分配了它的工作 但是


411
00:16:36,236 --> 00:16:37,566
让我们把重点放在图形处理器上


412
00:16:38,446 --> 00:16:43,596
如你所见 我们例子中的 App


413
00:16:43,596 --> 00:16:46,696
现在正在对所有这些图形处理器


414
00:16:46,696 --> 00:16:48,576
所有工作流程进行编码


415
00:16:48,746 --> 00:16:51,286
从而使一帧进入单一的公用缓冲区


416
00:16:51,286 --> 00:16:54,016
因此除非这一公用缓冲区已完成


417
00:16:54,016 --> 00:16:56,466
否则图形处理器就会


418
00:16:56,466 --> 00:16:57,316
处于空闲的等待状态


419
00:16:58,836 --> 00:17:00,306
不过 值得注意的是


420
00:17:00,546 --> 00:17:02,676
在中央处理器上 对图形处理器的操作


421
00:17:02,676 --> 00:17:05,336
进行编码所花费的时间


422
00:17:05,586 --> 00:17:06,796
比在图形处理器上处理这些操作


423
00:17:06,796 --> 00:17:08,165
所花费的时间要少很多


424
00:17:08,986 --> 00:17:10,336
因此我们可以利用这一事实


425
00:17:10,336 --> 00:17:13,935
并将我们的编码操作


426
00:17:13,935 --> 00:17:15,656
分解成为几个公用缓冲区


427
00:17:15,656 --> 00:17:17,876
而几个公用缓冲区


428
00:17:17,876 --> 00:17:19,276
可以进行快速编码


429
00:17:19,276 --> 00:17:21,266
仅需几步操作而已


430
00:17:21,776 --> 00:17:23,715
并尽快将其提交至


431
00:17:23,786 --> 00:17:24,336
图形处理器


432
00:17:25,626 --> 00:17:30,426
这样一来 我们就能


433
00:17:30,486 --> 00:17:33,016
在图形处理器已经处理帧的同时


434
00:17:33,016 --> 00:17:34,626
进行我们的编码


435
00:17:35,086 --> 00:17:36,826
而且如你所见


436
00:17:36,826 --> 00:17:39,926
在图形处理器进行处理的时候


437
00:17:40,036 --> 00:17:43,456
我们延长了时间


438
00:17:43,456 --> 00:17:45,216
作为结果 这样进一步增加了


439
00:17:45,216 --> 00:17:46,706
你可以在一帧中提交的工作量


440
00:17:48,156 --> 00:17:49,226
现在让我们回到我们的图表


441
00:17:49,266 --> 00:17:50,826
看一下全部放在一起


442
00:17:50,826 --> 00:17:51,906
看起来会如何


443
00:17:53,446 --> 00:17:55,636
如你所见 现在中央处理器


444
00:17:55,636 --> 00:17:57,766
和图形处理器都被完全利用起来了


445
00:17:58,746 --> 00:18:00,056
那么这样的 App 已经


446
00:18:00,056 --> 00:18:01,846
为你的 App 提供了


447
00:18:01,846 --> 00:18:03,966
很好的示范


448
00:18:03,966 --> 00:18:05,446
但我们仍有提升的空间


449
00:18:07,196 --> 00:18:09,396
你可能会注意到


450
00:18:09,506 --> 00:18:11,626
在收到预测停顿之前


451
00:18:11,696 --> 00:18:13,786
当对任何种类的图形处理器 进行编码时


452
00:18:14,306 --> 00:18:16,876
渲染线程仍然处于等待状态


453
00:18:17,566 --> 00:18:19,186
但是并非一帧里的所有工作流程


454
00:18:19,186 --> 00:18:21,486
都需要这些停顿


455
00:18:22,536 --> 00:18:24,766
那么让我们进行更加细致的分析


456
00:18:24,886 --> 00:18:26,086
来选择帧的工作负荷


457
00:18:27,486 --> 00:18:29,956
在这里 你可以看到


458
00:18:30,006 --> 00:18:32,916
工作负荷列表 它们可能会在每一帧中被执行


459
00:18:34,056 --> 00:18:35,656
其中一部分在屏幕空间中进行


460
00:18:35,656 --> 00:18:37,696
或者需要了解


461
00:18:37,696 --> 00:18:39,766
与为了渲染帧所产生的停顿


462
00:18:39,766 --> 00:18:40,736
有关的总体信息


463
00:18:41,496 --> 00:18:42,726
我们将这样的工作负荷


464
00:18:42,846 --> 00:18:44,116
称为停顿依赖性工作负荷


465
00:18:44,986 --> 00:18:46,506
与此同时


466
00:18:46,506 --> 00:18:48,746
还有一般性的


467
00:18:48,746 --> 00:18:50,056
无需与停顿有关的信息


468
00:18:50,096 --> 00:18:51,996
就能立即执行的工作负荷


469
00:18:53,096 --> 00:18:54,886
我们将这些工作负荷称为


470
00:18:54,886 --> 00:18:55,886
非停顿依赖性工作负荷


471
00:18:56,496 --> 00:18:59,306
那么现在 我们的 App 


472
00:18:59,306 --> 00:19:01,346
正在等待停顿


473
00:19:01,346 --> 00:19:02,996
以对图形处理器的任何工作进行编码


474
00:19:03,626 --> 00:19:05,336
但如果我们将这些工作负荷平分开来


475
00:19:05,336 --> 00:19:08,636
我们就能立即


476
00:19:08,636 --> 00:19:09,676
对非停顿依赖性工作负荷编码


477
00:19:09,766 --> 00:19:11,936
然后等待停顿


478
00:19:12,026 --> 00:19:15,156
以继续对停顿依赖性工作负荷编码


479
00:19:16,126 --> 00:19:19,456
在这张幻灯片中 我们已经


480
00:19:19,456 --> 00:19:21,076
将非停顿依赖性工作负荷


481
00:19:21,076 --> 00:19:23,006
与停顿依赖性工作负荷


482
00:19:23,036 --> 00:19:23,346
区分来开


483
00:19:24,516 --> 00:19:26,096
非停顿依赖性工作负荷


484
00:19:26,096 --> 00:19:27,346
现在已经在公用缓冲区


485
00:19:27,496 --> 00:19:29,096
被编码 如果将它和后面的停顿依赖性


486
00:19:29,446 --> 00:19:31,066
工作负荷比较的话


487
00:19:31,276 --> 00:19:32,746
它被标记地


488
00:19:32,746 --> 00:19:33,446
要更暗一些


489
00:19:34,336 --> 00:19:35,666
因为停顿依赖性工作负荷


490
00:19:35,666 --> 00:19:36,886
可以被立即编码


491
00:19:36,886 --> 00:19:39,146
所以我们就会


492
00:19:39,146 --> 00:19:39,376
采取如下操作


493
00:19:39,966 --> 00:19:41,526
我们会在


494
00:19:41,636 --> 00:19:42,796
上一帧工作负荷编码完成后


495
00:19:42,796 --> 00:19:43,286
立即对其编码


496
00:19:44,766 --> 00:19:46,866
这给了你的中央处理器更多时间


497
00:19:46,866 --> 00:19:49,246
以对图形处理器工作进行编码


498
00:19:49,416 --> 00:19:51,646
更重要的是 这确保了


499
00:19:51,646 --> 00:19:54,196
这一图形处理器工作


500
00:19:54,196 --> 00:19:56,556
已在图形处理器上等待被执行


501
00:19:56,556 --> 00:19:59,336
因此图形处理器就没有


502
00:19:59,336 --> 00:20:00,576
任何空闲时间


503
00:20:00,636 --> 00:20:01,846
只要上一帧完成之后


504
00:20:01,846 --> 00:20:04,086
图形处理器就会立即开始


505
00:20:04,626 --> 00:20:06,766
下一帧处理


506
00:20:06,896 --> 00:20:09,376
最后一个小节就是


507
00:20:09,376 --> 00:20:11,306
多图形处理器工作负荷的分配


508
00:20:13,226 --> 00:20:15,666
我们可以在多个图形处理器之间


509
00:20:15,666 --> 00:20:16,386
分配工作负荷


510
00:20:16,386 --> 00:20:19,226
当前的 Mac Book Pro 目前共有两个图形处理器


511
00:20:19,306 --> 00:20:21,166
虽然它们具有


512
00:20:21,166 --> 00:20:22,056
不同的性能特点


513
00:20:22,116 --> 00:20:23,616
但是我们可以


514
00:20:23,616 --> 00:20:25,366
畅通无阻地使用它们


515
00:20:26,036 --> 00:20:27,926
类似地 如果每个图形处理器相互连接起来


516
00:20:27,986 --> 00:20:29,906
那么 App 就能用它


517
00:20:29,906 --> 00:20:31,756
对头戴式设备进行渲染


518
00:20:32,096 --> 00:20:34,866
并同时使用 Mac 的主图形处理器


519
00:20:34,896 --> 00:20:35,936
对一些工作进行分流


520
00:20:39,066 --> 00:20:40,516
所以我们将


521
00:20:40,666 --> 00:20:43,286
停顿依赖性工作分离出来


522
00:20:43,566 --> 00:20:45,256
并将它移动至次图形处理器上


523
00:20:45,796 --> 00:20:48,436
我们这样做是因为这些工作


524
00:20:48,436 --> 00:20:52,046
在很久之前的帧中就已经


525
00:20:52,046 --> 00:20:53,576
完成编码 而且现在


526
00:20:53,666 --> 00:20:55,866
停顿依赖性工作负荷


527
00:20:55,866 --> 00:20:57,516
在执行上一帧


528
00:20:57,616 --> 00:20:59,746
停顿依赖性工作负荷的同时 被执行


529
00:21:00,196 --> 00:21:01,706
因此 我们进一步


530
00:21:01,706 --> 00:21:03,596
增加了你在帧方面拥有的


531
00:21:03,676 --> 00:21:04,916
图形处理器时间量


532
00:21:07,546 --> 00:21:09,856
但是 通过将这一工作分给


533
00:21:09,856 --> 00:21:13,146
多个图形处理器 我们现在到达了


534
00:21:13,256 --> 00:21:14,926
这么一种情况 我们需要一种方式


535
00:21:14,926 --> 00:21:16,886
来将这些工作负荷


536
00:21:16,886 --> 00:21:17,446
同步起来


537
00:21:22,676 --> 00:21:24,426
所以我们今天要介绍新的


538
00:21:24,426 --> 00:21:26,006
同步参数


539
00:21:26,066 --> 00:21:28,086
来处理这样的情况


540
00:21:28,816 --> 00:21:31,196
MTL Event 现在可以用于


541
00:21:31,196 --> 00:21:33,616
在不同 Metal 线索之间


542
00:21:33,616 --> 00:21:35,566
同步单个图形处理器范围内的


543
00:21:35,626 --> 00:21:38,826
图形处理器工作 而 MTL Shared Event


544
00:21:39,276 --> 00:21:41,436
拓展了这一功能


545
00:21:41,436 --> 00:21:42,886
使其可以同步


546
00:21:42,886 --> 00:21:44,816
不同图形处理器之间


547
00:21:44,986 --> 00:21:46,796
甚至不同进程之间的工作负荷


548
00:21:49,136 --> 00:21:50,996
那么在这里 我们来看看这个


549
00:21:51,106 --> 00:21:52,426
简单的代码示例


550
00:21:53,546 --> 00:21:55,406
我们的 Mac 拥有


551
00:21:55,406 --> 00:21:57,486
外置图形处理器 它通过 Thunderbolt 3 接口


552
00:21:57,486 --> 00:21:58,166
进行连接


553
00:21:58,266 --> 00:22:00,936
这一外置图形处理器将成为我们的


554
00:22:00,936 --> 00:22:04,396
主图形处理器 用于驱动头戴式设备


555
00:22:04,396 --> 00:22:06,576
这样我们就能使用 Mac 中


556
00:22:06,576 --> 00:22:08,676
已有的图形处理器作为辅助的


557
00:22:08,676 --> 00:22:09,136
次图形处理器


558
00:22:10,496 --> 00:22:12,766
然后我们会使用共享事件来


559
00:22:12,766 --> 00:22:16,896
同步两个图形处理器中的


560
00:22:18,486 --> 00:22:18,716
工作负荷


561
00:22:19,206 --> 00:22:21,816
事件的初始值为 0


562
00:22:21,816 --> 00:22:22,996
因此有必要


563
00:22:22,996 --> 00:22:25,526
从 1 开始启动同步计数器


564
00:22:26,176 --> 00:22:27,516
这是因为当我们


565
00:22:27,516 --> 00:22:30,096
在初始化事件中等待之时


566
00:22:30,276 --> 00:22:32,476
如果事件的计数器显示为 0


567
00:22:32,476 --> 00:22:34,696
事件就会立刻恢复原状


568
00:22:34,696 --> 00:22:35,976
所以就无法实现同步


569
00:22:37,786 --> 00:22:39,276
那么我们的渲染线程现在


570
00:22:39,276 --> 00:22:41,826
立即开始了针对辅助图形处理器


571
00:22:41,826 --> 00:22:43,836
的编码工作


572
00:22:44,536 --> 00:22:46,426
它会对停顿依赖性工作


573
00:22:46,426 --> 00:22:48,796
进行编码 这会发生在我们的


574
00:22:48,796 --> 00:22:50,996
次图形处理器上


575
00:22:51,026 --> 00:22:53,426
一旦这一工作完成


576
00:22:53,426 --> 00:22:55,496
结果将会存储在


577
00:22:55,646 --> 00:22:56,156
锁定存储器之中


578
00:22:56,796 --> 00:22:59,146
这就是为什么我们采用


579
00:22:59,146 --> 00:23:01,396
编码简单操作


580
00:23:01,396 --> 00:23:03,736
将这些结果传输到


581
00:23:03,736 --> 00:23:05,806
对两个图形处理器都可见


582
00:23:05,806 --> 00:23:06,676
的系统内存中


583
00:23:07,426 --> 00:23:08,786
一旦传输完成


584
00:23:08,786 --> 00:23:12,436
我们的次图形处理器就能


585
00:23:12,906 --> 00:23:15,216
安全地向我们的共享事件发出信号


586
00:23:15,866 --> 00:23:18,256
这一信号会告诉外置图形处理器


587
00:23:18,316 --> 00:23:20,236
现在接受这些结果是安全的


588
00:23:21,496 --> 00:23:23,536
所以我们的渲染线程


589
00:23:23,536 --> 00:23:24,576
执行这一些


590
00:23:24,576 --> 00:23:26,886
共用缓冲区 并且辅助图形处理器


591
00:23:26,916 --> 00:23:29,246
已经在处理这一工作


592
00:23:30,016 --> 00:23:32,336
与此同时 我们可以开始


593
00:23:32,336 --> 00:23:34,086
对驱动头戴式设备的


594
00:23:34,166 --> 00:23:36,486
主图形处理器的命令缓冲区进行编码


595
00:23:37,676 --> 00:23:39,356
在这一命令缓冲区中


596
00:23:39,356 --> 00:23:41,626
我们一开始会等待我们的


597
00:23:41,626 --> 00:23:43,446
共享事件 确保数据存储在


598
00:23:43,446 --> 00:23:45,516
在系统内存里


599
00:23:45,516 --> 00:23:47,426
只要它在那里  并且共享事件


600
00:23:47,426 --> 00:23:50,066
收到信号 那么我们可以执行一个


601
00:23:50,066 --> 00:23:51,306
简单操作


602
00:23:51,306 --> 00:23:52,516
它会通过 Thunderbolt 3 接口


603
00:23:52,516 --> 00:23:54,826
将这一数据传回


604
00:23:55,096 --> 00:23:57,856
我们的外部图形处理器中


605
00:23:57,956 --> 00:23:59,856
一旦传输完成


606
00:23:59,856 --> 00:24:01,936
执行停顿依赖性工作就会变得安全


607
00:24:01,966 --> 00:24:05,246
因此第二个命令缓冲区


608
00:24:05,556 --> 00:24:08,206
就会发出封锁事件的信号


609
00:24:08,356 --> 00:24:10,166
让停顿依赖性工作知道


610
00:24:10,166 --> 00:24:11,546
它可以开始执行操作了


611
00:24:12,366 --> 00:24:14,346
在将这两个命令缓冲区


612
00:24:14,416 --> 00:24:15,776
编码并提交之后


613
00:24:16,386 --> 00:24:18,436
渲染线程可以向往常一样继续


614
00:24:18,436 --> 00:24:20,566
等待停顿


615
00:24:20,816 --> 00:24:21,826
并在之后


616
00:24:21,916 --> 00:24:26,076
对停顿依赖性工作进行编码


617
00:24:26,296 --> 00:24:28,296
那么现在我们就有了一个


618
00:24:28,296 --> 00:24:30,306
同步不同图形处理器间


619
00:24:30,306 --> 00:24:31,146
不同工作负荷的机制


620
00:24:31,146 --> 00:24:35,156
但是你可以看到


621
00:24:35,156 --> 00:24:37,426
我们的次图形处理器仍然


622
00:24:37,426 --> 00:24:38,176
有些空闲


623
00:24:38,226 --> 00:24:40,506
这是因为在这个例子里


624
00:24:40,926 --> 00:24:43,886
我们想要设法完成


625
00:24:44,316 --> 00:24:45,846
停顿依赖性工作负荷


626
00:24:45,846 --> 00:24:47,396
即那些拥有依赖于


627
00:24:47,396 --> 00:24:48,856
停顿依赖性的工作


628
00:24:49,346 --> 00:24:49,786
抱歉


629
00:24:50,796 --> 00:24:52,156
不过 当然也有一些


630
00:24:52,206 --> 00:24:53,396
工作负荷不具


631
00:24:53,396 --> 00:24:55,086
依赖性 它们可以


632
00:24:55,216 --> 00:24:57,496
在较低频率中发生


633
00:24:57,496 --> 00:24:58,806
也就是头戴式设备的频率


634
00:24:59,576 --> 00:25:01,076
这样的工作负荷


635
00:25:01,196 --> 00:25:03,456
比如可以是


636
00:25:03,456 --> 00:25:05,076
基于物理的精准


637
00:25:05,076 --> 00:25:07,076
异常值的模拟


638
00:25:07,766 --> 00:25:11,236
或者需要大量更新时间


639
00:25:11,976 --> 00:25:12,826
的任何东西


640
00:25:13,326 --> 00:25:15,846
这样的工作负荷可以发生在


641
00:25:15,846 --> 00:25:17,316
背景中 完全


642
00:25:17,316 --> 00:25:18,846
和渲染画面不同步


643
00:25:18,846 --> 00:25:20,596
而且在它每次


644
00:25:20,596 --> 00:25:23,336
准备完成后 它的结果就会被发送至


645
00:25:23,456 --> 00:25:24,536
主图形处理器


646
00:25:25,316 --> 00:25:27,296
这里灰色的标记


647
00:25:27,626 --> 00:25:28,996
是用来表示它


648
00:25:28,996 --> 00:25:31,036
和任何特定一帧无关


649
00:25:32,516 --> 00:25:33,616
那么 当然会有


650
00:25:33,616 --> 00:25:36,016
具有不同性能特点的


651
00:25:36,066 --> 00:25:38,086
不同图形处理器 而且


652
00:25:38,086 --> 00:25:38,976
它们会具有不同


653
00:25:38,976 --> 00:25:40,146
带宽的连接


654
00:25:40,606 --> 00:25:42,966
而且你的 App 将会


655
00:25:43,086 --> 00:25:44,976
在一帧中拥有不同的工作负荷


656
00:25:44,976 --> 00:25:47,876
它们之间分别具有不同的关系


657
00:25:48,986 --> 00:25:51,676
因此你需要设计出一种方式


658
00:25:51,786 --> 00:25:53,446
让你能分配这一工作负荷


659
00:25:53,446 --> 00:25:56,406
但是说了这么多


660
00:25:56,406 --> 00:25:58,166
开始考虑


661
00:25:58,166 --> 00:26:00,076
这一图形处理器工作负荷的分配


662
00:26:00,116 --> 00:26:02,106
非常重要


663
00:26:02,106 --> 00:26:04,026
因为多图形处理器配置如今


664
00:26:04,136 --> 00:26:05,956
在 Apple 应用平台上十分常见


665
00:26:07,956 --> 00:26:10,266
那么让我们来总结一下


666
00:26:10,266 --> 00:26:11,326
我们在这一节中学到的


667
00:26:11,416 --> 00:26:11,866
所有内容


668
00:26:12,496 --> 00:26:13,426
我们展示了多线程 App


669
00:26:13,426 --> 00:26:15,986
来充分利用


670
00:26:16,076 --> 00:26:17,396
所有的中央处理器代码


671
00:26:17,466 --> 00:26:20,556
并分离了命令缓冲区


672
00:26:20,786 --> 00:26:22,666
确保图形处理器没有处于空闲状态


673
00:26:23,756 --> 00:26:25,776
在这一过程中 在可能的条件下


674
00:26:26,066 --> 00:26:26,916
我们尽量将


675
00:26:27,046 --> 00:26:28,396
非停顿依赖性工作负荷


676
00:26:28,466 --> 00:26:31,036
与停顿依赖性工作负荷划分开来


677
00:26:31,036 --> 00:26:32,946
从而尽快对这一工作进行编码


678
00:26:32,946 --> 00:26:35,746
除此之外


679
00:26:36,206 --> 00:26:38,086
我们还根据更新频率划分工作负荷


680
00:26:38,086 --> 00:26:41,126
所以如果你的 App


681
00:26:41,126 --> 00:26:42,586
会在多图形处理器配置下执行


682
00:26:42,586 --> 00:26:44,486
你可以轻松地


683
00:26:44,486 --> 00:26:47,576
在那些图形处理器中对其进行分配


684
00:26:48,126 --> 00:26:50,726
而且在这一过程中


685
00:26:51,136 --> 00:26:53,296
确保你驱动各个图形处理器时


686
00:26:53,296 --> 00:26:55,566
使用了独立的渲染线程


687
00:26:55,566 --> 00:26:57,446
从而确保它们在执行时


688
00:26:57,446 --> 00:26:58,206
是不同步的


689
00:26:59,116 --> 00:27:01,766
现在 你来到了降低填充率的部分


690
00:27:03,186 --> 00:27:04,986
Vive Pro


691
00:27:05,046 --> 00:27:07,466
为 VR App 的开发者带来了新挑战


692
00:27:08,026 --> 00:27:09,516
为了更好地认识到


693
00:27:09,516 --> 00:27:11,186
问题的严重性 我们将比较


694
00:27:11,186 --> 00:27:12,676
不同的媒介填充率


695
00:27:12,676 --> 00:27:15,756
例如


696
00:27:15,756 --> 00:27:18,556
按默认缩放比例


697
00:27:18,616 --> 00:27:21,966
对 Vive 头戴式设备进行渲染的 App 


698
00:27:22,266 --> 00:27:27,776
每秒可产生 4.36 亿像素


699
00:27:27,776 --> 00:27:29,766
而对于目前便宜的高清屏幕相比于


700
00:27:30,236 --> 00:27:32,776
最先进驱动的屏幕


701
00:27:32,776 --> 00:27:39,546
拥有每秒 4.75 亿像素


702
00:27:39,606 --> 00:27:40,156
的填充率


703
00:27:40,916 --> 00:27:43,806
这些数据已经过于大了


704
00:27:44,136 --> 00:27:45,416
以至于游戏开发者


705
00:27:45,476 --> 00:27:47,486
做出了不同的改进 来降低这一填充率


706
00:27:48,246 --> 00:27:49,856
接下来让我们看看 Vive Pro


707
00:27:49,856 --> 00:27:51,226
在这些数据上的对比情况


708
00:27:53,046 --> 00:27:55,116
Vive Pro 拥有正常的填充率


709
00:27:55,116 --> 00:27:58,676
为每秒 7.75 亿像素


710
00:27:59,146 --> 00:28:00,826
如果你增加


711
00:28:00,826 --> 00:28:02,976
4 倍多样本抗锯齿


712
00:28:03,206 --> 00:28:05,186
或者更大的缩放率


713
00:28:05,186 --> 00:28:06,486
这一数据就会变得更大


714
00:28:06,486 --> 00:28:09,786
这就是降低填充率


715
00:28:09,786 --> 00:28:11,206
为何如此重要


716
00:28:12,146 --> 00:28:13,406
现在已经有多种技术


717
00:28:13,406 --> 00:28:14,956
而且每一天都会


718
00:28:14,956 --> 00:28:15,826
产生新的技术


719
00:28:16,316 --> 00:28:19,046
所以我建议你们 把它们都尝试一遍


720
00:28:19,046 --> 00:28:22,106
但是今天我们


721
00:28:22,106 --> 00:28:24,506
只关注其中的一小部分 因为它们


722
00:28:24,506 --> 00:28:27,746
执行起来最为简单


723
00:28:27,746 --> 00:28:29,836
并能带来不错的性能提升


724
00:28:30,356 --> 00:28:31,986
那么我们先讲讲裁剪


725
00:28:31,986 --> 00:28:33,056
不可见的像素


726
00:28:33,946 --> 00:28:36,186
这里 你可以看到渲染的图像


727
00:28:36,186 --> 00:28:37,076
它针对的是左眼


728
00:28:38,526 --> 00:28:40,566
但是因为


729
00:28:40,566 --> 00:28:44,766
镜头的性质 大约 20% 的


730
00:28:44,896 --> 00:28:47,646
像素会在生成器


731
00:28:47,726 --> 00:28:50,156
执行失真校正后丢失


732
00:28:50,786 --> 00:28:52,166
在右侧 你可以看到


733
00:28:52,216 --> 00:28:53,796
将在通过镜头之前


734
00:28:53,796 --> 00:28:55,746
展示在头戴式设备面板上


735
00:28:55,746 --> 00:28:56,706
的图像


736
00:28:58,746 --> 00:29:00,896
所以 最简单的


737
00:29:00,896 --> 00:29:03,836
降低填充率的方式就是防止我们的


738
00:29:03,836 --> 00:29:05,426
App 渲染那些


739
00:29:05,486 --> 00:29:07,066
完全不可见的像素


740
00:29:07,066 --> 00:29:09,616
你可以


741
00:29:09,616 --> 00:29:12,176
通过使用 SteamVR Stencil Mask


742
00:29:12,176 --> 00:29:12,946
轻松实现


743
00:29:14,416 --> 00:29:18,836
那么我们刚刚降低了百分之 20 的


744
00:29:18,836 --> 00:29:20,406
填充率 借助了这一


745
00:29:20,406 --> 00:29:22,626
简单的遮罩 并将我们 Vive


746
00:29:22,966 --> 00:29:26,806
Pro 的填充率降至 6.2 亿像素


747
00:29:29,286 --> 00:29:32,236
现在我们来分析一下


748
00:29:32,276 --> 00:29:33,776
执行这一镜头失真校正


749
00:29:33,776 --> 00:29:35,326
的更多细节


750
00:29:36,336 --> 00:29:40,836
我们可以将我们的视场


751
00:29:40,836 --> 00:29:42,936
分为九个区域


752
00:29:43,886 --> 00:29:45,986
中心区域的视野


753
00:29:45,986 --> 00:29:48,396
水平为 80 度


754
00:29:48,456 --> 00:29:51,276
垂直为 80 度


755
00:29:51,276 --> 00:29:53,206
周围区域


756
00:29:53,266 --> 00:29:54,396
位于边缘和角落里


757
00:29:55,306 --> 00:29:57,596
我们为它们上了色


758
00:29:57,596 --> 00:29:58,956
从而可以更好地看到


759
00:29:58,956 --> 00:30:00,726
它们对最终图像的影响


760
00:30:01,306 --> 00:30:05,196
正如你所见


761
00:30:05,196 --> 00:30:08,236
角落几乎完全不可见


762
00:30:08,506 --> 00:30:11,786
和原来的相比


763
00:30:11,786 --> 00:30:13,596
边缘对图像的影响


764
00:30:13,626 --> 00:30:14,696
会更小


765
00:30:15,486 --> 00:30:17,996
事实上 如果你


766
00:30:17,996 --> 00:30:19,996
在头戴式设备中看这幅图像


767
00:30:20,066 --> 00:30:22,616
你是无法直接看到红色


768
00:30:22,726 --> 00:30:23,346
区域的


769
00:30:24,126 --> 00:30:25,846
可以看到这些图像的唯一方式


770
00:30:25,846 --> 00:30:27,366
就是使用你的周边视觉


771
00:30:28,886 --> 00:30:31,666
这就给了我们很大的启发


772
00:30:33,306 --> 00:30:35,186
我们可以通过较低的填充率


773
00:30:35,236 --> 00:30:37,626
渲染这些边角区域


774
00:30:37,626 --> 00:30:40,086
因为不管怎么说


775
00:30:40,086 --> 00:30:41,046
它们几乎不可见


776
00:30:42,276 --> 00:30:45,056
我们渲染了中心区域


777
00:30:45,056 --> 00:30:45,956
如同之前一样


778
00:30:47,296 --> 00:30:49,046
但之后在渲染垂直边缘时


779
00:30:49,046 --> 00:30:51,856
我们会将宽度减半


780
00:30:51,906 --> 00:30:53,946
对于水平区域


781
00:30:53,976 --> 00:30:54,686
则将高度减半


782
00:30:54,686 --> 00:30:56,966
最后 在渲染角落区域时


783
00:30:57,026 --> 00:31:00,306
我们会将分辨率降至


784
00:31:00,306 --> 00:31:01,066
四分之一


785
00:31:03,076 --> 00:31:05,166
当我们完成昂贵的


786
00:31:05,246 --> 00:31:06,976
渲染通道之后 我们会


787
00:31:06,976 --> 00:31:09,606
执行廉价的放大通道


788
00:31:09,606 --> 00:31:11,416
让这些区域


789
00:31:11,646 --> 00:31:13,276
拉伸至


790
00:31:13,276 --> 00:31:15,356
需要提交给生成器的分辨率


791
00:31:16,386 --> 00:31:18,186
那么你可能会好奇


792
00:31:18,226 --> 00:31:20,166
这样我们可以获得多少提升


793
00:31:21,316 --> 00:31:23,576
对于 80x80 度


794
00:31:23,576 --> 00:31:25,546
的中央区域 我们将我们的


795
00:31:25,546 --> 00:31:27,556
填充率一下子降到了


796
00:31:27,556 --> 00:31:30,586
每秒 4.91 亿像素


797
00:31:31,736 --> 00:31:32,936
但是你应该记得我们刚刚


798
00:31:32,996 --> 00:31:34,666
提到了裁剪不可见像素


799
00:31:34,666 --> 00:31:36,866
所以让我们


800
00:31:36,946 --> 00:31:38,036
将这两个技术结合起来


801
00:31:40,016 --> 00:31:42,456
通过将像素裁剪


802
00:31:42,456 --> 00:31:44,016
和多分辨率变化结合起来


803
00:31:44,016 --> 00:31:45,696
你甚至可以进一步将填充率


804
00:31:45,696 --> 00:31:48,796
降至每秒 4.56 亿像素


805
00:31:48,796 --> 00:31:50,996
这并不是一个随机数字


806
00:31:51,696 --> 00:31:54,196
事实上这是


807
00:31:54,196 --> 00:31:57,456
Vive 头戴式设备的默认填充率


808
00:31:57,456 --> 00:31:59,176
所以仅仅通过使用这两项优化技术


809
00:31:59,176 --> 00:32:01,246
你的 App 就可以


810
00:32:01,246 --> 00:32:03,536
使用与渲染 Vive 头戴式设备时


811
00:32:03,536 --> 00:32:05,796
所使用的相同图形处理器


812
00:32:05,796 --> 00:32:08,386
而得到更高的分辨率


813
00:32:08,386 --> 00:32:09,796
对 Vive Pro 进行渲染


814
00:32:10,816 --> 00:32:12,486
当然 你也可以


815
00:32:12,556 --> 00:32:13,626
在对 Vive 进行渲染时


816
00:32:13,626 --> 00:32:15,346
使用这些技术


817
00:32:15,346 --> 00:32:17,306
这能让你 App 的视觉化效果


818
00:32:17,566 --> 00:32:19,386
更加突出


819
00:32:20,106 --> 00:32:21,046
更加美观


820
00:32:21,626 --> 00:32:25,306
这里要提醒一下


821
00:32:25,676 --> 00:32:27,166
多分辨率变化


822
00:32:27,296 --> 00:32:30,356
需要一些新的渲染通道


823
00:32:30,356 --> 00:32:34,006
所以它会在几何管线上


824
00:32:34,126 --> 00:32:36,356
增加你的工作负荷


825
00:32:36,356 --> 00:32:38,466
但你可以轻松缓解这一问题


826
00:32:38,516 --> 00:32:39,996
只需将你的中心区域


827
00:32:39,996 --> 00:32:41,746
降低几度


828
00:32:42,556 --> 00:32:44,036
这里 仅将我们的中心视野


829
00:32:44,036 --> 00:32:45,996
降低了 10 度


830
00:32:46,486 --> 00:32:48,026
我们就将填充率一下子降低到了


831
00:32:48,026 --> 00:32:50,826
每秒 3.82 亿像素


832
00:32:51,546 --> 00:32:53,956
而且如果你的几何图形的工作负荷


833
00:32:53,956 --> 00:32:56,606
非常高 你可以更进一步


834
00:32:56,696 --> 00:32:59,146
尝试更低的填充率


835
00:32:59,146 --> 00:33:02,116
更低的区域


836
00:33:02,446 --> 00:33:03,966
这会将填充率降得更低


837
00:33:04,846 --> 00:33:07,206
对于 55x55 度的


838
00:33:07,206 --> 00:33:10,446
中心区域 你百分之 80 的


839
00:33:11,266 --> 00:33:12,536
眼部动作仍然会


840
00:33:12,536 --> 00:33:15,546
位于这一区域之中 但是


841
00:33:15,546 --> 00:33:17,426
我们将我们的填充率


842
00:33:17,426 --> 00:33:20,016
减少了一大半


843
00:33:20,146 --> 00:33:23,476
降至每秒 3.6 亿像素


844
00:33:23,696 --> 00:33:25,116
当然 还有其他


845
00:33:25,116 --> 00:33:26,316
方法可以实现


846
00:33:26,366 --> 00:33:29,446
多分辨率变化


847
00:33:30,466 --> 00:33:32,326
而且你会从中获得


848
00:33:32,416 --> 00:33:34,626
不同的性能提升


849
00:33:34,816 --> 00:33:36,366
所以我建议大家


850
00:33:36,366 --> 00:33:37,966
尝试这一技术


851
00:33:38,006 --> 00:33:39,446
看看什么最适合你


852
00:33:41,546 --> 00:33:42,926
下面让我们来总结一下


853
00:33:42,926 --> 00:33:46,986
我们在本次会议中 学到的所有内容


854
00:33:47,086 --> 00:33:48,676
我们刚刚公布了针对 Vive Pro 头戴式设备


855
00:33:48,716 --> 00:33:50,446
的即插即用支持


856
00:33:50,486 --> 00:33:53,526
并且介绍了


857
00:33:53,526 --> 00:33:55,256
Metal 2 的新特性 它们能使你


858
00:33:55,256 --> 00:33:57,306
开发更多的


859
00:33:57,306 --> 00:33:58,916
先进的 VR App


860
00:33:59,726 --> 00:34:01,486
然后我建议大家


861
00:34:01,486 --> 00:34:03,246
利用多图形处理器配置


862
00:34:03,246 --> 00:34:05,006
因为它们现在


863
00:34:05,006 --> 00:34:07,416
在 Apple 平台上变得越来越常见


864
00:34:08,076 --> 00:34:12,136
你可以通过这个链接


865
00:34:12,136 --> 00:34:14,106
了解有关本次会议的更多内容


866
00:34:14,106 --> 00:34:16,335
我想邀请大家


867
00:34:16,525 --> 00:34:17,606
在 Metal 4 VR 实验室里


868
00:34:17,606 --> 00:34:19,616
和我以及我的同事见面


869
00:34:19,616 --> 00:34:21,766
时间就定在今天


870
00:34:21,766 --> 00:34:24,136
中午 12 点 地点在 6 号


871
00:34:24,136 --> 00:34:24,536
科技实验室


872
00:34:24,626 --> 00:34:26,976
非常感谢大家


873
00:34:27,516 --> 00:34:30,500
[ 掌声 ]

