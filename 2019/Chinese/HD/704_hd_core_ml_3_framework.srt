1
00:00:06,473 --> 00:00:11,245 line:0
（CORE ML 3框架）


2
00:00:15,482 --> 00:00:17,518 line:-2
大家好 我是
Michael Brennan


3
00:00:17,584 --> 00:00:20,387 line:-2
我是Apple的一名工程师
致力于Core ML


4
00:00:21,321 --> 00:00:23,690 line:-1
今天能与大家一起分享


5
00:00:23,757 --> 00:00:27,895 line:-2
我们今年在Core ML 3中
引入的一些新功能 我感到万分激动


6
00:00:30,430 --> 00:00:32,366 line:-1
Core ML尽可能地简化了


7
00:00:32,966 --> 00:00:35,536 line:-1
把机器学习无缝集成到app的过程


8
00:00:36,737 --> 00:00:40,307 line:-2
可以让你创建多种多样的新奇
和引人注目的体验


9
00:00:41,375 --> 00:00:44,244 line:-1
而这一切的中心就是模型自身


10
00:00:47,047 --> 00:00:47,881 line:-1
你可以从许多所支持的训练库中


11
00:00:48,549 --> 00:00:50,284 line:-1
获得模型


12
00:00:50,851 --> 00:00:53,053 line:-2
通过使用我们作为
Core ML工具的一部分


13
00:00:53,620 --> 00:00:55,522 line:-1
所提供的转换器转换训练库来实现


14
00:00:57,291 --> 00:01:00,727 line:-2
通过添加新的
Create ML app


15
00:01:01,094 --> 00:01:04,331 line:-1
我们把获得模型的过程变得更简单了


16
00:01:05,331 --> 00:01:06,466 line:-1
（在设备上实现模型个性化）


17
00:01:06,967 --> 00:01:08,902 line:-1
在这场演讲中 我们要讲许多话题


18
00:01:09,536 --> 00:01:11,805 line:-1
从在设备上个性化模型


19
00:01:12,372 --> 00:01:14,474 line:-1
到我们对神经网络所添加的额外支持


20
00:01:15,042 --> 00:01:16,009 line:-1
等等


21
00:01:17,578 --> 00:01:19,112 line:-1
让我们先讲


22
00:01:19,546 --> 00:01:21,448 line:-1
在设备上个性化你的模型


23
00:01:24,785 --> 00:01:25,853 line:-1
从传统上说


24
00:01:26,353 --> 00:01:29,489 line:-2
这些模型要么与app绑定
要么下载到app


25
00:01:30,123 --> 00:01:32,092 line:-2
一旦你的设备上有了模型
模型就是完全可变的


26
00:01:32,926 --> 00:01:35,696 line:-2
并在你的app内针对性能进行了
大量优化


27
00:01:38,932 --> 00:01:40,934 line:-2
关于把你的app与模型相关联
最棒的是


28
00:01:41,235 --> 00:01:44,705 line:-2
这意味着你可以为所有用户提供
同样优秀的体验


29
00:01:46,473 --> 00:01:47,641 line:-1
但每个用户都是独一无二的


30
00:01:49,276 --> 00:01:50,911 line:-1
他们每个人都有自己的特别需求


31
00:01:51,445 --> 00:01:54,248 line:-1
他们自己的与app相交互的方式


32
00:01:55,482 --> 00:01:56,950 line:-1
我认为这为我们创造了一个机遇


33
00:01:59,219 --> 00:02:01,154 line:-1
如果每个用户都能得到一个


34
00:02:01,522 --> 00:02:03,357 line:-1
特别为他们个性化的模型怎么样？


35
00:02:05,526 --> 00:02:07,861 line:-2
嗯 让我们以一个用户为例
看看如何实现


36
00:02:08,996 --> 00:02:10,297 line:-1
我们可以获取那个用户的数据


37
00:02:11,298 --> 00:02:12,733 line:-1
设置一种云服务


38
00:02:13,734 --> 00:02:15,469 line:-1
向那个云服务发送用户数据


39
00:02:16,303 --> 00:02:18,172 line:-2
并在云内创建那个
针对用户数据个性化的新模型


40
00:02:18,505 --> 00:02:21,375 line:-1
然后再把模型部署给用户


41
00:02:23,277 --> 00:02:24,478 line:-1
这给你们开发人员以及我们的用户们


42
00:02:24,545 --> 00:02:26,980 line:-1
带来了许多挑战


43
00:02:28,815 --> 00:02:32,586 line:-1
对你们而言 挑战是


44
00:02:32,653 --> 00:02:35,189 line:-2
使用这些云服务管理那种个性化服务
增加了费用


45
00:02:35,756 --> 00:02:38,225 line:-2
以及创建一个可以扩展到百万用户的
基础设施


46
00:02:39,526 --> 00:02:40,494 line:-1
对用户来说


47
00:02:40,561 --> 00:02:42,296 line:-1
很显然他们需要暴露他们的全部数据


48
00:02:43,130 --> 00:02:45,165 line:-2
他们并不想这样做
这有一定的侵入性


49
00:02:45,232 --> 00:02:47,100 line:-2
他们不得不暴露自己的数据
并把它发送到云上


50
00:02:47,167 --> 00:02:49,036 line:-1
而这些数据将由另一方进行管理


51
00:02:51,505 --> 00:02:52,539 line:-1
在Core ML 3上


52
00:02:53,273 --> 00:02:56,276 line:-2
你可以完全在设备上执行这种
个性化操作


53
00:03:03,684 --> 00:03:04,985 line:-1
获取具有用户所创建


54
00:03:05,652 --> 00:03:07,921 line:-1
或重新生成的数据的那个通用模型


55
00:03:09,056 --> 00:03:10,924 line:-1
你可以用那些数据


56
00:03:11,358 --> 00:03:12,392 line:-1
对用户个性化那个模型


57
00:03:14,962 --> 00:03:16,830 line:-1
这意味着数据将保持私密性


58
00:03:17,531 --> 00:03:18,599 line:-1
它永远不会离开设备


59
00:03:19,733 --> 00:03:22,636 line:-2
这意味着不需要服务器来执行
这种交互性


60
00:03:23,937 --> 00:03:25,305 line:-2
并且这还意味着你可以在任何地方
执行个性化操作


61
00:03:25,372 --> 00:03:28,675 line:-2
好吧 你不会仅仅为了要更新
用户的模型


62
00:03:29,276 --> 00:03:30,310 line:-2
而把用户束缚在Wi-Fi
或一些数据计划上


63
00:03:30,944 --> 00:03:32,246 line:-1
（模型剖析）


64
00:03:33,413 --> 00:03:35,249 line:-2
在我们继续讲之前
先深入了解一下其中一个模型


65
00:03:35,315 --> 00:03:36,884 line:-1
看看有什么变化


66
00:03:38,886 --> 00:03:41,522 line:-1
目前 你的模型主要由参数组成


67
00:03:41,889 --> 00:03:43,423 line:-1
一些诸如各层权重这样的东西


68
00:03:43,490 --> 00:03:44,791 line:-1
如果有神经网络的话 比如说


69
00:03:45,425 --> 00:03:47,561 line:-2
还有一些元数据
描述诸如许可证这样的东西


70
00:03:48,161 --> 00:03:50,664 line:-1
还有作者以及一个界面


71
00:03:50,731 --> 00:03:52,132 line:-1
这就是app自身所关注的地方


72
00:03:52,866 --> 00:03:54,635 line:-1
它描述了你如何与这个模型相交互


73
00:03:56,503 --> 00:03:57,538 line:-1
在Core ML 3上


74
00:03:57,804 --> 00:04:00,541 line:-1
我们添加了一组新参数 用于更新


75
00:04:00,607 --> 00:04:03,410 line:-2
这组新参数描述了模型的哪些部分
可以进行更新以及如何更新


76
00:04:04,011 --> 00:04:06,180 line:-1
我们添加了一个新的更新界面


77
00:04:06,246 --> 00:04:07,381 line:-1
你的app可以用于执行这些更新


78
00:04:10,584 --> 00:04:12,219 line:-1
这意味着可以通过那个界面


79
00:04:12,686 --> 00:04:14,321 line:-1
直接获取全部功能


80
00:04:14,688 --> 00:04:17,024 line:-1
我们压缩了大量细节


81
00:04:17,524 --> 00:04:20,027 line:-1
这些都包含在那一个模型文件中


82
00:04:22,329 --> 00:04:23,764 line:-1
因此就像是做预测一样


83
00:04:23,830 --> 00:04:26,667 line:-2
我们提供一组输入
你得到一组相应的输出


84
00:04:27,801 --> 00:04:29,102 line:-1
更新非常简单


85
00:04:29,169 --> 00:04:30,737 line:-1
你只需要提供一组训练样本


86
00:04:31,171 --> 00:04:32,806 line:-1
你就能得到那个模型的新版本


87
00:04:33,140 --> 00:04:34,842 line:-2
这个新版本是针对那些数据进行适应
或调整的


88
00:04:36,176 --> 00:04:37,477 line:-1
（所支持的模型类型）


89
00:04:38,145 --> 00:04:39,179 line:-1
对Core ML 3而言


90
00:04:39,479 --> 00:04:42,783 line:-1
我们支持给最近邻分类器


91
00:04:43,217 --> 00:04:44,351 line:-1
以及神经网络创建可更新的模型


92
00:04:44,885 --> 00:04:46,653 line:-1
并且我们还将支持在你的管道内


93
00:04:46,720 --> 00:04:47,654 line:-1
嵌入一个可支持的模型


94
00:04:48,121 --> 00:04:49,823 line:-1
意思是你的管道也变得可更新了


95
00:04:52,092 --> 00:04:53,126 line:-2
（演示
PRSONALIZED GRADING APP）


96
00:04:53,193 --> 00:04:55,362 line:-2
有了这些信息 我认为我们应该
在实际操作中具体看一下


97
00:04:56,263 --> 00:04:58,298 line:-2
因此我要把舞台交给
我同事Anil Katti


98
00:04:59,032 --> 00:04:59,900 line:-1
Anil


99
00:05:06,673 --> 00:05:07,608 line:-1
谢谢Michael


100
00:05:08,075 --> 00:05:09,009 line:-1
大家好


101
00:05:10,010 --> 00:05:14,681 line:-1
今天我要演示如何使用模型个性化


102
00:05:14,948 --> 00:05:17,117 line:-1
为用户们创建自定义体验


103
00:05:17,818 --> 00:05:21,622 line:-2
为此我有一款app 它帮助老师们
给学生们的家庭作业评级


104
00:05:22,523 --> 00:05:24,391 line:-1
我使用模型个性化


105
00:05:24,691 --> 00:05:25,993 line:-2
给这个app添加了
一个很酷的新功能


106
00:05:26,059 --> 00:05:28,896 line:-2
但在我们讲这个功能之前
先看看这个app现在有什么功能


107
00:05:29,496 --> 00:05:30,964 line:-1
切换到演示屏


108
00:05:37,771 --> 00:05:39,606 line:-1
太棒了 这就是那款app


109
00:05:40,174 --> 00:05:41,875 line:-2
它叫做
Personalized Grading App


110
00:05:42,442 --> 00:05:46,146 line:-1
它可以让你获取家庭作业的一张照片


111
00:05:47,047 --> 00:05:51,318 line:-2
然后开始像老师在纸上评级一样
给家庭作业评级


112
00:05:52,319 --> 00:05:54,354 line:-1
你可以像这样标记为正确


113
00:05:54,788 --> 00:05:56,290 line:-1
或像这样标记为错误


114
00:05:57,090 --> 00:05:58,125 line:-1
非常直截了当


115
00:05:58,892 --> 00:05:59,893 line:-1
非常简单


116
00:06:00,194 --> 00:06:03,497 line:-2
这款app使用PencilKit
来捕捉输入


117
00:06:03,864 --> 00:06:07,067 line:-2
并预训练Core ML模型来识别
评级样本


118
00:06:09,203 --> 00:06:11,205 line:-1
最近我添加了一个新功能


119
00:06:11,605 --> 00:06:15,976 line:-2
可以让老师们为学生们提供一些
特别的东西以示鼓励


120
00:06:17,211 --> 00:06:18,078 line:-1
也就是贴纸


121
00:06:19,146 --> 00:06:22,015 line:-2
孩子们绝对喜欢收集
家庭作业上的贴纸


122
00:06:22,449 --> 00:06:24,852 line:-2
因此我认为这对于app来说
可能是个非常不错的改进


123
00:06:25,118 --> 00:06:28,088 line:-2
如果他们可以允许…
如果我们可以允许老师们提供贴纸


124
00:06:29,423 --> 00:06:30,490 line:-1
要给学生发贴纸


125
00:06:30,757 --> 00:06:32,626 line:-1
我可以轻触上边的这个加号按钮


126
00:06:34,561 --> 00:06:37,030 line:-1
滚动浏览贴纸列表 选择其中一个


127
00:06:37,798 --> 00:06:41,602 line:-1
把它拖动到正确的位置 并调整尺寸


128
00:06:42,903 --> 00:06:43,837 line:-1
就是这样


129
00:06:44,905 --> 00:06:47,107 line:-2
但我认为我们可以把这个流程
变得更好


130
00:06:47,574 --> 00:06:49,476 line:-1
让用户们也觉得非常神奇


131
00:06:51,178 --> 00:06:52,446 line:-1
让我们稍微思考一下


132
00:06:54,114 --> 00:06:56,950 line:-2
用户仅使用
Apple Pencil来评级


133
00:06:57,651 --> 00:07:00,654 line:-2
如果他们可以
在整个屏幕上的任意位置


134
00:07:01,054 --> 00:07:03,190 line:-1
快速地手绘一些东西是不是很酷


135
00:07:03,490 --> 00:07:06,660 line:-2
然后app会自动选择正确尺寸的
正确贴纸


136
00:07:06,727 --> 00:07:08,562 line:-1
并把它放在正确的位置上


137
00:07:10,097 --> 00:07:13,433 line:-2
嗯 我们绝对可以通过机器学习
来实现这个功能 对吗？


138
00:07:13,834 --> 00:07:15,035 line:-1
因此让我们思考一些可选方案


139
00:07:15,302 --> 00:07:16,837 line:-1
让我切换到幻灯片中


140
00:07:17,671 --> 00:07:21,208 line:-2
有些人已经用过Core ML了
你们可能在想


141
00:07:21,275 --> 00:07:23,477 line:-1
嗯 我们实际上可以预训练…


142
00:07:24,278 --> 00:07:26,547 line:-1
一个可以识别贴纸的模型


143
00:07:26,847 --> 00:07:28,248 line:-1
并把它发布为app的一部分


144
00:07:28,315 --> 00:07:29,349 line:-1
（使用预训练的贴纸模型？）


145
00:07:29,416 --> 00:07:31,885 line:-2
嗯 我们可以这样做
但是这种方法有几个问题


146
00:07:32,586 --> 00:07:35,722 line:-1
其一 app中有许多贴纸


147
00:07:36,023 --> 00:07:38,392 line:0
我们可能需要收集大量训练数据


148
00:07:38,692 --> 00:07:40,260 line:0
才能预训练这些模型


149
00:07:41,261 --> 00:07:43,730 line:0
即使某个用户可能仅对


150
00:07:43,797 --> 00:07:45,432 line:0
其中一小部分贴纸感兴趣


151
00:07:47,134 --> 00:07:48,168 line:0
其二


152
00:07:49,603 --> 00:07:51,271 line:-1
如果我计划在将来引入一批新贴纸


153
00:07:51,572 --> 00:07:54,441 line:-2
这个预训练的模型该如何处理
那些新贴纸呢？


154
00:07:56,009 --> 00:07:57,945 line:-1
嗯 我可能得预训练模型


155
00:07:58,312 --> 00:08:02,382 line:-2
并通过app更新来发布它
或也许允许app下载它


156
00:08:04,484 --> 00:08:06,854 line:-1
最后 我认为这是最关键的点


157
00:08:07,187 --> 00:08:09,723 line:-2
这个预训练模型对于不同的用户来说
如何运作？


158
00:08:12,659 --> 00:08:15,329 line:-1
不同的用户有不同的手绘方式


159
00:08:16,396 --> 00:08:19,099 line:-1
如果我去外面要求一百个不同的人


160
00:08:19,399 --> 00:08:21,301 line:-1
快速手绘出这个漂亮的贴纸


161
00:08:21,702 --> 00:08:23,270 line:-1
我至少会得到50个不同的答案


162
00:08:24,071 --> 00:08:26,373 line:-2
真正让人震惊的是人们的个性
太不一样了


163
00:08:27,007 --> 00:08:28,976 line:-2
那么在这种情况下
app应该怎么做呢？


164
00:08:30,677 --> 00:08:34,780 line:-2
我们是否应该…
app是否应该训练用户


165
00:08:35,381 --> 00:08:36,383 line:-1
如何进行手绘…


166
00:08:38,018 --> 00:08:41,522 line:-2
或用户是否应该训练app
以改善模型


167
00:08:41,889 --> 00:08:43,823 line:-1
识别你的手绘的方式？


168
00:08:44,925 --> 00:08:47,761 line:-1
嗯 这正是模型个性化所提供的功能


169
00:08:49,763 --> 00:08:53,734 line:-1
我要做的是使用模型个性化


170
00:08:53,800 --> 00:08:57,337 line:-2
和我从用户那里收集的用户数据
来训练…


171
00:08:57,404 --> 00:08:59,907 line:-1
来定义一个模型来满足他们的需要


172
00:08:59,973 --> 00:09:02,176 line:-1
让我演示一下那如何转化为用户体验


173
00:09:02,242 --> 00:09:03,777 line:-1
（用户可以训练模型）


174
00:09:08,582 --> 00:09:11,084 line:-1
我要切换到演示屏继续评级


175
00:09:12,119 --> 00:09:14,588 line:-1
第三个答案…第三个问题


176
00:09:14,655 --> 00:09:15,689 line:-1
对于幼儿园的孩子们来说非常棘手


177
00:09:15,756 --> 00:09:17,324 line:-1
但我认为Jane已经解决了


178
00:09:17,391 --> 00:09:19,560 line:-1
那个图解中有四个三角形


179
00:09:20,060 --> 00:09:20,994 line:-1
做得很好 Jane


180
00:09:21,929 --> 00:09:24,598 line:-1
嗯 现在我想给她发一个贴纸


181
00:09:24,665 --> 00:09:26,366 line:-1
鼓励她对细节的关注


182
00:09:26,433 --> 00:09:28,235 line:-1
但我想通过快速手绘来发贴纸


183
00:09:28,969 --> 00:09:29,970 line:-1
让我们试着做一下


184
00:09:33,841 --> 00:09:37,277 line:-2
app看起来告诉我说它不能识别
我的手绘


185
00:09:37,611 --> 00:09:40,113 line:-2
这很公平
因为这是我第一次使用这款app


186
00:09:40,614 --> 00:09:42,416 line:-1
让我试着添加一个贴纸


187
00:09:42,749 --> 00:09:45,886 line:-2
但这一次我想创建一个快捷方式
是的


188
00:09:45,953 --> 00:09:48,188 line:-1
我要选择我上次所使用的那个贴纸


189
00:09:50,290 --> 00:09:53,260 line:-1
现在app要求我提供一个样本


190
00:09:53,727 --> 00:09:56,029 line:-1
就是我会如何手绘这个特定的贴纸


191
00:09:56,697 --> 00:09:57,898 line:-1
它不一定非常完美


192
00:09:57,965 --> 00:10:00,000 line:-1
它甚至看起来也可以跟贴纸不一样


193
00:10:00,300 --> 00:10:02,569 line:-1
这只是我自己的表示


194
00:10:02,903 --> 00:10:06,507 line:-1
表示我想如何手绘那个贴纸 对吗？


195
00:10:06,573 --> 00:10:10,644 line:-1
因此我使用了一颗星来…


196
00:10:12,412 --> 00:10:13,881 line:-1
代表那个特定的贴纸


197
00:10:15,649 --> 00:10:17,751 line:-1
app要求我再提供几个样本


198
00:10:17,818 --> 00:10:20,120 line:-1
这也很公平 因为这只需要几秒钟


199
00:10:20,821 --> 00:10:23,657 line:-2
但现在看起来app…
快捷方式已经注册成功了


200
00:10:24,591 --> 00:10:28,595 line:-2
现在我在屏幕上看到了贴纸
以及我所提供的样本


201
00:10:29,930 --> 00:10:33,300 line:-2
在我返回之前 让我再向贴纸库中
添加一个贴纸


202
00:10:34,701 --> 00:10:38,005 line:-2
那儿有一个非常漂亮的“击掌”手势
我很想用这个


203
00:10:38,305 --> 00:10:39,373 line:-1
就在这儿


204
00:10:40,941 --> 00:10:42,910 line:-2
我在考虑我应该用什么来作为
它的快捷方式


205
00:10:43,777 --> 00:10:46,246 line:-1
我希望是一种容易记住的东西


206
00:10:46,313 --> 00:10:47,247 line:-1
很容易画出来的东西


207
00:10:47,581 --> 00:10:48,916 line:-1
数字五怎么样


208
00:10:48,982 --> 00:10:50,484 line:-1
从某种程度上来说可以代表“击掌”


209
00:10:53,287 --> 00:10:56,590 line:-2
太棒了 又提供了两个样本
我已经完成了


210
00:10:58,058 --> 00:10:59,493 line:-1
让我们返回到屏幕上


211
00:10:59,560 --> 00:11:03,096 line:-2
试着为绝望等待的Jane
发这个贴纸


212
00:11:04,631 --> 00:11:05,632 line:-1
那不是很酷吗？


213
00:11:11,471 --> 00:11:14,074 line:-1
我非常高兴我不必浏览贴纸选择器


214
00:11:14,141 --> 00:11:16,877 line:-2
并从那些乱糟糟的贴纸堆中
把贴纸移出来


215
00:11:17,811 --> 00:11:20,414 line:-2
太棒了 下一个问题
耶 这个也对了


216
00:11:20,480 --> 00:11:22,182 line:-1
让我再给她发一个小星星


217
00:11:23,383 --> 00:11:25,152 line:-1
我对这款app超级满意


218
00:11:25,219 --> 00:11:27,020 line:-1
在顶部贴一个大的“击掌”贴纸


219
00:11:27,521 --> 00:11:28,455 line:-1
那怎么样？


220
00:11:36,363 --> 00:11:37,764 line:-1
这只是一个例子


221
00:11:38,165 --> 00:11:41,034 line:-1
你们可以思考使用这个新功能


222
00:11:41,101 --> 00:11:43,203 line:-1
打造一些非常优秀的体验


223
00:11:43,971 --> 00:11:45,272 line:-1
在我结束之前


224
00:11:45,339 --> 00:11:47,374 line:-1
让我快速总结一下要实施这个功能


225
00:11:47,441 --> 00:11:48,842 line:-1
所需要采取的操作


226
00:11:48,909 --> 00:11:49,877 line:-1
（用户可以训练模型）


227
00:11:49,943 --> 00:11:51,245 line:-1
我要做的第一件事


228
00:11:51,912 --> 00:11:56,483 line:-2
是向项目中导入一个可更新的
Core ML模型


229
00:11:57,150 --> 00:11:58,685 line:-1
它在Xcode中看起来是这样的


230
00:12:01,054 --> 00:12:02,856 line:-1
因为我要通过添加新贴纸或类


231
00:12:02,923 --> 00:12:05,192 line:-1
来试着个性化这个模型


232
00:12:05,492 --> 00:12:07,995 line:-1
使用最邻近分类器很有道理


233
00:12:09,930 --> 00:12:13,600 line:-1
虽然那是个填充到最邻近分类器中的


234
00:12:13,934 --> 00:12:16,069 line:-1
预训练的神经网络功能提取器


235
00:12:16,436 --> 00:12:19,106 line:-1
用于帮助改善预测效率和稳健性


236
00:12:20,440 --> 00:12:23,310 line:-2
但这就是它
你不需要担心任何模型细节


237
00:12:23,677 --> 00:12:25,512 line:-2
因为Core ML
以这样的方式进行提取


238
00:12:25,879 --> 00:12:27,848 line:-1
从API界面提取全部模型细节


239
00:12:31,985 --> 00:12:33,320 line:-1
你可以使用这个模型进行预测


240
00:12:33,387 --> 00:12:34,521 line:-1
并不需要任何修改


241
00:12:35,522 --> 00:12:38,725 line:-2
Xcode中你会看到跟以前一样的
预测输入和输出


242
00:12:40,460 --> 00:12:42,996 line:-1
但今年的新功能是一个更新部分


243
00:12:44,431 --> 00:12:48,669 line:-2
描述一组输入 是这个模型用于
进行个性化所需要的一组输入


244
00:12:49,336 --> 00:12:51,138 line:-1
正如你所预期的那样


245
00:12:51,205 --> 00:12:52,372 line:-1
它需要一个灰度图像的贴纸


246
00:12:52,873 --> 00:12:55,475 line:-1
以及同样是灰度图像的相应的手绘


247
00:12:55,776 --> 00:12:59,346 line:-2
而相应的贴纸作为真正的标签
从而实现个性化


248
00:13:00,347 --> 00:13:03,217 line:-2
关于代码
你可以重调Core ML


249
00:13:03,617 --> 00:13:06,720 line:-2
自动生成一组类
用于帮助你进行预测


250
00:13:07,487 --> 00:13:09,223 line:-1
现在它生成新类


251
00:13:09,656 --> 00:13:12,259 line:-1
用于帮助你以自我方式提供训练数据


252
00:13:13,327 --> 00:13:14,595 line:-1
如果你看一下这个类


253
00:13:14,995 --> 00:13:16,430 line:-1
你会看到一组属性


254
00:13:16,697 --> 00:13:19,199 line:-2
与你在Xcode中
所看到的一致 对吗？


255
00:13:19,266 --> 00:13:22,035 line:-1
那么我们在这里看到了手绘和贴纸


256
00:13:24,938 --> 00:13:29,042 line:-2
一旦你从用户那儿收集到
用于个性化模型…


257
00:13:29,610 --> 00:13:34,114 line:-2
或用于为用户进行个性化的全部
训练数据


258
00:13:34,848 --> 00:13:38,252 line:-1
真正的个性化需要三个简单的步骤


259
00:13:39,786 --> 00:13:42,456 line:-2
第一 你需要获取
可更新的模型URL


260
00:13:43,023 --> 00:13:44,791 line:-1
你可以从捆绑包获取


261
00:13:45,158 --> 00:13:47,461 line:-1
或从已更新模型之前的快照中获取


262
00:13:49,096 --> 00:13:52,566 line:-2
接下来你要准备所支持格式的
训练数据


263
00:13:53,300 --> 00:13:57,638 line:-1
为此 你可以使用我所展示的原生类


264
00:13:57,704 --> 00:14:00,340 line:-1
或创建你自己的功能提供器


265
00:14:01,675 --> 00:14:04,511 line:-1
最后你要启动一个更新任务


266
00:14:06,446 --> 00:14:09,716 line:-1
一旦更新完成 就调用完成处理器


267
00:14:10,217 --> 00:14:14,688 line:-2
那会为你提供已更新的模型
你可以立即用于进行预测


268
00:14:15,322 --> 00:14:16,256 line:-1
就是如此简单


269
00:14:16,723 --> 00:14:20,260 line:-2
我已经迫不及待地想看到
你们使用这些功能


270
00:14:20,327 --> 00:14:21,562 line:-2
在你们的app和框架中会创建出
多么酷的功能


271
00:14:21,962 --> 00:14:23,597 line:-2
就这样
让我把舞台交还给Michael


272
00:14:23,964 --> 00:14:25,966 line:-1
讲一些更复杂的情境


273
00:14:26,033 --> 00:14:27,234 line:-1
和模型个性化


274
00:14:27,301 --> 00:14:28,335 line:-1
谢谢


275
00:14:37,144 --> 00:14:38,145 line:-1
好的 谢谢Anil


276
00:14:41,448 --> 00:14:42,482 line:-1
简单回顾一下


277
00:14:43,150 --> 00:14:44,785 line:-2
Anil刚给我们演示了
使用基础模型…


278
00:14:46,253 --> 00:14:48,055 line:-1
并尝试实现个性化体验


279
00:14:48,689 --> 00:14:52,626 line:-2
通过提供一些模型很容易接受的
绘画来实现


280
00:14:52,693 --> 00:14:53,927 line:-1
然后我们看到我们得到了怎样的输出


281
00:14:54,962 --> 00:14:56,930 line:-1
最初我们并没有得到很多


282
00:14:58,031 --> 00:14:59,166 line:-1
那是因为在内部


283
00:14:59,466 --> 00:15:01,201 line:-1
虽然我们已经预训练了神经网络


284
00:15:01,535 --> 00:15:03,804 line:-1
但它注入的是一个


285
00:15:04,238 --> 00:15:05,239 line:-1
实际上是空的K最近邻基类分类器


286
00:15:05,305 --> 00:15:06,607 line:-1
它没有可以进行分类的近邻


287
00:15:10,110 --> 00:15:11,912 line:-2
因此我们要更新它并给它提供
一些近邻


288
00:15:11,979 --> 00:15:14,748 line:-2
正如Anil给我们所展示的那样
我们获取训练数据


289
00:15:15,115 --> 00:15:17,818 line:-2
我们所选择的贴纸以及我们所绘制的
与贴纸相对应的绘画


290
00:15:18,552 --> 00:15:20,621 line:-2
然后我们把这些与我们的基础模型
一起


291
00:15:21,221 --> 00:15:24,691 line:-2
注入那个可更新的K最近邻基础模型
以完成更新任务


292
00:15:26,026 --> 00:15:27,995 line:-1
这就为我们提供了新版的模型


293
00:15:29,329 --> 00:15:30,631 line:-1
（用已更新模型进行预测）


294
00:15:31,098 --> 00:15:34,701 line:-2
这个新版本可以更可靠地识别
它的培训内容


295
00:15:35,669 --> 00:15:38,038 line:-1
从内部来说 唯一发生改变的


296
00:15:38,105 --> 00:15:40,240 line:-1
就是那个可更新K最近邻基础模型


297
00:15:41,575 --> 00:15:42,943 line:-1
（更新任务）


298
00:15:44,144 --> 00:15:45,779 line:-1
让我们看一下ML更新任务类


299
00:15:45,846 --> 00:15:46,980 line:-1
我们今年引入了这个类


300
00:15:47,314 --> 00:15:49,249 line:-1
用于帮助管理这些更新过程


301
00:15:50,684 --> 00:15:53,687 line:-2
因此它有一个与它相关联的状态
关于它处于哪个过程


302
00:15:53,754 --> 00:15:56,156 line:-1
并且它可以恢复或取消那个任务


303
00:15:57,658 --> 00:16:00,127 line:-1
要构建一个状态 你只需要传入


304
00:16:00,594 --> 00:16:04,431 line:-2
模型的那个基础URL和配置
以及训练数据即可


305
00:16:06,066 --> 00:16:08,502 line:-2
正如Anil所演示的那样
你还需要传入完成处理器


306
00:16:09,603 --> 00:16:10,704 line:-1
对于完成处理器


307
00:16:11,004 --> 00:16:12,506 line:-1
我们将在你完成更新任务后进行调用


308
00:16:12,573 --> 00:16:14,007 line:-1
并且它会给你提供一个更新情境


309
00:16:14,808 --> 00:16:17,110 line:-1
当你完成更新后


310
00:16:17,177 --> 00:16:18,345 line:-1
你可以用它来编写那个模型


311
00:16:18,879 --> 00:16:20,013 line:-1
对它进行预测


312
00:16:20,380 --> 00:16:21,849 line:-1
并查询任务的其它部分


313
00:16:21,915 --> 00:16:23,817 line:-1
那可以让我们得到一部分更新情境


314
00:16:26,453 --> 00:16:29,022 line:-2
在代码中 正如Anil所演示的
实施起来非常得直截了当


315
00:16:29,790 --> 00:16:33,460 line:-2
你只需要构建一个MLupdateTask
提供那个URL、


316
00:16:33,961 --> 00:16:36,163 line:-1
你的配置和你的完成处理器


317
00:16:36,230 --> 00:16:38,098 line:-1
在这里我们用于检查准确度


318
00:16:39,032 --> 00:16:40,934 line:-1
把模型保留在这个代码块的范围之外


319
00:16:41,568 --> 00:16:42,736 line:-1
并保存那个模型


320
00:16:43,337 --> 00:16:46,206 line:-2
这非常棒 用起来很不错
并且它让我们通过了这个演示


321
00:16:46,907 --> 00:16:49,843 line:-2
但如果是更复杂的用例怎么样呢
对吗？


322
00:16:49,910 --> 00:16:51,044 line:-1
如果是神经网络会怎么样？


323
00:16:51,111 --> 00:16:52,479 line:-1
（可更新的神经网络）


324
00:16:52,779 --> 00:16:56,016 line:-1
嗯 最简单的神经网络只有几个层


325
00:16:56,750 --> 00:16:58,485 line:-1
每个层都有一些输入和一些权重


326
00:16:58,852 --> 00:17:00,888 line:-1
输入和权重结合使用创建一个输出


327
00:17:02,589 --> 00:17:03,657 line:-1
要调整那个输出


328
00:17:03,724 --> 00:17:05,492 line:-1
我们需要在这些层中调整权重


329
00:17:05,858 --> 00:17:08,362 line:-2
为此 我们需要把
这些层标记为可更新


330
00:17:10,664 --> 00:17:13,133 line:-2
我们需要一些方式来告诉它
输出偏离了多少


331
00:17:13,867 --> 00:17:16,703 line:-2
如果我们想要一个微笑脸
但我们却得到了一个“击掌”


332
00:17:17,171 --> 00:17:18,105 line:-1
我们需要对此进行修正


333
00:17:18,172 --> 00:17:19,940 line:-1
这要在我们的损失函数上实现


334
00:17:20,307 --> 00:17:21,575 line:-1
损失函数描述那个delta


335
00:17:22,876 --> 00:17:24,944 line:-2
最后我们需要把这个提供给我们的
优化器


336
00:17:25,212 --> 00:17:26,946 line:-1
优化器会获取那个损失 我们的输出


337
00:17:27,214 --> 00:17:29,983 line:-2
并算出实际上要在这些层中
调整多少权重


338
00:17:33,520 --> 00:17:34,788 line:-1
在Core ML 3上


339
00:17:34,855 --> 00:17:38,125 line:-1
我们支持卷积更新和完全…


340
00:17:38,492 --> 00:17:41,962 line:-1
完全连接的层以及通过更多层


341
00:17:42,029 --> 00:17:42,930 line:-1
进行反向传播


342
00:17:43,297 --> 00:17:45,199 line:-1
我们无条件支持交叉熵


343
00:17:45,532 --> 00:17:47,201 line:-1
和均方误差损失类型


344
00:17:48,101 --> 00:17:50,737 line:-1
此外我们还支持随机梯度下降


345
00:17:50,804 --> 00:17:52,639 line:-1
和Adam优化策略


346
00:17:55,209 --> 00:17:56,243 line:-1
这非常棒 对吗？


347
00:17:56,577 --> 00:17:59,546 line:-1
但还有其它与神经网络相关联的参数


348
00:18:00,047 --> 00:18:01,915 line:-2
比如学习速率
和要运行的epoch数


349
00:18:02,850 --> 00:18:05,018 line:-1
这些都要被封装在那个模型内


350
00:18:06,820 --> 00:18:09,423 line:-2
然而我们理解你们中有些人
想在运行时进行修改


351
00:18:10,958 --> 00:18:11,925 line:-1
你可以通过


352
00:18:11,992 --> 00:18:14,461 line:-1
覆盖更新参数字典


353
00:18:14,728 --> 00:18:15,929 line:-1
和模型配置在运行时进行修改


354
00:18:16,330 --> 00:18:17,664 line:-2
你可以通过使用MLParameterKey
和为其指定值


355
00:18:18,632 --> 00:18:21,201 line:-1
覆盖内部的值


356
00:18:21,768 --> 00:18:23,537 line:-1
我们给你们提供了很大的灵活度


357
00:18:24,671 --> 00:18:25,939 line:-1
（Xcode中的参数）


358
00:18:26,573 --> 00:18:29,243 line:-1
此外 如果你在考虑


359
00:18:29,309 --> 00:18:30,544 line:-1
我的模型内到底嵌入了多少参数


360
00:18:31,111 --> 00:18:34,214 line:-2
你可以在Xcode中查看
该模型视图的参数部分


361
00:18:34,548 --> 00:18:37,150 line:-1
将为你提供那些参数的值


362
00:18:37,417 --> 00:18:39,586 line:-1
以及该模型内到底定义了哪些参数


363
00:18:44,057 --> 00:18:45,692 line:-1
你可能想要更多的灵活度


364
00:18:45,759 --> 00:18:48,495 line:-2
而不仅仅是我们之前所演示的API
我们为你们提供灵活度


365
00:18:49,763 --> 00:18:50,731 line:-1
在你的MLUpdateTask中


366
00:18:50,797 --> 00:18:52,933 line:-2
你可以提供一个
MLupdateProgressHandler


367
00:18:53,634 --> 00:18:54,835 line:-1
而不是提供完成处理器


368
00:18:55,469 --> 00:18:57,704 line:-2
并提供进度处理器
而那个完成处理器


369
00:18:58,405 --> 00:19:00,207 line:-1
将允许你输入特定事件


370
00:19:00,274 --> 00:19:02,843 line:-2
因此当训练开始
或当epoch结束时


371
00:19:03,277 --> 00:19:04,811 line:-1
我们将调用你的进度处理器


372
00:19:05,946 --> 00:19:08,682 line:-2
并为你提供更新情境
就像我们在完成处理器中所做的那样


373
00:19:11,051 --> 00:19:12,019 line:-1
此外


374
00:19:12,085 --> 00:19:14,454 line:-2
我们还会告诉你是哪个事件导致
我们调用那个回调


375
00:19:15,422 --> 00:19:16,757 line:-1
并为你提供关键指标


376
00:19:16,823 --> 00:19:18,525 line:-1
从而你可以在处理


377
00:19:18,892 --> 00:19:20,894 line:-2
每一小批或每个epoch时
查询训练损失


378
00:19:23,163 --> 00:19:25,098 line:-1
在代码中 仍然是非常得直截了当


379
00:19:25,566 --> 00:19:27,434 line:-2
你构建这个
MLupdateProgressHandler


380
00:19:27,901 --> 00:19:29,336 line:-1
并告诉它你对哪些事件感兴趣


381
00:19:29,703 --> 00:19:30,938 line:-1
并提供一个它可以调用的代码块


382
00:19:32,673 --> 00:19:34,975 line:-1
此外 你还要提供完成处理器


383
00:19:35,676 --> 00:19:36,910 line:-1
和你刚刚用于


384
00:19:37,177 --> 00:19:39,046 line:-2
提供进度处理器的
MLUpdateTask


385
00:19:41,982 --> 00:19:43,116 line:-1
（后台中的CORE ML）


386
00:19:43,684 --> 00:19:45,385 line:-1
我们已经讲了如何更新模型


387
00:19:45,452 --> 00:19:46,653 line:-1
以及更新模型意味着什么


388
00:19:47,254 --> 00:19:50,357 line:-2
嗯 我们目前还没有真正讲到的是
何时适合更新


389
00:19:51,525 --> 00:19:53,126 line:-1
在我们之前演示过的评级app中


390
00:19:53,193 --> 00:19:56,763 line:-2
我们在他与app第二次交互
并绘制绘画时进行更新


391
00:19:57,130 --> 00:19:59,199 line:-1
我们获取那个数据并把它发送给模型


392
00:20:00,567 --> 00:20:01,702 line:-1
但那可能会不合适


393
00:20:01,768 --> 00:20:04,071 line:-1
如果你有数百万数据点会怎样？


394
00:20:05,005 --> 00:20:06,840 line:-1
如果你的模型极其复杂会怎样？


395
00:20:07,975 --> 00:20:08,976 line:-1
嗯 我对此感到很激动


396
00:20:09,309 --> 00:20:11,044 line:-2
我想说使用
BackgroundTask框架


397
00:20:11,879 --> 00:20:14,481 line:-2
将会给你的app
分配数分钟的运行时间


398
00:20:15,148 --> 00:20:16,650 line:-1
即使用户没有在使用你的app


399
00:20:17,084 --> 00:20:18,719 line:-1
或即使他们并没有与设备进行交互


400
00:20:19,620 --> 00:20:23,557 line:-2
你都可以使用BGTaskScheduler
并执行BGProcessingTaskRequest


401
00:20:24,124 --> 00:20:26,226 line:-2
我们将为你提供数分钟来执行
进一步的更新


402
00:20:26,660 --> 00:20:27,694 line:-1
和进一步的计算


403
00:20:29,029 --> 00:20:30,364 line:-1
要了解更多信息…是的


404
00:20:33,834 --> 00:20:34,735 line:-1
太棒了


405
00:20:34,801 --> 00:20:37,037 line:-1
要了解更多信息 我强烈推荐你们


406
00:20:37,104 --> 00:20:39,606 line:-1
查看“关于App后台执行的改进”


407
00:20:43,343 --> 00:20:45,045 line:-1
此外 你要如何获得可更新的模型？


408
00:20:45,312 --> 00:20:46,880 line:-1
嗯 我们之前讲过了


409
00:20:47,414 --> 00:20:48,982 line:-1
你可以通过


410
00:20:49,049 --> 00:20:50,851 line:-1
从许多所支持的训练库中转换模型


411
00:20:51,285 --> 00:20:52,653 line:-1
这并没有变


412
00:20:53,987 --> 00:20:55,989 line:-1
当你转化模型时


413
00:20:56,356 --> 00:20:57,758 line:-2
你只需要传入
可接受的可训练标志即可


414
00:20:58,392 --> 00:20:59,960 line:-1
它会获取那些可训练参数


415
00:21:00,027 --> 00:21:01,929 line:-1
比如你想采取哪种优化策略


416
00:21:02,429 --> 00:21:03,730 line:-1
哪个层可更新


417
00:21:04,131 --> 00:21:06,033 line:-2
我们会获取那些信息
并把它们嵌入到你的模型内


418
00:21:06,600 --> 00:21:08,168 line:-1
然后模型的其余部分与之前一模一样


419
00:21:10,204 --> 00:21:12,840 line:-1
如果你们想直接修改模型自身


420
00:21:13,140 --> 00:21:14,741 line:-1
我们也完全支持


421
00:21:15,609 --> 00:21:17,144 line:-1
（模型个性化概述）


422
00:21:17,911 --> 00:21:20,414 line:-1
我们讲了如何在app中


423
00:21:20,480 --> 00:21:22,382 line:-1
使用设备上的模型个性化


424
00:21:22,850 --> 00:21:24,785 line:-1
为用户创建更个性化的体验


425
00:21:25,953 --> 00:21:28,288 line:-2
你可以通过新的灵活但简单的
API来实现


426
00:21:29,289 --> 00:21:31,491 line:-1
非常棒 你完全可以在设备上实现


427
00:21:32,192 --> 00:21:33,026 line:-1
有了这些信息


428
00:21:33,894 --> 00:21:36,230 line:-2
我要把舞台交给我的同事
Aseem Wadhwa


429
00:21:36,296 --> 00:21:37,831 line:-1
她会讲我们今年针对神经网络


430
00:21:37,898 --> 00:21:39,600 line:-1
所添加的一些很棒的新功能


431
00:21:40,234 --> 00:21:41,502 line:-1
（神经网络）


432
00:21:45,572 --> 00:21:46,673 line:-1
好的


433
00:21:48,275 --> 00:21:49,376 line:-1
我感到非常激动…


434
00:21:50,277 --> 00:21:53,914 line:-2
我要讲的是今年Core ML中
有关神经网络的新功能


435
00:21:55,015 --> 00:21:56,183 line:-1
但在此之前


436
00:21:57,084 --> 00:22:01,154 line:0
我想花几分钟笼统地讲一下神经网络


437
00:22:02,856 --> 00:22:05,959 line:-1
嗯 我们都知道神经网络致力于


438
00:22:06,026 --> 00:22:08,095 line:-1
解决具有挑战性的任务


439
00:22:08,595 --> 00:22:11,932 line:-1
比如了解图片内容或文档内容


440
00:22:12,266 --> 00:22:13,267 line:-1
或音频剪辑的内容


441
00:22:14,501 --> 00:22:18,972 line:-2
我们可以使用这个功能来创建一些
非常优秀的app


442
00:22:20,774 --> 00:22:25,979 line:-2
如果你深入了解一下神经网络
并查看它的结构


443
00:22:26,847 --> 00:22:28,849 line:-1
我们可能会更好地理解它


444
00:22:30,250 --> 00:22:31,251 line:-1
让我们来试一下


445
00:22:31,818 --> 00:22:35,055 line:-1
但我们不是从研究者的角度来看


446
00:22:35,422 --> 00:22:36,857 line:-1
让我们尝试从一个不同的视角来看


447
00:22:37,291 --> 00:22:40,727 line:-1
让我们从程序员的视角来看


448
00:22:41,895 --> 00:22:44,398 line:-1
如果你查看Core ML模型内部


449
00:22:44,865 --> 00:22:47,334 line:-1
我们所看到的类似一个图形


450
00:22:48,335 --> 00:22:49,503 line:-1
如果你再仔细查看


451
00:22:49,903 --> 00:22:54,608 line:-2
我们会意识到那个图形
只是程序的另一种表示


452
00:22:55,375 --> 00:22:56,410 line:-1
让我们再看一眼


453
00:22:58,512 --> 00:23:02,049 line:-2
这是我们都能理解的一个
非常简单的代码片段


454
00:23:02,816 --> 00:23:05,452 line:0
这是与它相对应的图形表示


455
00:23:06,386 --> 00:23:09,356 line:0
你可能已经注意到了 代码中的操作


456
00:23:09,723 --> 00:23:11,892 line:0
就是图形中的这些注释


457
00:23:12,726 --> 00:23:17,097 line:0
而可读取的比如X、Y、Z
就是图形中的这些边界


458
00:23:18,031 --> 00:23:20,133 line:0
如果你返回去看神经网络图形


459
00:23:21,201 --> 00:23:23,437 line:0
它现在显示的是相应的代码片段


460
00:23:24,037 --> 00:23:26,139 line:0
看起来与之前的非常类似


461
00:23:26,974 --> 00:23:29,176 line:0
但我要指出几个不同点


462
00:23:32,312 --> 00:23:36,483 line:0
第一 我们现在所拥有的
不是那些简单的数字变量


463
00:23:36,550 --> 00:23:40,988 line:0
而是这些多维变量 变量有多个参数


464
00:23:41,488 --> 00:23:46,193 line:0
它可以有形状参数和排名参数


465
00:23:46,493 --> 00:23:48,195 line:0
就是它所拥有的一些维度


466
00:23:49,062 --> 00:23:50,130 line:0
第二件事是


467
00:23:50,197 --> 00:23:53,500 line:0
操纵这些多维度变量的函数


468
00:23:53,800 --> 00:23:56,203 line:0
现在变成了这些专业的数学函数


469
00:23:56,570 --> 00:23:59,139 line:0
有时候也叫做层或操作


470
00:24:01,275 --> 00:24:03,644 line:-1
如果你真的看一下神经网络


471
00:24:08,115 --> 00:24:12,753 line:-2
我们会看到它实质上是一个图形
或一个程序


472
00:24:13,220 --> 00:24:17,391 line:-1
包含这些非常大的多维度变量


473
00:24:17,758 --> 00:24:20,227 line:-1
以及这些非常复杂的数学函数


474
00:24:20,661 --> 00:24:24,932 line:-2
从实质上说 它是要进行大量计算
和消耗大量内存的程序


475
00:24:25,866 --> 00:24:29,336 line:-2
关于Core ML
其中非常棒的一件事就是


476
00:24:30,103 --> 00:24:32,973 line:-2
它把全部这些复杂的东西都封装到
单个文件格式中


477
00:24:33,574 --> 00:24:35,042 line:-1
也就是Core ML框架


478
00:24:35,108 --> 00:24:38,245 line:-1
然后进行一些优化并非常高效地执行


479
00:24:40,547 --> 00:24:43,517 line:-2
因此如果我们返回去看
去年的Core ML 2


480
00:24:43,851 --> 00:24:48,255 line:-2
嗯 我们会很轻松地使用非循环图形
来表示直线式代码


481
00:24:48,889 --> 00:24:51,491 line:-1
我们大约有40种不同的层类型


482
00:24:51,758 --> 00:24:55,696 line:-2
通过这些层 我们可以表示绝大部分
常用的卷积架构


483
00:24:55,762 --> 00:24:57,731 line:-1
和循环架构


484
00:24:58,866 --> 00:24:59,867 line:-1
今年有什么新功能呢？


485
00:25:00,434 --> 00:25:05,372 line:-2
嗯 你可能已经注意到了
通过对程序的类比


486
00:25:05,706 --> 00:25:08,075 line:-1
我们都知道代码


487
00:25:08,141 --> 00:25:09,576 line:-2
会比简单的直线式代码复杂的多
对吗？


488
00:25:10,310 --> 00:25:11,278 line:-1
比如说


489
00:25:11,345 --> 00:25:15,415 line:-1
使用像分支这样的控制流很常见


490
00:25:16,049 --> 00:25:17,551 line:-1
如这段代码所示


491
00:25:18,118 --> 00:25:19,653 line:-1
在Core ML 3中


492
00:25:19,720 --> 00:25:22,890 line:-1
新功能是我们可以在神经网络规范内


493
00:25:22,956 --> 00:25:24,691 line:-1
表达同样的分支概念


494
00:25:30,831 --> 00:25:34,401 line:-2
另一种常见的控制流的形式
很显然是循环


495
00:25:34,902 --> 00:25:39,206 line:-2
我们也可以在Core ML网络内
轻松地表达循环


496
00:25:40,174 --> 00:25:42,976 line:-1
继续研究代码的另一个复杂特性


497
00:25:44,044 --> 00:25:46,780 line:-2
当我们编写动态代码时
经常会做的一件事


498
00:25:47,214 --> 00:25:49,650 line:-1
就是在运行时分配内存


499
00:25:50,083 --> 00:25:51,318 line:-1
如这段代码所示


500
00:25:51,385 --> 00:25:54,855 line:-1
我们正在按照程序的输入分配内存


501
00:25:54,922 --> 00:25:56,490 line:-1
从而可以在运行时改变内存的分配


502
00:25:56,857 --> 00:25:59,560 line:-2
今年我们可以在Core ML
实现同样的功能


503
00:25:59,960 --> 00:26:03,197 line:-1
通过动态层来实现


504
00:26:03,664 --> 00:26:06,400 line:-1
它可以让我们根据图形的输入


505
00:26:06,667 --> 00:26:07,935 line:-1
修改多数组的形状


506
00:26:08,302 --> 00:26:11,405 line:-2
你可能在想我们为什么
要在Core ML图形内


507
00:26:11,471 --> 00:26:15,409 line:-1
添加这些新的复杂的代码结构呢


508
00:26:15,742 --> 00:26:16,844 line:-1
答案很简单


509
00:26:16,910 --> 00:26:20,981 line:-2
因为神经网络研究正在积极地探索
这些想法


510
00:26:21,281 --> 00:26:23,951 line:-1
从而使神经网络变得更强大


511
00:26:24,017 --> 00:26:27,654 line:-1
事实上 许多最先进的神经网络


512
00:26:28,155 --> 00:26:30,524 line:-1
都内嵌了某种控制流


513
00:26:31,658 --> 00:26:36,063 line:-1
研究者们不断探索的另一个方面是


514
00:26:36,129 --> 00:26:38,065 line:-1
某种新操作


515
00:26:38,565 --> 00:26:43,370 line:-2
为此我们今年向Core ML中
添加了大量新层


516
00:26:44,371 --> 00:26:47,441 line:-1
我们不仅把当前层变得更通用了


517
00:26:47,508 --> 00:26:50,878 line:-1
我们还添加了大量新的基础数学运算


518
00:26:51,411 --> 00:26:53,614 line:-1
因此如果你遇到了一个新层


519
00:26:54,081 --> 00:26:57,217 line:-1
它很可能会


520
00:26:57,284 --> 00:26:58,986 line:-1
以Core ML 3中的层来表示


521
00:27:06,927 --> 00:27:11,331 line:-1
有了这些控制流功能、动态行为


522
00:27:11,398 --> 00:27:12,299 line:-1
和新层


523
00:27:12,833 --> 00:27:15,969 line:-2
Core ML模型
比以前更有表现力了


524
00:27:16,637 --> 00:27:18,105 line:-1
最重要的是


525
00:27:18,172 --> 00:27:22,943 line:-1
绝大多数流行的架构都可以轻松地


526
00:27:23,277 --> 00:27:24,178 line:-1
以Core ML格式表达


527
00:27:24,845 --> 00:27:27,748 line:-2
你可以从这张幻灯片上看到
我们列出了其中一些架构


528
00:27:28,115 --> 00:27:32,386 line:-1
突出显示的那些将在未来几个月实现


529
00:27:32,452 --> 00:27:34,955 line:-2
它们极大地推动了
机器学习的研究范围


530
00:27:35,355 --> 00:27:38,292 line:-2
现在你可以在Core ML中
轻松地表达它们


531
00:27:38,592 --> 00:27:40,160 line:-1
并把它们集成到app中


532
00:27:40,761 --> 00:27:41,662 line:-1
真是太棒了


533
00:27:45,766 --> 00:27:47,100 line:-1
（如何创建ML模型）


534
00:27:48,035 --> 00:27:50,737 line:-2
现在你可能在想
如何在Core ML模型内


535
00:27:51,071 --> 00:27:53,640 line:-1
利用这些新功能


536
00:27:53,707 --> 00:27:55,776 line:-1
嗯 答案是与去年一样


537
00:27:56,376 --> 00:27:58,846 line:-2
要创建一个Core ML模型
有两种方式可选


538
00:27:59,813 --> 00:28:04,351 line:-2
第一 因为Core ML是一个
开源Protobuf规范


539
00:28:04,818 --> 00:28:07,788 line:-1
我们总是可以使用任意编程语言


540
00:28:08,121 --> 00:28:09,957 line:-1
通过程序来指定模型


541
00:28:11,358 --> 00:28:12,993 line:-2
因此我们总是可以使用这个方法
来创建模型


542
00:28:13,560 --> 00:28:15,462 line:-1
但在绝大多数情况下


543
00:28:15,529 --> 00:28:18,532 line:-2
我们希望使用转换器来实现
它可以为我们自动创建模型


544
00:28:18,799 --> 00:28:22,202 line:-1
通过把图形从不同的表示转换为


545
00:28:22,769 --> 00:28:24,271 line:-1
Core ML表示来实现


546
00:28:24,972 --> 00:28:27,608 line:-1
让我们具体看一下这两种方法


547
00:28:29,409 --> 00:28:31,812 line:-1
在这里我要展示一个简单的神经网络


548
00:28:32,379 --> 00:28:36,483 line:-2
并演示如何使用Core ML工具
轻松地表达它


549
00:28:36,884 --> 00:28:40,754 line:-2
它是围绕Protobuf规范的
一个简单的Python包装器


550
00:28:41,889 --> 00:28:43,323 line:-1
我个人很喜欢这个方法


551
00:28:43,590 --> 00:28:47,494 line:-2
特别是当我转换一个我非常了解
其架构的模型时


552
00:28:47,928 --> 00:28:50,764 line:-1
如果我有一个可用的预训练的权重


553
00:28:51,098 --> 00:28:54,635 line:-2
这是一个很好的数据
就跟编号的数组一样


554
00:28:55,669 --> 00:28:56,670 line:-1
话虽如此


555
00:28:57,371 --> 00:28:59,439 line:-1
神经网络通常更复杂一些


556
00:28:59,973 --> 00:29:03,911 line:-2
我们最好是使用转换器
并且我们也有一些转换器


557
00:29:04,878 --> 00:29:07,447 line:-1
我们在GitHub上有一些转换器


558
00:29:07,714 --> 00:29:09,416 line:-1
通过这些转换器


559
00:29:10,250 --> 00:29:12,252 line:-1
你可以到达绝大部分机器学习框架


560
00:29:13,187 --> 00:29:16,623 line:-2
好消息是通过支持
Core ML 3规范


561
00:29:17,090 --> 00:29:19,326 line:-1
这些转换器也进行了更新


562
00:29:19,393 --> 00:29:20,561 line:-1
变得更强健了


563
00:29:21,395 --> 00:29:24,665 line:-1
如果你之前用过我们的转换器


564
00:29:25,299 --> 00:29:28,502 line:-1
你可能会遇到类似这样的报错信息


565
00:29:28,569 --> 00:29:30,704 line:-1
比如也许它在抱怨缺失一个层


566
00:29:30,771 --> 00:29:32,306 line:-1
或层中缺失一个属性


567
00:29:33,207 --> 00:29:35,242 line:-1
现在所有这些都会消失


568
00:29:35,309 --> 00:29:38,045 line:-1
因为我们更新了转换器


569
00:29:38,378 --> 00:29:40,080 line:-2
转换器可以充分利用
Core ML 3规范


570
00:29:41,315 --> 00:29:42,649 line:-1
（前面是一马平川）


571
00:29:47,254 --> 00:29:50,624 line:-2
那么我们已经讲了
许多幻灯片上的内容


572
00:29:50,691 --> 00:29:52,826 line:-2
现在是时候在实际操作中
了解一下模型了


573
00:29:52,893 --> 00:29:54,661 line:-2
为此我要邀请我朋友
Allen上台来


574
00:29:56,830 --> 00:29:57,965 line:-1
（问答APP）


575
00:29:58,265 --> 00:30:01,068 line:-1
谢谢 谢谢Aseem


576
00:30:01,869 --> 00:30:03,403 line:-1
大家好 我是Allen


577
00:30:03,837 --> 00:30:06,740 line:-2
今天我要给大家演示如何使用
Core ML 3中的新功能


578
00:30:06,807 --> 00:30:10,410 line:-2
把用于自然语言处理的最先进的
机器学习模型


579
00:30:10,477 --> 00:30:12,579 line:-1
引入到我们的app中


580
00:30:14,848 --> 00:30:17,084 line:-1
我喜欢阅读与历史相关的内容


581
00:30:17,918 --> 00:30:20,754 line:-2
无论何时当我遇到一些
与历史有关的有意思的文章时


582
00:30:21,255 --> 00:30:23,624 line:-1
我脑子里经常会浮现一些问题


583
00:30:23,690 --> 00:30:25,559 line:-1
我很想知道问题的答案


584
00:30:26,360 --> 00:30:28,028 line:-1
但有时我会很不耐烦


585
00:30:28,495 --> 00:30:30,063 line:-1
我不想阅读整篇文章


586
00:30:30,998 --> 00:30:33,867 line:-1
因此如果我可以创建一个app


587
00:30:34,301 --> 00:30:37,638 line:-2
可以扫描文档然后给出回答
不是很好吗？


588
00:30:38,238 --> 00:30:42,276 line:-2
我就开始用Core ML 3中的
新功能创建这个app


589
00:30:42,676 --> 00:30:43,577 line:-1
让我来给你们展示一下


590
00:30:51,418 --> 00:30:52,819 line:-1
好的 这就是我的app


591
00:30:54,021 --> 00:30:58,292 line:-2
你可以看到 它显示了一篇文章
是一个叫做NeXT的公司的历史


592
00:30:59,326 --> 00:31:02,162 line:-1
你可以看到 这篇文章很长


593
00:31:02,462 --> 00:31:04,031 line:-1
我当然没有时间通读一遍


594
00:31:04,698 --> 00:31:05,766 line:-1
而且我有一些相关的疑问


595
00:31:06,333 --> 00:31:07,768 line:-1
让我来问问这个app


596
00:31:10,671 --> 00:31:11,738 line:-1
试着问第一个问题


597
00:31:13,807 --> 00:31:15,342 line:-1
NeXT是由谁成立的？


598
00:31:19,479 --> 00:31:20,614 line:-1
Steve Jobs


599
00:31:26,787 --> 00:31:28,589 line:-1
好的 我想这是对的


600
00:31:29,289 --> 00:31:30,524 line:-1
让我再问一个问题


601
00:31:34,261 --> 00:31:36,330 line:-1
它的总部在哪儿？


602
00:31:39,533 --> 00:31:41,735 line:-1
加利福尼亚的红杉城


603
00:31:46,206 --> 00:31:49,042 line:-1
现在我还有一个非常感兴趣的问题


604
00:31:49,610 --> 00:31:50,644 line:-1
让我试一试


605
00:31:53,280 --> 00:31:55,048 line:-1
工程师们的工资是多少？


606
00:31:58,352 --> 00:32:01,455 line:-1
7万5千美元或5万美元


607
00:32:02,556 --> 00:32:03,457 line:-1
有意思


608
00:32:09,863 --> 00:32:11,265 line:-1
这不是很酷吗？


609
00:32:11,865 --> 00:32:13,267 line:-1
那么现在…


610
00:32:15,736 --> 00:32:18,572 line:-2
让我们更深入地看一下
看看app实际上做了什么


611
00:32:20,574 --> 00:32:24,144 line:-2
这款app的中心部分
是一个最先进的


612
00:32:24,211 --> 00:32:28,348 line:-1
机器学习模型


613
00:32:28,415 --> 00:32:29,349 line:-2
是Transformers的
Bidirectional Encoder Representation


614
00:32:29,816 --> 00:32:30,884 line:-1
这个名字很长


615
00:32:31,351 --> 00:32:34,421 line:-2
我们可以和其他研究者一样
把它简称为BERT模型


616
00:32:35,289 --> 00:32:37,658 line:-1
那么BERT模型是做什么的？


617
00:32:38,225 --> 00:32:40,227 line:-1
嗯 通常是…


618
00:32:40,527 --> 00:32:42,896 line:-1
它实际上是一个神经网络


619
00:32:44,498 --> 00:32:48,869 line:-1
可以实施多任务用于理解自然语言


620
00:32:51,071 --> 00:32:53,340 line:-1
但BERT模型内有什么？


621
00:32:54,808 --> 00:32:55,809 line:-1
有一些模块


622
00:32:56,310 --> 00:32:57,477 line:-1
这些模块内有什么？


623
00:32:58,645 --> 00:33:00,280 line:-1
有层 许多许多层


624
00:33:01,381 --> 00:33:03,050 line:-1
你可以看到 它非常复杂


625
00:33:03,350 --> 00:33:06,053 line:-2
但通过Core ML 3中的
新工具和新功能


626
00:33:06,587 --> 00:33:09,022 line:-2
我可以轻松地把这个模型
引入到我的app中


627
00:33:12,259 --> 00:33:14,661 line:-2
但首先问题是
我要如何得到这个模型？


628
00:33:15,395 --> 00:33:17,631 line:-1
嗯 你可以从我们的模型库网站上


629
00:33:18,999 --> 00:33:21,101 line:-1
得到模型


630
00:33:22,236 --> 00:33:24,071 line:-1
或你可以…如果你喜欢的话


631
00:33:24,338 --> 00:33:26,807 line:-2
如果你可以…你可以训练一个模型
然后再转换它


632
00:33:28,075 --> 00:33:29,977 line:-1
比如前几天的一个晚上


633
00:33:30,043 --> 00:33:32,579 line:-2
我用TensorFlow训练了
我的BERT模型


634
00:33:33,247 --> 00:33:35,883 line:-1
这是我工作区的一张截图


635
00:33:36,517 --> 00:33:39,086 line:-1
抱歉 我的工作区乱糟糟的


636
00:33:39,686 --> 00:33:43,056 line:-1
但要使用Core ML的新转换器


637
00:33:43,724 --> 00:33:49,696 line:-2
我需要把一个模型导入到
Protobuf格式…就是这里


638
00:33:51,031 --> 00:33:54,768 line:-2
然后我需要做的就是键入三行
Python代码


639
00:33:55,869 --> 00:33:57,437 line:-1
导入TF Core ML转换器


640
00:33:58,038 --> 00:33:59,206 line:-1
调用转换函数


641
00:33:59,840 --> 00:34:01,575 line:-1
然后保存为ML模型


642
00:34:03,177 --> 00:34:06,613 line:-2
你可以看到
把模型引入app中非常简单


643
00:34:07,080 --> 00:34:09,283 line:-1
但要让app执行问答操作


644
00:34:09,616 --> 00:34:12,485 line:-1
还需要几个步骤 我想具体讲一下


645
00:34:13,387 --> 00:34:15,088 line:-1
要使用QA模型


646
00:34:15,789 --> 00:34:18,525 line:-1
我需要准备一个问题和一段内容


647
00:34:19,059 --> 00:34:20,893 line:-2
然后把它们分开
作为不同的token


648
00:34:21,695 --> 00:34:24,364 line:-1
模型要预测的是


649
00:34:24,898 --> 00:34:28,101 line:-1
答案在段落中的位置


650
00:34:28,802 --> 00:34:31,338 line:-2
你可以把它看作是个荧光笔
就像你在演示中所看到的那样


651
00:34:33,473 --> 00:34:35,909 line:-1
然后我就可以开始创建我的app了


652
00:34:36,409 --> 00:34:38,478 line:-1
模型自身并不构成app


653
00:34:39,112 --> 00:34:40,280 line:-1
除此之外


654
00:34:40,547 --> 00:34:45,351 line:-2
我还利用其它框架的许多功能
来构建这个app


655
00:34:46,186 --> 00:34:49,056 line:-2
比如我使用语音框架的
speech-to-text API


656
00:34:49,121 --> 00:34:52,659 line:-1
把我的声音翻译为文本


657
00:34:53,560 --> 00:34:58,065 line:-2
我使用自然语言API帮助我创建
分词器


658
00:34:58,832 --> 00:35:03,070 line:-2
最后我使用AVFoundation的
text-to-speech API


659
00:35:03,403 --> 00:35:06,406 line:-1
为我播放答案的音频


660
00:35:07,040 --> 00:35:10,777 line:-2
这些组成部分都利用了设备上的
机器学习


661
00:35:11,078 --> 00:35:14,381 line:-2
因此使用这个app
不需要访问因特网


662
00:35:18,218 --> 00:35:19,319 line:-1
谢谢


663
00:35:19,386 --> 00:35:23,423 line:-1
想象一下有多少新想法


664
00:35:23,490 --> 00:35:26,260 line:-1
和新的用户体验可以引入到app中


665
00:35:27,027 --> 00:35:28,128 line:-1
到此结束 谢谢


666
00:35:36,270 --> 00:35:38,739 line:-1
好的 谢谢Allen


667
00:35:40,841 --> 00:35:43,410 line:-1
好的 在我们总结之前


668
00:35:43,477 --> 00:35:47,881 line:-2
我想再强调今年引入到
Core ML中的三个功能


669
00:35:47,948 --> 00:35:51,018 line:-2
我相信许多Core ML用户
一定会觉得非常有用


670
00:35:52,186 --> 00:35:53,320 line:-1
让我们先看第一个


671
00:35:53,654 --> 00:35:54,988 line:-1
额外更新


672
00:35:56,990 --> 00:35:59,426 line:-2
请想象一下幻灯片中所显示的
这个情境


673
00:35:59,493 --> 00:36:03,697 line:-2
假如我们有两个模型
可以区分动物的不同品种


674
00:36:04,798 --> 00:36:05,933 line:-1
如果你看一下内部


675
00:36:06,400 --> 00:36:09,203 line:-1
这两个模型都是管道模型


676
00:36:09,603 --> 00:36:11,471 line:-1
共享一个通用的功能提取器


677
00:36:12,206 --> 00:36:13,307 line:-1
这种情况经常发生


678
00:36:13,373 --> 00:36:15,776 line:-1
共享…


679
00:36:15,843 --> 00:36:18,879 line:-1
训练深度神经网络以获得功能很常见


680
00:36:19,213 --> 00:36:22,049 line:-2
并且那些功能可以注入到不同的
神经网络


681
00:36:23,684 --> 00:36:24,885 line:-1
实际上在幻灯片中


682
00:36:25,519 --> 00:36:29,189 line:0
我们注意到我们在这两个管道内


683
00:36:29,456 --> 00:36:30,724 line:0
使用了同一模型的多个副本


684
00:36:31,225 --> 00:36:32,759 line:0
这很明显效率很低


685
00:36:33,527 --> 00:36:34,995 line:0
为了提高效率


686
00:36:35,362 --> 00:36:37,865 line:0
我们启动了一个新模型类型
叫做链接模型


687
00:36:38,498 --> 00:36:39,600 line:0
如这里所示


688
00:36:40,968 --> 00:36:42,736 line:0
请看 想法非常简单


689
00:36:43,036 --> 00:36:45,639 line:0
链接模型就是


690
00:36:45,906 --> 00:36:47,808 line:0
对已经引入app的模型的一个引用


691
00:36:48,542 --> 00:36:52,779 line:0
这就把在不同模型中共享一个模型
变得非常简单了


692
00:36:54,915 --> 00:36:57,417 line:-1
我还可以把链接模型看作是


693
00:36:57,484 --> 00:37:01,121 line:-1
它就像是链接到一个动态库一样


694
00:37:01,922 --> 00:37:04,191 line:-1
并且它只有几个参数


695
00:37:04,258 --> 00:37:07,828 line:-2
其中包括它所链接到的模型的名称
以及搜索路径


696
00:37:09,062 --> 00:37:10,797 line:-1
这对于可更新的模型或管道来说


697
00:37:11,665 --> 00:37:13,867 line:-1
非常有用


698
00:37:14,935 --> 00:37:16,069 line:-1
让我们看下一个功能


699
00:37:16,136 --> 00:37:17,337 line:-1
（链接模型）


700
00:37:17,738 --> 00:37:19,806 line:-1
假如你有一个Core ML模型


701
00:37:19,873 --> 00:37:21,708 line:-1
接受图片作为输入


702
00:37:22,142 --> 00:37:26,980 line:-2
目前为止Core ML希望图片是
CVPixelBuffer格式


703
00:37:27,714 --> 00:37:31,285 line:-1
但如果你的图片来自不同的源


704
00:37:31,351 --> 00:37:32,653 line:-1
是不同的格式会怎么样？


705
00:37:33,554 --> 00:37:34,855 line:-1
在大部分情况下


706
00:37:35,522 --> 00:37:39,426 line:-1
你可以使用Vision框架


707
00:37:39,493 --> 00:37:41,562 line:-2
从而可以通过VNCoreMLRequest类
调用Core ML


708
00:37:42,162 --> 00:37:43,597 line:-1
这有一定的好处


709
00:37:43,664 --> 00:37:47,234 line:-2
Vision可以替我们处理
许多不同的图片格式


710
00:37:47,634 --> 00:37:51,939 line:-2
Vision也可以执行预处理
比如图片缩放和剪切等等


711
00:37:53,273 --> 00:37:57,377 line:-2
然而在某些情况下 我们可能会
直接调用Core ML API


712
00:37:57,644 --> 00:38:01,348 line:-1
比如当我们尝试调用更新API时


713
00:38:02,349 --> 00:38:03,417 line:-1
对于这些情况


714
00:38:03,483 --> 00:38:06,119 line:-1
我们发布了一些新初始化程序方法


715
00:38:06,453 --> 00:38:07,521 line:-1
如幻灯片所示


716
00:38:07,588 --> 00:38:11,825 line:-2
因此现在我们可以直接从URL
或CGimage获得一张图片


717
00:38:18,265 --> 00:38:22,503 line:-2
这应该使得在Core ML中
使用图片变得非常方便


718
00:38:24,371 --> 00:38:26,240 line:-1
继续讲我想强调的最后一个功能


719
00:38:26,907 --> 00:38:30,310 line:-2
在Core ML API中有一个类
叫做MLModelConfiguration


720
00:38:31,278 --> 00:38:34,848 line:-1
用于约束Core ML模型


721
00:38:34,915 --> 00:38:36,950 line:-1
可以在哪些设备上执行


722
00:38:37,618 --> 00:38:42,055 line:-1
比如[听不清]默认值是“全部”


723
00:38:42,589 --> 00:38:45,826 line:-1
即全部计算机设备可用


724
00:38:45,893 --> 00:38:47,327 line:-1
包括神经引擎


725
00:38:48,629 --> 00:38:51,398 line:-2
现在我们向这个类中又添加了
一些选项


726
00:38:53,300 --> 00:38:58,272 line:-1
第一个是可以指定


727
00:38:59,239 --> 00:39:00,707 line:-2
模型可以在其上执行的
首选Metal设备


728
00:39:01,275 --> 00:39:02,276 line:-1
你可以想象一下


729
00:39:02,342 --> 00:39:05,279 line:-2
如你在Mac上运行Core ML
模型的话这非常有用


730
00:39:05,345 --> 00:39:08,348 line:-2
因为有许多不同的GPU
连接到Mac


731
00:39:10,150 --> 00:39:13,720 line:-2
我们所添加的另一个选项叫做
低精度累积


732
00:39:14,721 --> 00:39:18,225 line:-2
我们的想法是如果你的模型
在GPU上学习


733
00:39:18,959 --> 00:39:21,562 line:-1
但不是在float32中进行累积


734
00:39:21,628 --> 00:39:22,930 line:-1
而恰好是在float60中


735
00:39:23,664 --> 00:39:27,901 line:-2
现在这可以很大地提高
你模型的学习速度


736
00:39:28,702 --> 00:39:30,537 line:-1
但无论何时当我们降低精度时


737
00:39:30,871 --> 00:39:33,340 line:-1
一定要记得检查模型的准确度


738
00:39:33,874 --> 00:39:36,643 line:-1
准确度可能会下降或也可能不会下降


739
00:39:36,710 --> 00:39:37,945 line:-1
取决于模型类型


740
00:39:38,712 --> 00:39:43,784 line:-2
当你修改模型的精确度时
请总是要试验它的准确度


741
00:39:44,218 --> 00:39:46,553 line:-1
我强烈鼓励你尝试一下这个选项


742
00:39:46,620 --> 00:39:48,322 line:-1
看看是否对你的模型有帮助


743
00:39:50,357 --> 00:39:53,227 line:-2
好的 我们在这场演讲中
讲了许多内容


744
00:39:53,293 --> 00:39:55,462 line:-1
让我快速地总结一下


745
00:39:56,463 --> 00:39:58,999 line:-1
我们讲了


746
00:39:59,566 --> 00:40:02,269 line:-2
通过在设备上
更新Core ML模型


747
00:40:02,336 --> 00:40:04,471 line:-2
来为用户们打造个性化体验
有多么容易


748
00:40:05,205 --> 00:40:08,809 line:-2
我们讲了如何向我们的规范中
添加更多的功能


749
00:40:08,876 --> 00:40:12,346 line:-1
并且现在我们可以向app中


750
00:40:12,813 --> 00:40:13,814 line:-1
引入最先进的神经网络架构了


751
00:40:14,381 --> 00:40:17,985 line:-2
我们还讲了一些与GPU有关的
很便利的API和选项


752
00:40:20,053 --> 00:40:22,422 line:0
这里有一些你可能会感兴趣


753
00:40:22,723 --> 00:40:23,891 line:-1
并且与本场演讲相关的演讲


754
00:40:25,259 --> 00:40:26,326 line:-1
谢谢大家

