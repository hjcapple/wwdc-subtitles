1
00:00:06,473 --> 00:00:09,710 line:0
（用METAL进行光线追踪）


2
00:00:14,982 --> 00:00:15,949 line:-1
大家早上好


3
00:00:16,250 --> 00:00:19,686 line:-2
我叫Sean 我是Apple
GPU软件团队的一名软件工程师


4
00:00:20,854 --> 00:00:22,890 line:-1
在这场演讲中我们要讲光线追踪


5
00:00:23,390 --> 00:00:25,325 line:-1
让我们先回顾一下什么是光线追踪


6
00:00:26,927 --> 00:00:30,063 line:-1
光线追踪app基于追踪


7
00:00:30,130 --> 00:00:31,331 line:-1
光线与场景进行交互时所采取的路径


8
00:00:32,432 --> 00:00:34,401 line:-1
因此光线追踪的app有渲染、


9
00:00:34,768 --> 00:00:36,937 line:-1
音频、物理模拟等等


10
00:00:37,971 --> 00:00:41,842 line:-2
特别是光线追踪经常用于
离线渲染app中


11
00:00:42,142 --> 00:00:44,811 line:-1
用于模拟单条光线在场景中的反弹


12
00:00:46,079 --> 00:00:49,082 line:-2
这就允许这些app渲染照片的
真实反射、


13
00:00:49,149 --> 00:00:52,486 line:-1
折射、阴影、全局照明等等


14
00:00:56,590 --> 00:01:00,127 line:-2
最近光线追踪已经开始
在实时app中使用了


15
00:01:00,194 --> 00:01:01,295 line:-1
比如游戏


16
00:01:01,662 --> 00:01:03,730 line:-1
这实际上引入了一些新需求


17
00:01:05,098 --> 00:01:08,268 line:-1
首先在实时app中物体要四处移动


18
00:01:08,802 --> 00:01:11,305 line:-2
因此我们要既支持摄像头
又支持物体移动


19
00:01:12,940 --> 00:01:15,042 line:-1
第二性能现在变得更加至关重要了


20
00:01:15,108 --> 00:01:15,943 line:-1
（实时光线追踪）


21
00:01:16,009 --> 00:01:19,179 line:-2
这意味着光线交叉自身
必须尽可能的高效


22
00:01:19,913 --> 00:01:22,549 line:-2
并且我们还要高效地使用
有限的光线预算


23
00:01:23,984 --> 00:01:25,853 line:-1
因此我们需要当心采样策略、


24
00:01:25,919 --> 00:01:27,654 line:-1
随机数生成等等


25
00:01:29,590 --> 00:01:31,358 line:-1
最后即使使用这些技术


26
00:01:31,425 --> 00:01:33,760 line:-2
我们也不能投射足够的光线
来消除所有的噪声


27
00:01:34,461 --> 00:01:36,530 line:-2
因此我们需要一个复杂的
噪声消减策略


28
00:01:37,531 --> 00:01:41,535 line:-2
幸运的是Metal内嵌
有对光线追踪和降噪的支持


29
00:01:41,869 --> 00:01:42,970 line:-1
这样就容易多了


30
00:01:44,004 --> 00:01:46,106 line:-2
首先让我们回顾一下光线追踪
在Metal中是如何运作的


31
00:01:46,607 --> 00:01:48,542 line:-1
然后我们继续了解一些更先进的话题


32
00:01:50,677 --> 00:01:52,679 line:-1
如果你看一下典型的光线追踪app


33
00:01:53,046 --> 00:01:54,681 line:-1
它们都遵循一个大致相同的大纲


34
00:01:55,716 --> 00:01:56,950 line:-1
首先我们生成一些光线


35
00:01:57,684 --> 00:02:00,587 line:-2
每条光线都由它的起点和方向矢量
决定


36
00:02:01,889 --> 00:02:04,625 line:-2
然后那些光线在场景中的几何图形上
交叉贯穿


37
00:02:04,691 --> 00:02:06,026 line:-1
这通常会构成三角形


38
00:02:07,194 --> 00:02:10,097 line:-1
交叉数据可以是到交叉点的距离


39
00:02:10,364 --> 00:02:12,232 line:-1
但一般包含额外数据


40
00:02:12,299 --> 00:02:14,067 line:-1
比如被击中的三角的索引


41
00:02:14,501 --> 00:02:16,737 line:-1
以及交叉点的中心坐标


42
00:02:19,006 --> 00:02:20,908 line:-1
下一步将使用交叉点结果


43
00:02:21,175 --> 00:02:22,876 line:-1
比如在渲染app中


44
00:02:23,243 --> 00:02:25,746 line:-1
这一般是着色过程 输出一张图片


45
00:02:26,680 --> 00:02:28,815 line:-1
这个步骤可能也生成额外光线


46
00:02:29,183 --> 00:02:32,219 line:-2
然后我们就重复这个过程
一直重复好多次 直到我们完成


47
00:02:34,254 --> 00:02:36,490 line:-1
app的每一帧的场景中


48
00:02:36,557 --> 00:02:37,724 line:-1
一般都交叉无数条光线


49
00:02:38,792 --> 00:02:42,196 line:-2
并且这个核心交叉步骤对于所有
光线追踪app来说很常见


50
00:02:42,996 --> 00:02:45,699 line:-2
因此我们在Metal中加速了这个
交叉步骤


51
00:02:47,568 --> 00:02:50,637 line:-2
去年我们引入了
MPSRayIntersector API


52
00:02:51,238 --> 00:02:53,473 line:-2
它是Metal性能着色器框架的
一部分


53
00:02:54,308 --> 00:02:57,311 line:-2
这个API在我们所有的
Mac和iOS设备上


54
00:02:57,744 --> 00:02:59,346 line:-1
加速GPU上的光线交叉


55
00:03:00,414 --> 00:03:02,616 line:-2
我们在去年的演讲中
具体介绍了这个API


56
00:03:02,683 --> 00:03:05,519 line:-2
我们推荐你们参考去年的这场演讲
获取更多信息


57
00:03:06,587 --> 00:03:10,190 line:-2
从高层级上说API通过Metal
缓冲区获取成批的光线


58
00:03:11,024 --> 00:03:13,160 line:-1
它查找每条光线上最近的交叉点


59
00:03:13,427 --> 00:03:15,062 line:-1
并把结果返回到另一个缓冲区中


60
00:03:16,997 --> 00:03:19,633 line:-2
所有这些操作都被编码到
Metal commandBuffer中


61
00:03:20,000 --> 00:03:22,936 line:-2
就是你在app中
执行交叉测试的地方


62
00:03:24,905 --> 00:03:26,874 line:-1
许多加速都来自于创建一种


63
00:03:26,940 --> 00:03:28,442 line:-1
叫做加速结构的数据结构


64
00:03:29,243 --> 00:03:32,045 line:-2
这种数据结构在空间中递归地
划分三角


65
00:03:33,080 --> 00:03:35,682 line:-1
从而我们可以在交叉搜索过程中


66
00:03:35,749 --> 00:03:38,151 line:-2
迅速消除不可能与给定光线
进行交叉的三角


67
00:03:40,254 --> 00:03:42,456 line:-1
Metal会替你创建这种数据结构


68
00:03:42,856 --> 00:03:44,057 line:-1
你所要做的就是指定


69
00:03:44,124 --> 00:03:46,193 line:-1
何时创建加速结构


70
00:03:46,527 --> 00:03:49,062 line:-2
再把它传给intersector
用于交叉测试


71
00:03:50,764 --> 00:03:53,166 line:-1
现在创建这种数据结构一般是


72
00:03:53,233 --> 00:03:54,434 line:-1
在app启动时的固定消耗


73
00:03:55,669 --> 00:03:57,237 line:-1
在去年的API版本中


74
00:03:57,304 --> 00:03:59,306 line:-1
总是在CPU上创建这种数据结构


75
00:04:00,107 --> 00:04:02,442 line:-1
今年我们把加速结构的创建


76
00:04:02,709 --> 00:04:03,777 line:-1
移到了GPU上


77
00:04:03,844 --> 00:04:06,079 line:-1
这样可以极大地减少启动消耗


78
00:04:06,713 --> 00:04:09,650 line:-2
更好的是 无论何时只要可能的话
就自动使用GPU


79
00:04:10,184 --> 00:04:12,953 line:-2
因此你不需要做任何事
就能在app中看到这种加速


80
00:04:14,488 --> 00:04:17,324 line:-2
现在让我们回顾一下典型的
光线追踪app


81
00:04:17,391 --> 00:04:20,360 line:-2
看看我们需要执行哪些操作才能把它
转换到Metal光线追踪app中


82
00:04:22,329 --> 00:04:24,198 line:-1
正如我所说过的 我们先生成光线


83
00:04:24,898 --> 00:04:27,000 line:-1
这一般是使用计算内核完成


84
00:04:27,067 --> 00:04:28,869 line:-1
但也可以从片段着色器中实现


85
00:04:29,236 --> 00:04:31,572 line:-2
或可以写入Metal缓冲区的
任意机制


86
00:04:32,673 --> 00:04:34,575 line:-2
然后我们把光线缓冲区传给
intersector


87
00:04:35,709 --> 00:04:36,844 line:-1
它会查找交叉


88
00:04:37,211 --> 00:04:39,112 line:-1
并把结果返回到我们的交叉缓冲区中


89
00:04:40,013 --> 00:04:41,615 line:-2
请记住 要使用
intersector


90
00:04:41,949 --> 00:04:43,750 line:0
我们需要提供一个加速结构


91
00:04:44,451 --> 00:04:47,120 line:0
我们通常只需要创建一次
然后多次重复使用


92
00:04:48,589 --> 00:04:50,791 line:0
最后我们要启动最后一个计算内核


93
00:04:51,291 --> 00:04:55,028 line:0
它将使用交叉数据
把着色的图片写入一个纹理中


94
00:04:56,029 --> 00:04:57,197 line:0
并且在迭代的app中


95
00:04:57,264 --> 00:05:00,801 line:0
这个计算内核还会把额外光线
重新写入到光线缓冲区


96
00:05:02,336 --> 00:05:04,271 line:0
让我们在一个实际的app中看一下
这是如何运作的


97
00:05:05,606 --> 00:05:08,342 line:-1
在这个例子中 我们要讲


98
00:05:08,408 --> 00:05:09,543 line:-2
如何在AR Quick Look
中使用光线追踪


99
00:05:10,177 --> 00:05:11,879 line:-2
AR Quick Look
是去年引入的


100
00:05:11,945 --> 00:05:14,848 line:-1
可以让你在增强现实中预览3D资产


101
00:05:15,983 --> 00:05:18,452 line:-2
我们在今早的演讲中具体讲了
AR Quick Look


102
00:05:18,519 --> 00:05:20,354 line:-1
我也推荐你们观看那场演讲


103
00:05:21,154 --> 00:05:23,257 line:-2
在本场演讲中 我们主要讲
AR Quick Look


104
00:05:23,323 --> 00:05:26,093 line:-2
如何使用光线追踪来渲染
环境光遮蔽效果


105
00:05:27,160 --> 00:05:29,763 line:-2
我们稍后再具体讲环境光遮蔽
但现在


106
00:05:29,830 --> 00:05:31,999 line:-1
你需要了解环境光遮蔽


107
00:05:32,065 --> 00:05:35,736 line:-2
计算一个近似值 即有多少光可以
到达场景中的每一个点


108
00:05:36,703 --> 00:05:39,540 line:-1
这导致机器人模型下的地面变暗


109
00:05:39,873 --> 00:05:43,143 line:-2
以及机器人的腿和地面之间的
软接触阴影


110
00:05:45,112 --> 00:05:47,314 line:-2
效果有点微不足道
但如果我们把它关掉


111
00:05:47,381 --> 00:05:48,949 line:-1
我们可以看到它实际上花了很久


112
00:05:49,016 --> 00:05:50,617 line:-1
才把机器人放在场景中的地面上


113
00:05:51,318 --> 00:05:53,453 line:-1
这对于AR app来说非常重要


114
00:05:53,854 --> 00:05:56,623 line:-2
可以防止物体看起来像是漂浮在
地面上一样


115
00:05:58,859 --> 00:06:00,494 line:-2
在去年的
AR Quick Look版本中


116
00:06:00,561 --> 00:06:02,196 line:-1
阴影实际上是预先计算的


117
00:06:02,696 --> 00:06:04,531 line:-1
因此它们不会随着物体的移动而移动


118
00:06:06,300 --> 00:06:09,336 line:-2
今年我们使用了
Metal对动态场景的支持


119
00:06:09,403 --> 00:06:10,938 line:-1
对这些阴影进行实时渲染


120
00:06:11,505 --> 00:06:14,174 line:-2
因此现在随着物体的移动
它们的阴影也随着它们移动


121
00:06:16,310 --> 00:06:19,246 line:-2
这甚至对于变形的物体也起作用
比如蒙皮模型


122
00:06:19,746 --> 00:06:21,882 line:-1
我们可以看到阴影


123
00:06:21,949 --> 00:06:23,250 line:-1
随着鱼在场景中的游动而移动


124
00:06:26,320 --> 00:06:28,856 line:-1
正在发生的有三种类型的动画


125
00:06:29,623 --> 00:06:31,258 line:-1
如果我们只使用光栅化程序


126
00:06:31,325 --> 00:06:33,460 line:-2
我们可以在三角的新位置上
对三角进行光栅化


127
00:06:33,527 --> 00:06:34,361 line:-1
（动态场景）


128
00:06:34,428 --> 00:06:35,796 line:-1
但因为我们使用了光线追踪


129
00:06:35,863 --> 00:06:37,798 line:-1
我们需要维持加速结构


130
00:06:39,299 --> 00:06:41,702 line:-2
因此动画的第一种类型是简单的
摄像头移动


131
00:06:41,969 --> 00:06:44,404 line:-2
这种移动是由于
只移动iPad造成的


132
00:06:45,506 --> 00:06:47,241 line:-1
我们不需要更新加速结构


133
00:06:47,307 --> 00:06:48,642 line:-1
仅仅因为摄像头移动了


134
00:06:48,942 --> 00:06:50,911 line:-2
因此我们实际上是免费获得了
这种类型的动画


135
00:06:51,678 --> 00:06:54,014 line:-2
我们可以开始从新摄像头的位置上
发射光线


136
00:06:55,349 --> 00:06:56,483 line:-1
其它两种动画类型


137
00:06:56,550 --> 00:06:58,485 line:-1
都要求更新加速结构


138
00:06:59,887 --> 00:07:01,388 line:-1
第一种是顶点动画


139
00:07:02,256 --> 00:07:04,191 line:-1
这可以是蒙皮模型 比如鱼


140
00:07:04,258 --> 00:07:06,393 line:-1
但也可以是风中摇曳的植物、


141
00:07:06,460 --> 00:07:08,395 line:-1
衣服或其它变形类型


142
00:07:09,363 --> 00:07:12,199 line:-2
Metal包含一种特殊的加速结构
更新机制


143
00:07:12,266 --> 00:07:13,600 line:-1
针对这样的类进行了优化


144
00:07:15,402 --> 00:07:17,504 line:-1
最后一种动画类型是刚体动画


145
00:07:18,405 --> 00:07:20,974 line:-1
物体可以移动、旋转和缩放


146
00:07:21,041 --> 00:07:22,910 line:-1
但完全维持它们的形状


147
00:07:23,710 --> 00:07:26,680 line:-2
因此一大部分加速结构实际上
仍然有效


148
00:07:27,347 --> 00:07:29,416 line:-1
Metal还包含一种特殊机制


149
00:07:29,483 --> 00:07:32,319 line:-2
用于重新利用
部分没有发生变更的加速结构


150
00:07:33,554 --> 00:07:35,255 line:-1
首先让我们讲一下顶点动画


151
00:07:35,322 --> 00:07:36,623 line:-1
（顶点动画）


152
00:07:36,690 --> 00:07:37,891 line:-1
随着几何图形的变更


153
00:07:37,958 --> 00:07:39,760 line:-1
我们需要更新加速结构


154
00:07:40,661 --> 00:07:42,729 line:-2
我们要给每一帧从头开始
重新创建加速结构


155
00:07:42,796 --> 00:07:43,997 line:-1
但我们实际上可以做的更好


156
00:07:45,432 --> 00:07:47,167 line:-1
在顶点动画用例中


157
00:07:47,467 --> 00:07:49,303 line:-1
物体往往保持大体形状


158
00:07:49,736 --> 00:07:52,339 line:-1
比如角色的手将保持与胳膊相连接


159
00:07:52,573 --> 00:07:54,875 line:-1
他们的胳膊将保持与身体相连接等等


160
00:07:55,776 --> 00:07:58,946 line:-1
因此编码到加速结构中的空间谱系


161
00:07:59,246 --> 00:08:00,447 line:-1
大部分仍然有效


162
00:08:00,881 --> 00:08:02,850 line:-1
只需要调整到新几何图形即可


163
00:08:03,750 --> 00:08:04,718 line:-1
让我们看一个例子


164
00:08:06,086 --> 00:08:08,188 line:-1
这是我们之前看到过的加速结构


165
00:08:09,356 --> 00:08:10,457 line:-1
如果三角移动


166
00:08:10,524 --> 00:08:13,193 line:-2
我们可以看到边界区域
不再与三角对齐了


167
00:08:13,894 --> 00:08:16,230 line:-1
但树形结构自身绝大部分仍然有意义


168
00:08:16,930 --> 00:08:18,599 line:-1
因此我们与其从头重新创建加速结构


169
00:08:18,665 --> 00:08:21,702 line:-1
不如把边界区域对齐到三角的新位置


170
00:08:21,768 --> 00:08:22,736 line:-1
从底部到顶部


171
00:08:24,505 --> 00:08:25,973 line:-1
我们把这个操作叫做再安置


172
00:08:26,874 --> 00:08:29,676 line:-2
我们可以看到
这仍然是有效的加速结构


173
00:08:30,244 --> 00:08:32,312 line:-1
但比从头开始创建要快多了


174
00:08:32,379 --> 00:08:34,114 line:-2
因为我们可以重新使用现有的
树形结构


175
00:08:35,916 --> 00:08:37,683 line:0
这也是完全在GPU上运行的


176
00:08:38,051 --> 00:08:39,318 line:0
从而让这个过程变得更快了


177
00:08:39,385 --> 00:08:42,289 line:0
但也意味着我们可以安全地编码
再安置操作


178
00:08:42,356 --> 00:08:45,526 line:0
在比如说计算内核更新顶点之后


179
00:08:47,394 --> 00:08:49,863 line:0
坏消息是我们不能添加或移除
任何几何图形


180
00:08:49,930 --> 00:08:52,599 line:0
因为树形结构仍将编码
对旧几何图形的引用


181
00:08:54,568 --> 00:08:57,371 line:0
这还潜在地降低了加速结构的品质


182
00:08:57,437 --> 00:08:59,139 line:0
那可能会影响光线追踪的性能


183
00:08:59,973 --> 00:09:02,242 line:0
这是因为三角形最初是使用一套
未来学进行划分的


184
00:09:02,309 --> 00:09:05,479 line:0
在三角移动之后不会进行加速


185
00:09:06,780 --> 00:09:08,148 line:0
影响通常都很微小


186
00:09:08,215 --> 00:09:11,818 line:0
但极端情况下 比如远距离传送
几何图形可能会导致性能问题


187
00:09:12,686 --> 00:09:15,189 line:0
尽管如此 这对于典型的变形用例


188
00:09:15,255 --> 00:09:16,790 line:0
和角色蒙皮用例来说非常棒


189
00:09:17,724 --> 00:09:18,926 line:0
让我们看一下如何在代码中进行设置


190
00:09:20,494 --> 00:09:22,596 line:-1
首先在我们创建加速结构之前


191
00:09:22,663 --> 00:09:24,331 line:-1
我们需要先启动对重新安置的支持


192
00:09:24,998 --> 00:09:26,767 line:-1
请注意仅仅启动重新安置


193
00:09:26,834 --> 00:09:29,136 line:-1
就已经可能会降低加速结构的品质了


194
00:09:29,636 --> 00:09:31,071 line:-1
因此如果你真的需要再安置加速结构


195
00:09:31,138 --> 00:09:33,106 line:-1
请一定要开启这个功能


196
00:09:33,173 --> 00:09:34,508 line:-1
（再安置）


197
00:09:34,575 --> 00:09:37,578 line:-2
然后我们把encodeRefit调用到
Metal commandBuffer中


198
00:09:38,946 --> 00:09:40,814 line:-2
对于顶点动画来说
这是我们所需要做的全部操作


199
00:09:41,715 --> 00:09:43,951 line:-1
接下来我们讲刚体动画


200
00:09:45,385 --> 00:09:46,320 line:-1
正如它的名字所暗示的那样


201
00:09:46,386 --> 00:09:49,189 line:-2
在这种动画中 物体可以移动、
旋转和缩放


202
00:09:49,256 --> 00:09:51,225 line:-1
但要完全维持它们的形状


203
00:09:51,959 --> 00:09:53,393 line:-1
在右侧的例子中


204
00:09:53,460 --> 00:09:55,295 line:-1
即使机器人看起来正在变形


205
00:09:55,362 --> 00:09:57,464 line:-1
实际上它所有的关节都在僵硬地移动


206
00:09:57,831 --> 00:10:00,067 line:-1
这也是一个刚体动画的例子


207
00:10:01,401 --> 00:10:02,469 line:-1
在一个典型场景中


208
00:10:02,536 --> 00:10:04,972 line:-2
大部分几何图形很可能只是
僵硬地移动


209
00:10:05,606 --> 00:10:08,342 line:-2
事实上大部分几何图形很可能
不发生移动


210
00:10:10,010 --> 00:10:13,013 line:-2
我们还可以在场景中多次复制
同一个物体


211
00:10:13,914 --> 00:10:16,483 line:-1
在加速结构中多次复制这些物体


212
00:10:16,550 --> 00:10:17,885 line:-1
消耗很大


213
00:10:18,352 --> 00:10:20,554 line:-2
仅仅因为几何图形的一部分
发生了移动


214
00:10:20,621 --> 00:10:22,122 line:-1
就再安置或重建整个加速结构


215
00:10:22,456 --> 00:10:24,491 line:-1
效率也很低


216
00:10:25,993 --> 00:10:27,461 line:-1
因此为了解决这两个问题


217
00:10:27,528 --> 00:10:29,930 line:-2
我们可以使用一种叫做
二级加速结构的东西


218
00:10:32,432 --> 00:10:33,600 line:-1
我们要做的就是首先


219
00:10:33,667 --> 00:10:35,802 line:-1
给场景中的每个唯一物体


220
00:10:35,869 --> 00:10:37,671 line:-1
创建一个高品质的三角加速结构


221
00:10:37,738 --> 00:10:39,873 line:-2
我们只需要在app启动时
做一次就可以


222
00:10:41,441 --> 00:10:43,243 line:-1
然后我们要使用第二加速结构


223
00:10:43,710 --> 00:10:47,214 line:-1
两次复制那些三角加速结构


224
00:10:48,015 --> 00:10:49,850 line:-1
每次复制


225
00:10:49,917 --> 00:10:52,252 line:-1
都是原始三角加速结构的一个实例


226
00:10:53,887 --> 00:10:56,290 line:-1
每个实例都与一个转换矩阵相关联


227
00:10:57,124 --> 00:10:58,792 line:-1
描述要把它放在场景中的哪个位置


228
00:10:59,760 --> 00:11:01,428 line:-1
我们使用两个缓冲区来实现


229
00:11:01,495 --> 00:11:04,464 line:-2
每个缓冲区都包含场景中
每个实例的一个输入


230
00:11:05,832 --> 00:11:08,035 line:-1
第一个缓冲区包含


231
00:11:08,101 --> 00:11:09,203 line:-1
所有实例的转换矩阵


232
00:11:10,404 --> 00:11:12,472 line:-1
第二个缓冲区包含


233
00:11:12,539 --> 00:11:14,875 line:-1
对三角加速结构数组的索引


234
00:11:15,209 --> 00:11:18,078 line:-1
描述每个实例使用哪个加速结构


235
00:11:20,414 --> 00:11:22,516 line:-1
然后我们要在场景中的实例上


236
00:11:22,583 --> 00:11:24,451 line:-1
创建第二加速结构


237
00:11:25,586 --> 00:11:28,488 line:-1
然后随着物体的移动


238
00:11:28,555 --> 00:11:29,623 line:-2
我们只需要快速重建实例的
加速结构即可


239
00:11:30,557 --> 00:11:31,725 line:-1
让我们看一下如何进行设置


240
00:11:32,926 --> 00:11:35,529 line:0
首先我们要创建一个
AccelerationStructureGroup


241
00:11:36,396 --> 00:11:38,565 line:0
实例的等级中的所有加速结构


242
00:11:38,632 --> 00:11:39,833 line:0
都必须属于同一个群组


243
00:11:40,267 --> 00:11:42,336 line:0
这就允许它们在内部分享资源


244
00:11:43,971 --> 00:11:47,007 line:0
接下来我们要创建一个数组
容纳我们的三角加速结构


245
00:11:47,908 --> 00:11:50,711 line:0
最后我们要循环场景中的
全部唯一物体


246
00:11:51,111 --> 00:11:53,447 line:0
给每个唯一物体都创建一个
三角加速结构


247
00:11:53,514 --> 00:11:54,982 line:0
并在结束时把它们添加到数组中


248
00:11:57,251 --> 00:11:59,853 line:-2
我们现在已经准备好创建
二级加速结构了


249
00:12:00,187 --> 00:12:03,423 line:-2
我们通过使用NPSInstance
AccelerationStructure类实现


250
00:12:04,358 --> 00:12:07,361 line:-1
先附加我们的三角加速结构数组


251
00:12:08,128 --> 00:12:10,130 line:-1
以及我之前讲过的两个缓冲区


252
00:12:10,931 --> 00:12:13,767 line:-1
最后我们要指定场景中的实例的编号


253
00:12:15,369 --> 00:12:18,005 line:-1
然后无论何时当物体移动时


254
00:12:18,071 --> 00:12:19,239 line:-1
或场景中增加或移除一个物体时


255
00:12:19,706 --> 00:12:22,242 line:0
我们可以使用实例加速结构
来进行重建


256
00:12:23,243 --> 00:12:25,379 line:0
一般来说这种加速结构


257
00:12:25,445 --> 00:12:27,047 line:0
比三角加速结构要小多了


258
00:12:27,381 --> 00:12:28,849 line:0
我们可以给每一帧都执行这种操作


259
00:12:29,316 --> 00:12:31,051 line:0
请注意 与再安置类似


260
00:12:31,118 --> 00:12:33,053 line:0
当使用实例时有一些消耗


261
00:12:33,720 --> 00:12:36,456 line:0
因此如果你的场景仅有一个物体
或只有少量物体


262
00:12:36,523 --> 00:12:38,392 line:0
或特别是如果没有物体发生移动


263
00:12:38,792 --> 00:12:42,162 line:0
可能值得把那些物体放到单个
三角加速结构中


264
00:12:43,030 --> 00:12:44,598 line:0
这将增加你的内存占用


265
00:12:44,665 --> 00:12:46,967 line:0
但也会回馈给你更好的性能


266
00:12:47,668 --> 00:12:50,537 line:0
因此你需要进行试验来找到
对于你的app来说最好的方案


267
00:12:52,239 --> 00:12:53,540 line:0
那么这就是动态场景


268
00:12:53,841 --> 00:12:56,076 line:0
我们讲了如何使用再安置


269
00:12:56,143 --> 00:12:57,177 line:0
支持顶点动画和蒙皮动画


270
00:12:57,678 --> 00:12:59,513 line:0
以及如何使用二级加速结构


271
00:12:59,580 --> 00:13:01,381 line:0
支持刚体动画


272
00:13:02,249 --> 00:13:04,618 line:-1
接下来我们谈谈降噪


273
00:13:07,287 --> 00:13:09,890 line:-2
目前我们所看到的所有图片
都没有噪声


274
00:13:10,390 --> 00:13:12,793 line:-1
那是因为它们都使用了降噪过滤器


275
00:13:13,727 --> 00:13:14,661 line:-1
如果我们把它关掉


276
00:13:14,728 --> 00:13:17,197 line:-2
我们可以看到如果没有降噪程序
看起来会是什么样子


277
00:13:17,898 --> 00:13:20,901 line:-2
我们可以看到这些图片如果用在
真正的app中太嘈杂了


278
00:13:21,568 --> 00:13:23,971 line:-2
那是因为我们仅对每个像素使用了
少量样本


279
00:13:25,272 --> 00:13:27,307 line:-1
通常我们会随时间


280
00:13:27,374 --> 00:13:28,542 line:-1
一起平均更多的样本来解决


281
00:13:28,976 --> 00:13:30,777 line:-1
但如果摄像头或物体正在移动


282
00:13:30,844 --> 00:13:31,945 line:-1
就没有那么简单了


283
00:13:32,613 --> 00:13:35,916 line:-2
幸运的是Metal现在包含
一个复杂的降噪过滤器


284
00:13:36,783 --> 00:13:37,751 line:-1
让我们看看它是如何运作的


285
00:13:39,186 --> 00:13:42,155 line:-1
理想情况是我们可以轻松地


286
00:13:42,222 --> 00:13:43,290 line:-1
使用渲染器输出噪声图像


287
00:13:43,357 --> 00:13:45,592 line:-2
通过降噪器运行它并返回一张
干净的图片


288
00:13:46,293 --> 00:13:49,196 line:-2
在实践中
降噪器需要关于场景的一些信息


289
00:13:50,397 --> 00:13:52,199 line:-1
我们从提供直接可见的


290
00:13:52,266 --> 00:13:53,667 line:-1
几何图形的深度和法线开始


291
00:13:54,401 --> 00:13:56,603 line:-1
许多渲染器周围都有这样的纹理


292
00:13:56,904 --> 00:13:58,438 line:-1
如果没有 那也很容易生成


293
00:14:00,107 --> 00:14:02,576 line:-1
然后降噪器将运行一堆图像处理操作


294
00:14:02,643 --> 00:14:03,810 line:-1
并输入一个较干净的图片


295
00:14:04,411 --> 00:14:06,780 line:-2
但因为我们的起点是每个像素仅有的
少量样本


296
00:14:06,847 --> 00:14:08,315 line:-1
因此最后得到的图片仍会有一些噪声


297
00:14:09,016 --> 00:14:12,286 line:-2
因此我们要重新查看在多个帧上
合并样本的想法


298
00:14:13,754 --> 00:14:16,690 line:0
我们首先要留出干净的图片
从而在下一帧中重复使用


299
00:14:17,791 --> 00:14:19,660 line:0
我们还要留出深度和法线


300
00:14:19,726 --> 00:14:21,261 line:0
从而我们可以与下一帧中的
深度和法线进行对比


301
00:14:22,262 --> 00:14:24,498 line:0
最后我们要提供一个动作矢量纹理


302
00:14:24,765 --> 00:14:27,434 line:0
描述每个像素在帧之间移动了多少


303
00:14:29,603 --> 00:14:31,672 line:0
在下一帧中 降噪器将穿过


304
00:14:31,738 --> 00:14:34,074 line:0
所有纹理并产生一张更好的图片


305
00:14:34,808 --> 00:14:36,877 line:0
这个图片将随时间变得更好


306
00:14:37,177 --> 00:14:38,645 line:0
即使摄像头或物体移动了也一样


307
00:14:40,080 --> 00:14:42,683 line:-1
降噪器将使用深度和法线来检测


308
00:14:43,016 --> 00:14:45,152 line:-1
像素的历史记录是否


309
00:14:45,586 --> 00:14:47,588 line:-2
由于物体移动或物体被阻碍
而变得无效


310
00:14:49,289 --> 00:14:52,426 line:-2
这些都要使用MPSSVGF类家族
来实施


311
00:14:53,827 --> 00:14:56,697 line:-2
这是对很流行的
MPSSVGF降噪算法的实施


312
00:14:57,431 --> 00:14:59,499 line:-1
这个算法在高品质


313
00:14:59,566 --> 00:15:00,734 line:-1
和实时性能之间做出很好的权衡


314
00:15:01,902 --> 00:15:03,770 line:-1
因此降噪的整个过程


315
00:15:03,837 --> 00:15:06,206 line:-1
都由MPSSVGFDenoiser类调节


316
00:15:07,241 --> 00:15:11,245 line:-2
与此同时还使用MPSSVGF类
提供低级控制


317
00:15:12,246 --> 00:15:14,314 line:-1
这个类提供单一计算内核


318
00:15:14,381 --> 00:15:15,415 line:-1
供降噪器使用


319
00:15:15,682 --> 00:15:17,918 line:-1
并暴露许多参数 你可以用于调整


320
00:15:17,985 --> 00:15:19,319 line:-1
app中的降噪处理


321
00:15:20,087 --> 00:15:22,222 line:-1
你只需要直接调用这个类的方法


322
00:15:22,289 --> 00:15:23,624 line:-1
就可以创建一个自定义降噪器


323
00:15:25,225 --> 00:15:26,260 line:-1
降噪器


324
00:15:26,326 --> 00:15:28,262 line:-1
在降噪过程中


325
00:15:28,328 --> 00:15:29,663 line:-1
创建并销毁相当多的临时纹理


326
00:15:30,297 --> 00:15:33,000 line:-1
因此MPSSVGF纹理分配器协议


327
00:15:33,367 --> 00:15:35,302 line:-1
充当了这些内存分配的缓存


328
00:15:36,603 --> 00:15:38,438 line:-1
你可以使用默认实施


329
00:15:38,705 --> 00:15:41,909 line:-2
或自己实施这个协议
与你自己的app共享内存


330
00:15:43,343 --> 00:15:46,580 line:-2
一般来说 我们会对所有
Mac和iOS设备优化这些类


331
00:15:47,614 --> 00:15:50,517 line:-1
降噪器可以同时处理两张独立的图片


332
00:15:50,984 --> 00:15:54,087 line:-1
比如你可能想把直接和间接照明


333
00:15:54,154 --> 00:15:55,189 line:-1
分到不同的纹理中


334
00:15:56,089 --> 00:15:58,425 line:-1
还有单个通道纹理的快速路径


335
00:15:58,492 --> 00:16:00,727 line:-1
比如环境光遮蔽或阴影纹理


336
00:16:00,794 --> 00:16:03,197 line:-2
这比降噪一张完整的
RBG图片速度快


337
00:16:04,264 --> 00:16:05,365 line:-1
让我们看看该如何创建快速路径


338
00:16:06,700 --> 00:16:09,336 line:0
首先我们要创建MPSSVGF物体


339
00:16:09,403 --> 00:16:10,637 line:0
并配置其属性


340
00:16:11,238 --> 00:16:13,841 line:0
我们所要提供的就是
用于降噪的Metal设备


341
00:16:15,576 --> 00:16:17,211 line:0
接下来我们要创建
TextureAllocator


342
00:16:17,277 --> 00:16:19,379 line:0
在这个例子中我们仅使用默认实施


343
00:16:20,614 --> 00:16:23,083 line:0
最后我们要创建高级降噪器对象


344
00:16:23,150 --> 00:16:24,852 line:0
管理降噪过程


345
00:16:26,186 --> 00:16:27,721 line:-1
现在我们已经准备好执行降噪了


346
00:16:28,255 --> 00:16:30,858 line:0
我们先给降噪器附加全部的输入纹理


347
00:16:31,592 --> 00:16:33,794 line:0
现在我们把整个降噪进程编码到


348
00:16:33,861 --> 00:16:35,195 line:0
Metal commandBuffer中


349
00:16:35,929 --> 00:16:38,465 line:0
最后我们可以从降噪器中取回
干净的图片


350
00:16:39,533 --> 00:16:42,102 line:-2
这就是给app启动降噪过程
所需要做的全部操作


351
00:16:44,137 --> 00:16:46,173 line:-1
目前我们讲了Metal中


352
00:16:46,240 --> 00:16:48,308 line:-1
用于光线追踪和降噪的所有基本知识


353
00:16:49,142 --> 00:16:51,812 line:-2
我们回顾了如何使用
MPS Ray Intersector API


354
00:16:52,145 --> 00:16:54,081 line:-1
执行基本的光线/三角交叉测试


355
00:16:54,982 --> 00:16:57,251 line:-2
然后我们讲了如何使用再安置
和二级加速结构


356
00:16:57,317 --> 00:17:00,020 line:-1
把这个测试扩展到动态场景中


357
00:17:00,921 --> 00:17:03,123 line:-2
最后我们讲了如何使用
MPSSVGF类


358
00:17:03,190 --> 00:17:05,959 line:-1
移除图片中的噪声


359
00:17:07,194 --> 00:17:09,329 line:-1
不要担心信息量太大


360
00:17:09,396 --> 00:17:10,396 line:-1
我们编写了一个样本


361
00:17:10,464 --> 00:17:12,432 line:-1
演示如何使用所有这些概念


362
00:17:12,499 --> 00:17:13,634 line:-1
这个样本在线可用


363
00:17:15,169 --> 00:17:17,771 line:-1
我之前提到过我们需要注意性能


364
00:17:17,838 --> 00:17:19,173 line:-1
特别是在实时情况下


365
00:17:19,705 --> 00:17:21,407 line:-2
因此接下来我要邀请我同事
Wayne上台


366
00:17:21,808 --> 00:17:24,211 line:-2
介绍如何在满足
实际性能预算的情况下


367
00:17:24,478 --> 00:17:25,746 line:-1
在实际设备上实现这些功能


368
00:17:31,985 --> 00:17:32,953 line:-1
大家好


369
00:17:33,720 --> 00:17:36,023 line:-1
在这部分的演讲中


370
00:17:36,089 --> 00:17:38,358 line:-1
我要讲的是如何使用


371
00:17:38,425 --> 00:17:39,493 line:-1
Metal中的光线追踪功能


372
00:17:39,993 --> 00:17:43,197 line:-2
在你的app中实施一些不同的
渲染技巧


373
00:17:44,298 --> 00:17:46,934 line:-1
特别是我主要讲软硬阴影、


374
00:17:47,467 --> 00:17:49,703 line:-1
环境光遮蔽和全局照明


375
00:17:51,505 --> 00:17:52,840 line:0
先从硬阴影开始讲


376
00:17:53,974 --> 00:17:55,809 line:0
我们用光线追踪
创建硬阴影模型的方式是


377
00:17:55,876 --> 00:17:57,744 line:0
让表面上的点


378
00:17:57,811 --> 00:17:59,980 line:0
朝着太阳的方向形成光线


379
00:18:01,348 --> 00:18:02,549 line:0
如果某条光线击中了某个东西


380
00:18:02,616 --> 00:18:04,251 line:0
那么相关联的点就处于阴影中


381
00:18:04,918 --> 00:18:06,453 line:0
反之就处于太阳光下


382
00:18:08,388 --> 00:18:11,425 line:-1
要把硬阴影集成到现有app中


383
00:18:11,725 --> 00:18:14,461 line:-1
我假设你已经有了这样一个东西


384
00:18:15,095 --> 00:18:16,430 line:-1
你已经栅格化一个G-Buffer


385
00:18:16,897 --> 00:18:18,432 line:-1
并对照明运行了计算过程


386
00:18:18,832 --> 00:18:21,034 line:-2
它的输出就是你最终得到的
着色的图片


387
00:18:22,836 --> 00:18:25,005 line:-1
要利用光线追踪


388
00:18:25,072 --> 00:18:26,640 line:-1
在这里我们先获取G-Buffer


389
00:18:27,040 --> 00:18:29,443 line:-2
然后运行一个计算着色器
生成一些光线


390
00:18:30,844 --> 00:18:32,513 line:-2
然后我们把那些光线
传递给Metal


391
00:18:32,579 --> 00:18:34,448 line:-1
以一种加速结构进行交叉


392
00:18:35,082 --> 00:18:37,551 line:-2
Metal将把结果输出到一个
交叉缓冲区中


393
00:18:38,852 --> 00:18:40,954 line:-2
现在你可以在着色内核中使用
这个缓冲区了


394
00:18:41,021 --> 00:18:43,023 line:-1
用于决定表面的点是否处于阴影中


395
00:18:44,858 --> 00:18:47,928 line:-1
我想让你们重点关注的是光线生成


396
00:18:48,762 --> 00:18:52,165 line:-2
让我们快速回顾一下Metal中
是如何描述光线的


397
00:18:54,368 --> 00:18:57,037 line:-1
Metal提供一些不同的光线结构


398
00:18:57,471 --> 00:19:00,340 line:-1
至少包含光线原点


399
00:19:00,407 --> 00:19:01,575 line:-1
和光线方向的字段


400
00:19:02,776 --> 00:19:05,779 line:-2
你只需要给你想要追踪的每条光线
填充其中一种结构


401
00:19:05,846 --> 00:19:07,314 line:-1
并把这种结构写入光线缓冲区即可


402
00:19:10,017 --> 00:19:12,653 line:0
你在光线缓冲区中安排光线的方式


403
00:19:13,153 --> 00:19:14,555 line:0
对性能有影响


404
00:19:15,556 --> 00:19:16,890 line:0
通常你可能像这样开始


405
00:19:17,257 --> 00:19:18,692 line:0
我们以线性次序调用这行


406
00:19:20,627 --> 00:19:24,064 line:0
这里的问题是随着Metal
以自己的方式处理这些光线


407
00:19:24,531 --> 00:19:27,935 line:0
光线可能会击中
Metal用于加速光线遍历的


408
00:19:28,001 --> 00:19:30,103 line:0
内部数据结构中不同的节点


409
00:19:31,371 --> 00:19:33,841 line:0
这反过来可能会刷新底层硬件缓存


410
00:19:35,709 --> 00:19:38,378 line:0
因此更好的方式是使用像素块
线性次序


411
00:19:39,746 --> 00:19:41,548 line:0
因此来自屏幕上相邻像素的光线


412
00:19:41,615 --> 00:19:44,251 line:0
可以击中加速结构的同一个部分


413
00:19:44,985 --> 00:19:46,720 line:0
并像这样存储光线


414
00:19:46,787 --> 00:19:49,356 line:0
让Metal更高效地驱动硬件


415
00:19:50,991 --> 00:19:54,561 line:0
在这里的可视化中我要给你演示
尺寸为4乘4的像素块


416
00:19:55,162 --> 00:19:57,464 line:0
在实践中我们发现8乘8尺寸
非常非常适合


417
00:20:00,200 --> 00:20:03,504 line:-2
因此优化光线存储
是改善性能的一个不错的方式


418
00:20:03,804 --> 00:20:07,341 line:-2
但如果可能的话
更好的方式是完全不发射光线


419
00:20:09,243 --> 00:20:10,644 line:-1
在阴影情境中


420
00:20:11,144 --> 00:20:12,546 line:-1
你想要这样做的原因可能是


421
00:20:12,613 --> 00:20:14,781 line:-1
并不是所有的像素都需要阴影光线


422
00:20:15,749 --> 00:20:18,485 line:-2
比如背景上的像素
天空盒上的像素


423
00:20:18,552 --> 00:20:20,654 line:-1
或背向太阳的表面上的像素


424
00:20:22,756 --> 00:20:25,993 line:-2
你的光线缓冲区很可能包含一种
光线结构


425
00:20:26,059 --> 00:20:27,494 line:-1
应用于屏幕上的每一个像素


426
00:20:28,228 --> 00:20:30,364 line:-1
我们需要的是一种方法


427
00:20:30,430 --> 00:20:33,333 line:-2
告诉Metal跳过我们毫不在乎的
像素的光线发射操作


428
00:20:34,801 --> 00:20:36,103 line:-1
有几种方法可以实现


429
00:20:36,537 --> 00:20:37,838 line:-1
我在这里要给你们展示的方式是


430
00:20:37,905 --> 00:20:40,641 line:-2
把光线结构中的
maxDistance字段


431
00:20:41,008 --> 00:20:42,075 line:-1
设为一个负值


432
00:20:44,344 --> 00:20:46,613 line:-2
这就是你需要了解的
关于硬阴影的主要信息


433
00:20:47,581 --> 00:20:49,917 line:-2
你可以看到
光线追踪能够产生非常好的效果


434
00:20:50,217 --> 00:20:52,252 line:-1
阴影非常清晰并且非常精确


435
00:20:54,354 --> 00:20:56,990 line:-2
但在现实中
阴影是由于太阳投射而产生


436
00:20:57,925 --> 00:20:59,259 line:-1
看起来不那么尖锐…


437
00:20:59,993 --> 00:21:01,061 line:-1
它们看起来可能更像是这样的效果


438
00:21:01,795 --> 00:21:04,798 line:-2
它们的边界比较柔和
并且柔和度与距离有关


439
00:21:06,233 --> 00:21:08,635 line:-1
你可以在左侧看到一个很棒的例子


440
00:21:09,403 --> 00:21:11,839 line:-1
灯柱的阴影在底座处是硬的


441
00:21:11,905 --> 00:21:14,341 line:-2
随着到地面距离的增加
阴影逐渐变柔和


442
00:21:16,276 --> 00:21:17,811 line:-2
要使用光线追踪
创建这个灯柱阴影的模型


443
00:21:18,178 --> 00:21:20,681 line:-1
我们不采用我刚才展示过的平行光线


444
00:21:21,081 --> 00:21:23,483 line:0
而是延伸椎体


445
00:21:23,750 --> 00:21:24,885 line:0
从表面点一直延伸到太阳


446
00:21:26,420 --> 00:21:29,189 line:0
然后在这个椎体内随机生成一些
光线方向


447
00:21:31,291 --> 00:21:33,827 line:0
现在你可以看到一些光线交叉
形成几何图形


448
00:21:33,894 --> 00:21:34,995 line:0
而一些不交叉


449
00:21:35,262 --> 00:21:37,998 line:0
就是这个比率控制着阴影的柔和度


450
00:21:39,933 --> 00:21:41,201 line:-1
看起来就像是这样


451
00:21:43,237 --> 00:21:45,939 line:-2
我在这里所展示的是
原生直接光照的概念


452
00:21:46,473 --> 00:21:48,008 line:-1
通过每个像素一条光线来追踪光线


453
00:21:49,276 --> 00:21:53,780 line:-2
在这个图片中 所有其它效果
比如反射和全局照明


454
00:21:54,448 --> 00:21:56,917 line:-2
都被禁用了
因此我们可以只关注阴影


455
00:21:58,752 --> 00:22:01,388 line:-2
你可以看到结果是非常非常嘈杂的
一张图片


456
00:22:03,624 --> 00:22:06,360 line:-2
为了解决这个问题
我们可以发射越来越多的光线


457
00:22:07,160 --> 00:22:09,162 line:-1
因为这是我们要在实时app中


458
00:22:09,229 --> 00:22:10,597 line:-1
很想避免的事


459
00:22:11,298 --> 00:22:13,667 line:-1
我们可以使用降噪器来替换这种方式


460
00:22:13,734 --> 00:22:15,269 line:-1
Sean之前给我们介绍过降噪器


461
00:22:16,870 --> 00:22:18,071 line:-1
这就是使用降噪器之后的效果


462
00:22:19,373 --> 00:22:20,807 line:-1
绝大多数噪声都被过滤掉了


463
00:22:21,141 --> 00:22:24,011 line:-2
我们可以获得看起来很不错的软阴影
每个像素只有一条光线


464
00:22:25,612 --> 00:22:28,582 line:-2
稍后我会在现场演示中为你实际演示
这个操作


465
00:22:32,019 --> 00:22:33,954 line:-1
现在让我们讲讲环境光遮蔽


466
00:22:35,923 --> 00:22:37,991 line:-1
从根本上说这是一个近似值


467
00:22:38,058 --> 00:22:40,360 line:-2
是关于有多少环境光可以到达
表面的近似值


468
00:22:41,295 --> 00:22:43,764 line:-2
正如你之前在我们的AR Quick Look
演示中所看到的那样


469
00:22:44,164 --> 00:22:47,167 line:-2
在环境中把物体放在地面上
是一个很不错的技巧


470
00:22:49,303 --> 00:22:51,305 line:-2
因此让我们使用光线追踪
把这个操作可视化


471
00:22:52,873 --> 00:22:54,775 line:-1
屏幕中间有一个表面点


472
00:22:55,609 --> 00:22:57,611 line:0
在右侧有一个蓝块


473
00:22:57,678 --> 00:22:59,413 line:0
它的作用是遮光板


474
00:23:00,681 --> 00:23:03,584 line:0
我们在表面点周围定义一个
假想的半球


475
00:23:04,284 --> 00:23:05,385 line:0
然后我们发射一些光线


476
00:23:07,421 --> 00:23:08,622 line:0
如果某条光线击中了某些东西


477
00:23:08,922 --> 00:23:11,859 line:0
我们就会发现那个物体阻挡了
环境光到达表面


478
00:23:14,728 --> 00:23:16,763 line:-1
正如我几分钟之前所提到的那样


479
00:23:16,830 --> 00:23:18,165 line:-1
在实时app中


480
00:23:18,232 --> 00:23:21,235 line:-2
我们真的很想避免把我们自己局限于
每个像素只有一条或两条光线


481
00:23:22,236 --> 00:23:24,605 line:-2
因此我们需要尽可能有效地使用
这些光线


482
00:23:26,707 --> 00:23:29,209 line:-1
其中一种方式就是重要性采样


483
00:23:29,843 --> 00:23:33,213 line:-1
这里的总体思路是以我们认为


484
00:23:33,280 --> 00:23:35,983 line:-2
最有利于最终图片效果的方向
发射光线


485
00:23:38,151 --> 00:23:39,453 line:-1
通过环境光遮蔽


486
00:23:39,520 --> 00:23:41,822 line:-1
最重要的光线就是距法线较近的光线


487
00:23:43,123 --> 00:23:46,093 line:-2
因此我们不像你在这里看到的那样
在半球均匀地发射光线


488
00:23:46,493 --> 00:23:47,961 line:-1
而是使用余弦采样


489
00:23:49,730 --> 00:23:52,165 line:-1
这在地平线周围分配了较少的光线


490
00:23:52,232 --> 00:23:53,867 line:-1
并在表面法线周围分配了较多的光线


491
00:23:54,368 --> 00:23:56,370 line:-2
这很棒
这正是我们所需要的光线分配


492
00:23:59,173 --> 00:24:01,074 line:-1
除角衰减之外


493
00:24:01,441 --> 00:24:03,777 line:-1
环境光遮蔽还有一个距离的概念


494
00:24:04,411 --> 00:24:07,281 line:-2
因此距离表面近的物体会遮挡
绝大部分光照


495
00:24:08,415 --> 00:24:10,284 line:-1
那里通常还存在一个脱落函数


496
00:24:10,350 --> 00:24:12,219 line:-1
与距离的平方成比例


497
00:24:14,221 --> 00:24:15,722 line:-1
现在有意思的是


498
00:24:15,989 --> 00:24:19,359 line:-2
我们可以把那个脱落函数直接放到
光线分配自身中


499
00:24:20,460 --> 00:24:23,330 line:-2
我们的实现方式是
发射不同长度的光线


500
00:24:25,465 --> 00:24:26,433 line:-1
你可以在这里看到


501
00:24:26,500 --> 00:24:28,902 line:-1
因为我告诉过你的那个


502
00:24:28,969 --> 00:24:29,970 line:-1
距离平方脱落函数


503
00:24:30,370 --> 00:24:32,372 line:-1
绝大多数光线都非常非常短


504
00:24:33,207 --> 00:24:34,575 line:-1
这对于性能来说很棒


505
00:24:34,875 --> 00:24:36,276 line:-1
短光线更易于


506
00:24:36,343 --> 00:24:38,545 line:-1
Metal在加速结构中进行追踪


507
00:24:42,216 --> 00:24:43,283 line:0
我已经提过几次了


508
00:24:43,350 --> 00:24:46,019 line:0
关于生成不同形状的光线


509
00:24:46,086 --> 00:24:47,554 line:0
以及不同的分配


510
00:24:47,855 --> 00:24:49,823 line:0
比如我们针对软阴影所使用的椎体


511
00:24:50,090 --> 00:24:52,459 line:0
以及我们针对环境光遮蔽
所使用的半球


512
00:24:54,561 --> 00:24:56,396 line:0
在实践中


513
00:24:56,463 --> 00:24:59,700 line:0
我们先在2D参数空间生成点


514
00:25:00,100 --> 00:25:03,504 line:0
然后我们通过你想使用的任何一种
光线分配来映射那个空间


515
00:25:05,606 --> 00:25:07,908 line:0
现在参数空间中的那些点的位置


516
00:25:08,175 --> 00:25:09,710 line:0
对图片品质有重大影响


517
00:25:11,311 --> 00:25:12,513 line:0
如果你随机选择点


518
00:25:12,846 --> 00:25:15,415 line:0
往往会出现采样点聚集在一起的区域


519
00:25:17,317 --> 00:25:20,654 line:-2
这就导致我们
发射方向基本相同的光线


520
00:25:20,721 --> 00:25:22,055 line:-1
而那些光线是多余的


521
00:25:24,558 --> 00:25:27,494 line:0
你还会得到完全没有采样点的区域


522
00:25:28,762 --> 00:25:30,330 line:0
这会影响图片品质


523
00:25:30,397 --> 00:25:32,499 line:0
因为我们这些区域中的场景欠采样


524
00:25:34,368 --> 00:25:36,537 line:0
生成采样点的一种更好的方式是


525
00:25:36,603 --> 00:25:39,072 line:0
使用一种叫做低差异序列的东西


526
00:25:40,040 --> 00:25:41,441 line:0
我正在屏幕上展示的这个


527
00:25:41,508 --> 00:25:43,177 line:0
是Halton 2 3序列


528
00:25:44,745 --> 00:25:47,347 line:0
你可以看到以这种方式生成的采样点


529
00:25:47,781 --> 00:25:50,651 line:0
更均匀地覆盖了这个空间


530
00:25:50,717 --> 00:25:52,486 line:0
并且我们可以通过放大和欠采样
来消除空隙


531
00:25:56,390 --> 00:25:59,326 line:0
这就是对单个像素
生成良好光线的方式


532
00:26:00,227 --> 00:26:02,863 line:-2
现在我们需要做的就是把这种方式
应用到屏幕上所有的像素点上


533
00:26:02,930 --> 00:26:04,264 line:-1
从而使所有像素点都生成良好的光线


534
00:26:06,099 --> 00:26:07,267 line:-1
我们的实现方式是


535
00:26:07,334 --> 00:26:10,170 line:-1
获取我刚刚所展示的


536
00:26:10,237 --> 00:26:11,305 line:-1
其中一个低差异采样点


537
00:26:11,939 --> 00:26:14,041 line:0
然后给每个像素应用
一个随机delta


538
00:26:16,610 --> 00:26:17,945 line:0
所产生的效果是


539
00:26:18,345 --> 00:26:21,582 line:0
每个像素仍以低差异序列运行


540
00:26:22,482 --> 00:26:24,451 line:0
但采样点的具体位置发生了偏移


541
00:26:24,518 --> 00:26:26,587 line:0
不是屏幕上相邻的像素


542
00:26:29,423 --> 00:26:31,925 line:0
还有几种不同的方式可以生成
这些deltas


543
00:26:32,659 --> 00:26:36,730 line:0
其中一种方式是采样一个完全是
随机数的RG纹理


544
00:26:38,699 --> 00:26:40,901 line:0
但我们之前看到过


545
00:26:40,968 --> 00:26:42,703 line:0
随机数并不是用于光线追踪的
好的选择


546
00:26:43,370 --> 00:26:46,473 line:0
对于环境光遮蔽来说


547
00:26:46,540 --> 00:26:47,608 line:0
有一个不错的替代方案 即蓝噪声


548
00:26:49,276 --> 00:26:50,611 line:0
你可以在右侧看到


549
00:26:50,777 --> 00:26:53,080 line:0
但蓝噪声纹理中的随机性


550
00:26:53,146 --> 00:26:56,783 line:0
它的分布更加均匀
这对于图片品质来说很棒


551
00:26:57,084 --> 00:27:00,254 line:0
特别是当我们局限于每个像素
只发射几条光线的情况下时


552
00:27:02,823 --> 00:27:04,525 line:0
让我们看一下这些


553
00:27:04,591 --> 00:27:07,227 line:0
对我们尝试要生成的
环境光遮蔽结果的影响


554
00:27:08,929 --> 00:27:10,130 line:0
我们要从这儿开始


555
00:27:11,031 --> 00:27:14,735 line:0
这是对全部像素使用半球采样
和随机deltas


556
00:27:17,204 --> 00:27:19,606 line:0
这是使用我讲过的椎体采样


557
00:27:19,673 --> 00:27:21,475 line:0
和蓝噪声所得到的结果


558
00:27:22,776 --> 00:27:24,645 line:0
我可以在这两张图片之间切换
这样你就能看到其中的区别


559
00:27:25,879 --> 00:27:29,283 line:0
现在这两张图片都是通过每个像素
仅发射两条光线而生成的


560
00:27:30,651 --> 00:27:33,954 line:0
但你可以看到根据我们选择使用
那些光线的方式


561
00:27:34,821 --> 00:27:36,990 line:0
噪声的数量很明显地有所下降


562
00:27:37,257 --> 00:27:40,260 line:-1
我们努力捕捉更多的表面细节


563
00:27:42,296 --> 00:27:43,864 line:-1
如果我们持续发射光线


564
00:27:44,631 --> 00:27:47,601 line:-2
最终这两种方法会产生
完全相同的结果


565
00:27:48,135 --> 00:27:51,038 line:-1
但使用重要性采样会让我们速度更快


566
00:27:53,941 --> 00:27:55,843 line:-1
那么这就是阴影和环境光遮蔽


567
00:27:56,677 --> 00:27:59,346 line:-1
对于这些效果 我们仅对光线


568
00:27:59,413 --> 00:28:02,115 line:-1
是否击中或是否错过某些东西感兴趣


569
00:28:04,017 --> 00:28:07,421 line:-2
对于我们通常与光线追踪相关联的
许多其它效果来说


570
00:28:07,487 --> 00:28:08,989 line:-1
比如全局照明


571
00:28:09,590 --> 00:28:11,959 line:-2
你需要随着光线在场景中的反弹
而创建光线模型


572
00:28:12,860 --> 00:28:15,329 line:-2
为了让你们了解更多相关信息
我要邀请我同事Matt上台来


573
00:28:17,898 --> 00:28:19,233 line:-1
（全局照明）


574
00:28:23,837 --> 00:28:24,805 line:-1
谢谢Wayne


575
00:28:27,908 --> 00:28:30,010 line:-1
在这部分中 我们要讲几个话题


576
00:28:30,077 --> 00:28:32,212 line:-1
先简要概述一下全局照明


577
00:28:32,913 --> 00:28:35,716 line:-2
然后看一些关于内存和光线管理的
最佳实践


578
00:28:36,850 --> 00:28:39,119 line:-1
最后讲


579
00:28:39,186 --> 00:28:40,420 line:-1
调试光线追踪app的一些策略


580
00:28:42,055 --> 00:28:43,323 line:-1
那么什么是全局照明？


581
00:28:44,892 --> 00:28:46,193 line:-1
从概念上说非常简单


582
00:28:46,660 --> 00:28:49,863 line:-2
光进入场景并直接照亮
它所击中的表面


583
00:28:50,697 --> 00:28:51,732 line:-1
并光栅化


584
00:28:51,798 --> 00:28:53,333 line:-1
这一般是渲染过程的结束


585
00:28:53,867 --> 00:28:56,336 line:-2
但在现实世界中
那些物体会吸收一些光


586
00:28:56,670 --> 00:28:59,139 line:-1
然后光线会弹开并继续在场景中穿梭


587
00:28:59,740 --> 00:29:02,342 line:-2
随着光线四处反弹会浮现一些
很有趣的视觉效果


588
00:29:04,411 --> 00:29:05,846 line:-1
当光反弹一次之后


589
00:29:05,913 --> 00:29:08,515 line:-1
我们就会在镜像表面上看到镜面反射


590
00:29:08,582 --> 00:29:09,883 line:-1
就像右边的球和墙一样


591
00:29:11,852 --> 00:29:14,021 line:-1
你还可以看到随着物体和阴影获取


592
00:29:14,087 --> 00:29:16,557 line:-2
由附近表面所反射的光
它们变得更明亮了


593
00:29:18,525 --> 00:29:19,760 line:-1
在光反弹两次之后


594
00:29:19,826 --> 00:29:22,162 line:-1
我们会在镜像表面之间看到反射


595
00:29:23,096 --> 00:29:26,366 line:-1
最终一些光线一直折射穿过透明物体


596
00:29:26,934 --> 00:29:28,502 line:-1
它们显示除了它们背后的表面


597
00:29:28,569 --> 00:29:30,037 line:-1
为我们提供了盒子的玻璃效果


598
00:29:31,705 --> 00:29:34,107 line:-2
如果我们尝试给场景周围所有的
光反弹都创建模型


599
00:29:34,675 --> 00:29:37,611 line:-1
只有一小部分光能反弹回摄像头


600
00:29:37,678 --> 00:29:39,146 line:-1
那样效率很低


601
00:29:39,580 --> 00:29:43,183 line:-2
所以我们要从反方向进行处理
从摄像头到光源


602
00:29:44,785 --> 00:29:47,621 line:-2
我们从摄像头向图片中的像素
投射光线


603
00:29:49,957 --> 00:29:53,160 line:-2
那些光线的交叉点会告诉我们
哪些物体可见


604
00:29:53,627 --> 00:29:55,429 line:-2
但我们还需要计算有多少光到达了
那些物体


605
00:29:55,495 --> 00:29:58,065 line:-1
以便了解它们在最终图片中的颜色


606
00:29:59,099 --> 00:30:01,635 line:-2
之前Wayne
描述了如何计算软阴影


607
00:30:01,902 --> 00:30:04,505 line:-1
在这里我们要实施完全相同的过程


608
00:30:05,973 --> 00:30:08,242 line:-1
我们从交叉点


609
00:30:08,308 --> 00:30:09,409 line:-1
向场景中的光源投射阴影光线


610
00:30:09,476 --> 00:30:11,612 line:-1
从而估计有多少光到达了光源


611
00:30:12,646 --> 00:30:15,048 line:-1
这将用作最终图片的光照效果


612
00:30:17,918 --> 00:30:19,786 line:-1
接下来我们从交叉点


613
00:30:19,853 --> 00:30:22,022 line:-1
向随机方向再次投射光线


614
00:30:23,190 --> 00:30:25,192 line:-2
我们使用Metal来了解那些光线
击中了什么


615
00:30:25,259 --> 00:30:27,594 line:-2
然后投射阴影光线以确定它们的
直接照明


616
00:30:27,794 --> 00:30:29,630 line:-2
然后使用直接光照给最终图片
添加光照


617
00:30:30,464 --> 00:30:31,698 line:-1
重复这个过程


618
00:30:31,765 --> 00:30:33,600 line:-1
我们可以模拟光在房间中的反弹


619
00:30:34,501 --> 00:30:36,703 line:-1
我们在去年的演讲中做了具体的描述


620
00:30:36,770 --> 00:30:39,606 line:-2
我推荐你参看去年的演讲获取如何
实施这个过程的具体信息


621
00:30:41,441 --> 00:30:43,343 line:-1
在这个过程中使用的管道看起来


622
00:30:43,410 --> 00:30:45,279 line:-2
与我们目前所见过的混合管道
稍微有点不一样


623
00:30:46,313 --> 00:30:48,749 line:-1
首先我们发射光线并使用Metal


624
00:30:48,815 --> 00:30:49,650 line:-1
找到它们在场景中的交叉点


625
00:30:52,019 --> 00:30:55,222 line:-2
然后我们编写一个着色器来处理
那些交叉测试的结果


626
00:30:55,589 --> 00:30:56,990 line:-1
从而了解我们击中了哪个表面


627
00:30:59,860 --> 00:31:02,596 line:0
然后我们生成阴影光线
从那些交叉点


628
00:31:02,663 --> 00:31:03,897 line:-1
向场景中的光源生成阴影光线


629
00:31:04,464 --> 00:31:06,333 line:0
我编写了一个着色器
用于了解哪些光线


630
00:31:06,400 --> 00:31:08,535 line:0
击中了光源 然后把它们的光添加到
最终图片中


631
00:31:10,137 --> 00:31:12,539 line:0
最后我们使用所击中的表面


632
00:31:12,606 --> 00:31:13,640 line:0
作为下一组光线的发起点


633
00:31:14,341 --> 00:31:16,043 line:0
我们一次又一次地重复这个过程


634
00:31:16,109 --> 00:31:18,045 line:0
直到我们创建了我们想要创建的
大量光线反弹模型


635
00:31:20,380 --> 00:31:21,949 line:-1
这就是全局照明的运作方式


636
00:31:23,483 --> 00:31:25,519 line:-1
现在我们要讨论


637
00:31:25,586 --> 00:31:27,688 line:-1
为这个模型提供内存的一些最佳实践


638
00:31:29,723 --> 00:31:31,325 line:-1
因为任意光线都在场景中发生反弹


639
00:31:31,859 --> 00:31:33,994 line:-1
光线的状态随着


640
00:31:34,061 --> 00:31:35,229 line:-1
光与它所击中的物体的交互而改变


641
00:31:36,129 --> 00:31:37,965 line:-1
比如 如果光线击中了一种红色材料


642
00:31:38,398 --> 00:31:41,335 line:-2
那个红色表面会吸收除红光以外的
所有光


643
00:31:41,935 --> 00:31:44,304 line:-1
因此从那个表面上反射的二级光


644
00:31:44,371 --> 00:31:45,772 line:-1
将只包含红光


645
00:31:46,773 --> 00:31:48,375 line:-1
因此我们要持续追踪那个信息


646
00:31:48,442 --> 00:31:50,544 line:-1
以便把它传给管道的下一次迭代


647
00:31:51,378 --> 00:31:53,280 line:-1
那意味着我们得分配一些资源


648
00:31:53,347 --> 00:31:55,315 line:-1
用于持续追踪光线和场景属性


649
00:31:56,617 --> 00:31:59,319 line:-1
在右侧我列出了


650
00:31:59,386 --> 00:32:00,487 line:-2
你可能想要追踪的
场景属性的一些例子


651
00:32:03,156 --> 00:32:04,758 line:-1
要重定位所有这些新缓冲区


652
00:32:05,225 --> 00:32:06,660 line:-1
我们将占用大量内存


653
00:32:07,494 --> 00:32:10,664 line:-2
对于一张4K图片来说
仅光线缓冲区就有250MB


654
00:32:11,465 --> 00:32:13,867 line:-2
在我们的一个演示中
每条光线几乎占用了80字节


655
00:32:14,601 --> 00:32:17,538 line:-2
这种方式可以迅速超出可用的
GPU内存量


656
00:32:19,773 --> 00:32:21,842 line:-1
其中一种解决方案就是把光线分批


657
00:32:21,909 --> 00:32:23,177 line:-1
放到较小的群组或平铺中


658
00:32:23,944 --> 00:32:26,713 line:-1
通过限制你同时发射的光线的数量


659
00:32:26,780 --> 00:32:29,383 line:-1
你可以极大地减少资源的内存占用


660
00:32:31,485 --> 00:32:33,420 line:-1
因为这些缓冲区中的数据


661
00:32:33,487 --> 00:32:35,189 line:-1
将在管道迭代之间传递


662
00:32:36,390 --> 00:32:38,725 line:-2
把那个数据存在外面
然后再读取进来 在下一次迭代时


663
00:32:38,792 --> 00:32:40,260 line:-1
这将成为主要的受限因素


664
00:32:41,395 --> 00:32:43,630 line:-2
对于4K图片来说
我们大约要产生800万条光线


665
00:32:44,331 --> 00:32:45,532 line:-1
对于这个数字


666
00:32:45,599 --> 00:32:48,402 line:-1
每次迭代要读写大约5GB的数据


667
00:32:50,370 --> 00:32:52,339 line:-1
每个带宽问题都没有任何解决方案


668
00:32:52,406 --> 00:32:54,741 line:-2
但我们可以给你提供一些
我们觉得很好的最佳实践


669
00:32:55,742 --> 00:32:57,845 line:-1
第一 不要随机索引到数据缓冲区中


670
00:32:59,012 --> 00:33:02,015 line:-1
如果你按线程ID索引可能效率更高


671
00:33:02,082 --> 00:33:04,685 line:-1
从而编译器可以合并全部加载和存储


672
00:33:05,285 --> 00:33:06,854 line:-1
因为线程要访问的内存


673
00:33:06,920 --> 00:33:08,555 line:-1
位于相邻的缓冲区中


674
00:33:09,823 --> 00:33:11,959 line:-1
这真的会改善你的缓存一致性


675
00:33:13,260 --> 00:33:15,796 line:-2
下一个
对于不需要完全精确度的变量


676
00:33:16,463 --> 00:33:18,498 line:-1
尽可能使用较小的数据类型


677
00:33:19,433 --> 00:33:22,035 line:-2
如果可以的话
对于光线和场景以及材料属性


678
00:33:22,102 --> 00:33:23,170 line:-2
请试着用half替代
float数据类型


679
00:33:24,905 --> 00:33:27,040 line:-1
最后如果可能的话 请分离结构


680
00:33:27,107 --> 00:33:29,343 line:-1
以避免加载或存储你不会用到的数据


681
00:33:30,177 --> 00:33:33,113 line:-1
比如我们有一个结构包含材料属性


682
00:33:33,780 --> 00:33:36,884 line:-2
我们通过去除透明度变量得到了
很好的性能提升


683
00:33:37,150 --> 00:33:39,453 line:-2
因为并不是每条光线都会击中
透明的表面


684
00:33:39,520 --> 00:33:41,588 line:-2
我们不希望那些没有击中
透明表面的光线


685
00:33:41,655 --> 00:33:42,856 line:-1
为了读写透明度数据而付出代价


686
00:33:43,657 --> 00:33:45,893 line:-1
我们稍后会在GPU调试部分


687
00:33:45,959 --> 00:33:47,127 line:-1
看到一个更具体的例子


688
00:33:50,297 --> 00:33:51,565 line:-1
分配自己的缓冲区


689
00:33:51,632 --> 00:33:53,834 line:-1
存储起点和方向数据可能有违常规


690
00:33:53,901 --> 00:33:56,069 line:-1
但这样更有效率


691
00:33:56,403 --> 00:33:58,438 line:-2
而不是重复使用
Metal光线缓冲区结构


692
00:33:59,873 --> 00:34:01,475 line:-1
这是因为Metal光线缓冲区


693
00:34:01,542 --> 00:34:04,778 line:-1
可能包含你不希望对可能获取光线的


694
00:34:05,145 --> 00:34:06,747 line:-1
每一个着色器加载和存储的额外数据


695
00:34:09,949 --> 00:34:11,351 line:-1
为了最大化GPU的使用


696
00:34:12,085 --> 00:34:13,920 line:-1
你需要注意着色器占用


697
00:34:14,621 --> 00:34:16,123 line:-1
占用是一个很大的话题


698
00:34:16,190 --> 00:34:17,724 line:-1
我们不会在这里深入地介绍


699
00:34:18,292 --> 00:34:20,092 line:-1
但如果你存在占用问题


700
00:34:20,159 --> 00:34:22,829 line:-1
最简单的改善方式就是减少注册压力


701
00:34:24,331 --> 00:34:27,201 line:-1
请注意着色器中


702
00:34:27,266 --> 00:34:28,368 line:-1
同时活跃的变量数量


703
00:34:28,869 --> 00:34:31,138 line:-1
请注意循环计数器、函数调用


704
00:34:31,972 --> 00:34:34,107 line:-2
如果可以避免
请不要紧抓住完整结构不放


705
00:34:37,244 --> 00:34:39,179 line:0
当我们处理光线交叉点时


706
00:34:39,679 --> 00:34:41,447 line:0
我们需要评估


707
00:34:41,514 --> 00:34:42,850 line:0
光线所击中的任何物体的表面属性


708
00:34:43,750 --> 00:34:46,587 line:0
图形app一般会在纹理中


709
00:34:46,652 --> 00:34:47,621 line:0
保存大量材料属性


710
00:34:48,522 --> 00:34:51,824 line:0
这里的问题在于
因为着色器可能需要访问


711
00:34:51,891 --> 00:34:53,092 line:0
物体所引用的任意纹理


712
00:34:53,627 --> 00:34:57,197 line:0
我们不能提前了解光线会击中
哪个物体


713
00:34:57,631 --> 00:34:59,733 line:0
潜在地 我们可能需要访问每一个


714
00:35:00,033 --> 00:35:01,368 line:0
场景中的每一个纹理


715
00:35:02,102 --> 00:35:03,470 line:0
这样很快就会脱离我们的掌控


716
00:35:04,271 --> 00:35:07,808 line:0
如常用Sponza Atrium
场景有76个纹理


717
00:35:08,308 --> 00:35:10,611 line:0
比可用的捆绑插槽的数量多两倍还多


718
00:35:11,512 --> 00:35:13,714 line:-2
因此我们很快就会用完全部的
捆绑位置


719
00:35:16,683 --> 00:35:19,286 line:-2
其中一种解决方式是使用
Metal参数缓冲区


720
00:35:19,987 --> 00:35:22,489 line:-1
Metal参数缓冲区代表一组资源


721
00:35:22,556 --> 00:35:25,325 line:-2
可以作为单个参数被集体分配到
着色器中


722
00:35:26,527 --> 00:35:28,929 line:-2
我们在两年前的WWDC做了一个
相关演讲


723
00:35:29,730 --> 00:35:32,132 line:-2
我推荐你参考那个演讲获取
更具体的信息


724
00:35:33,600 --> 00:35:35,469 line:-1
假设每个基元有一个纹理


725
00:35:35,936 --> 00:35:39,006 line:-2
参数缓冲区将是
包含对纹理的引用的一个结构


726
00:35:40,440 --> 00:35:42,676 line:-2
在这里我们创建了一个结构
叫做材料


727
00:35:42,743 --> 00:35:44,077 line:-1
它包含一个纹理引用


728
00:35:44,144 --> 00:35:46,079 line:-1
和我们想要访问的其它信息


729
00:35:47,648 --> 00:35:49,917 line:-2
接下来我们把参数缓冲区绑定到
计算内核


730
00:35:50,651 --> 00:35:52,653 line:-1
它将显示为材料结构的一个数组


731
00:35:54,521 --> 00:35:57,724 line:-2
我们从交叉缓冲区中读取它
从而了解光线击中了哪个基元


732
00:35:59,092 --> 00:36:01,862 line:-2
然后我们就使用那个索引
把基元索引到参数缓冲区中


733
00:36:02,729 --> 00:36:05,532 line:-2
这可以让我们访问
每个基元的唯一纹理


734
00:36:08,702 --> 00:36:09,937 line:-2
这就是我们今天要讲的
与内存相关的内容


735
00:36:11,238 --> 00:36:13,307 line:-1
现在我们要讨论管理光线的生命周期


736
00:36:15,108 --> 00:36:16,443 line:-1
随着光线在场景中的反弹


737
00:36:16,844 --> 00:36:19,513 line:-2
光线可能由于各种原因
不再影响最终的图片品质


738
00:36:20,581 --> 00:36:22,115 line:-1
第一 它可能完全离开了场景


739
00:36:22,783 --> 00:36:23,784 line:-1
与现实世界不同


740
00:36:23,851 --> 00:36:25,719 line:-1
你的场景占用的空间有限


741
00:36:26,086 --> 00:36:28,856 line:-2
如果光线退出了
就没办法再把它找回来了


742
00:36:30,123 --> 00:36:32,659 line:-2
如果发生那种情况
我们一般会估计一个环境贴图


743
00:36:32,726 --> 00:36:34,027 line:-1
来获取背景颜色


744
00:36:34,094 --> 00:36:35,362 line:-2
但那个光线实际上
已经从场景中消失了


745
00:36:36,897 --> 00:36:38,365 line:-1
第二 随着光线的反弹


746
00:36:39,166 --> 00:36:42,436 line:-2
它所携带的光
会被它与之相交互的表面衰减


747
00:36:43,470 --> 00:36:46,974 line:-2
如果光线丢失了足够多的光
它可能就不会


748
00:36:47,040 --> 00:36:48,041 line:-2
再对最终图片的品质产生
可衡量的影响了


749
00:36:49,176 --> 00:36:50,844 line:-1
最后对于透明表面


750
00:36:50,911 --> 00:36:53,480 line:-1
有一些光可能会被困在某些位置上


751
00:36:53,547 --> 00:36:55,315 line:-1
这样它们就永远都不能返回到摄像头


752
00:36:57,618 --> 00:36:59,253 line:-1
光线变得不活跃的速度有多快？


753
00:37:00,120 --> 00:37:02,589 line:-1
取决于场景类型 速度可能非常快


754
00:37:03,824 --> 00:37:05,726 line:-1
比如这个场景有个开放的世界


755
00:37:05,792 --> 00:37:08,428 line:-2
大量光线很快就会因为击中环境贴图
而迅速退出


756
00:37:09,396 --> 00:37:11,465 line:-1
在右侧我们展示的是


757
00:37:11,532 --> 00:37:13,066 line:-1
完全活跃的光线缓冲区


758
00:37:13,433 --> 00:37:15,936 line:-2
随着它在管道的第一次迭代中的
退出的一个简化表示


759
00:37:16,837 --> 00:37:19,640 line:-2
我们就是在这个步骤中从摄像头
向场景中投射光线


760
00:37:22,109 --> 00:37:24,711 line:-2
其中一些光线会击中环境贴图
并变得不活跃


761
00:37:25,279 --> 00:37:27,281 line:-2
在这里我们把不活跃的光线
表示为黄色


762
00:37:27,347 --> 00:37:29,016 line:-1
我们已经把它们从光线缓冲区中移除


763
00:37:29,983 --> 00:37:32,986 line:-2
在第一次迭代之后
只有57%的光线仍然活跃


764
00:37:35,055 --> 00:37:36,657 line:-1
我们让光线继续穿梭


765
00:37:36,723 --> 00:37:38,458 line:-1
最初击中地面的一些光线


766
00:37:38,725 --> 00:37:40,194 line:-1
发生反弹并击中环境贴图


767
00:37:40,661 --> 00:37:43,063 line:-1
现在余下的活跃光线降到了43%


768
00:37:45,365 --> 00:37:48,268 line:-1
其中有些光线一直穿过了透明物体


769
00:37:48,335 --> 00:37:49,536 line:-1
并最终退出了场景


770
00:37:50,037 --> 00:37:51,839 line:-1
我们的活跃光线只剩下三分之一了


771
00:37:53,073 --> 00:37:55,576 line:-2
当然了 我们迭代的次数越多
变得不活跃的光线越多


772
00:37:57,544 --> 00:37:59,980 line:-2
在这个例子中
我们知道光线缓冲区中的大量光线


773
00:38:00,047 --> 00:38:02,115 line:-1
都将变得不活跃 我们用于处理


774
00:38:02,182 --> 00:38:03,116 line:-1
这些不活跃的光线的时间是一种浪费


775
00:38:03,851 --> 00:38:05,419 line:-1
但因为我们不能提前了解到


776
00:38:05,485 --> 00:38:06,854 line:-1
哪些光线会变得不活跃


777
00:38:07,321 --> 00:38:08,522 line:-2
处理这个结果的
Metal Ray Intersector


778
00:38:08,889 --> 00:38:10,991 line:-1
以及全部着色器


779
00:38:11,058 --> 00:38:13,093 line:-1
仍要在全部光线上运行


780
00:38:13,694 --> 00:38:15,629 line:-1
那意味着我们得分配线程组内存


781
00:38:15,696 --> 00:38:17,364 line:-1
编译器可能会预取数据


782
00:38:17,431 --> 00:38:21,134 line:-2
我们可能要添加控制流语句
剔除不活跃的光线


783
00:38:22,169 --> 00:38:24,071 line:-1
我们的占用保持不变


784
00:38:24,605 --> 00:38:27,074 line:-1
但线程组的利用率却很低


785
00:38:27,674 --> 00:38:29,676 line:-1
我们浪费了所有的处理器容量


786
00:38:32,379 --> 00:38:34,615 line:-1
我们的解决方案是压缩光线缓冲区


787
00:38:36,049 --> 00:38:39,653 line:-2
对于每次迭代 我们仅向下一个
迭代的光线缓冲区中添加活跃光线


788
00:38:40,554 --> 00:38:41,688 line:-1
这增加了一些消耗


789
00:38:41,755 --> 00:38:44,625 line:-1
但却会提高缓存线和线程组的利用率


790
00:38:45,192 --> 00:38:48,028 line:-2
因此处理浪费少了
所需的带宽也少了


791
00:38:49,296 --> 00:38:52,132 line:-2
还有一个重点要注意
这个方案对于阴影光线也同样适用


792
00:38:52,900 --> 00:38:55,235 line:-1
有些光线会击中背光的表面


793
00:38:55,569 --> 00:38:56,637 line:-1
或可能会击中背景


794
00:38:56,703 --> 00:38:58,405 line:-2
因此我们不想缓存
这些光线的阴影光线


795
00:39:00,741 --> 00:39:03,143 line:-1
这个方法的缺点是


796
00:39:03,210 --> 00:39:04,311 line:-2
因为我们在光线缓冲区内
调整光线位置


797
00:39:04,778 --> 00:39:08,749 line:-2
我们的光线缓冲区中的索引
不再映射到恒定的像素位置上


798
00:39:09,483 --> 00:39:11,985 line:-1
因此我们需要分配一个缓冲区


799
00:39:12,052 --> 00:39:13,086 line:-1
用于沿着每条光线追踪像素坐标


800
00:39:14,321 --> 00:39:16,056 line:-1
虽然我们使用了额外缓冲区


801
00:39:16,123 --> 00:39:17,991 line:-1
但我们实际上所使用的内存变少了


802
00:39:18,058 --> 00:39:20,527 line:-2
如果我们把所有不需要处理的光线
都考虑进去的话


803
00:39:22,696 --> 00:39:23,964 line:-1
当我们压缩光线时


804
00:39:24,364 --> 00:39:27,501 line:-2
我们不希望两个着色器
都尝试向新光线缓冲区中的


805
00:39:27,568 --> 00:39:28,669 line:-1
同一个位置添加光线


806
00:39:29,336 --> 00:39:31,438 line:-1
因此我们需要在光线缓冲区中


807
00:39:31,505 --> 00:39:34,875 line:-2
为每一条在迭代之间保持活跃的光线
生产一个唯一索引


808
00:39:36,076 --> 00:39:37,644 line:-1
我们使用原子计数器来实现


809
00:39:38,545 --> 00:39:40,914 line:-2
在这里原子整数
outgoingRayCount


810
00:39:40,981 --> 00:39:43,717 line:-2
在新光线缓冲区中包含光线的
当前数量


811
00:39:45,419 --> 00:39:48,689 line:-2
我们使用atomic_fetch_add
明确地获取


812
00:39:48,755 --> 00:39:50,858 line:-1
流出光线的当前值并增加一


813
00:39:52,693 --> 00:39:55,395 line:-2
我们把这个值用作
对流出光线缓冲区的索引


814
00:39:55,462 --> 00:39:56,997 line:-1
以确保不会发生冲突


815
00:39:57,598 --> 00:39:59,867 line:-1
它还有一个额外的好处


816
00:39:59,933 --> 00:40:01,935 line:-2
即在流出光线计数中保留
仍然活跃的光线的数量


817
00:40:04,104 --> 00:40:06,607 line:-1
如果你不能限制你所启动的线程数


818
00:40:06,673 --> 00:40:07,975 line:-1
光线压缩也不会提供太多的帮助


819
00:40:08,242 --> 00:40:10,177 line:-1
我们刚生产的流出光线计数缓冲区


820
00:40:10,244 --> 00:40:13,680 line:-2
包含流出光线缓冲区中的
活跃光线的总数


821
00:40:14,915 --> 00:40:17,618 line:-2
我们可以用这个数来填充
MTLDispatch ThreadGroups


822
00:40:17,684 --> 00:40:18,952 line:-1
IndirectArguments对象


823
00:40:20,020 --> 00:40:23,023 line:-2
那正好指明了
即将用于分派的启动维度


824
00:40:24,191 --> 00:40:27,060 line:-2
然后通过对indirectBuffer对象
使用IndirectDispatch


825
00:40:27,528 --> 00:40:29,496 line:-2
我们可以限制
我们要启动的线程的数量


826
00:40:29,563 --> 00:40:31,698 line:-1
使线程仅处理保持活跃的光线


827
00:40:33,500 --> 00:40:35,335 line:0
还有一个与此相对应的


828
00:40:35,402 --> 00:40:36,503 line:0
光线交叉函数


829
00:40:38,272 --> 00:40:41,375 line:0
这里的重点是我们可以通过缓冲区
传递光线计数


830
00:40:41,708 --> 00:40:43,911 line:0
从而我们可以把结果填充到
光线压缩步骤中


831
00:40:43,977 --> 00:40:45,879 line:0
作为要启动的线程的数量


832
00:40:47,915 --> 00:40:49,082 line:-1
在压缩光线之后


833
00:40:49,516 --> 00:40:52,152 line:-2
在这个场景中我们获得了大约
15%的性能提升


834
00:40:52,686 --> 00:40:55,856 line:-1
但当然了 这个结果取决于


835
00:40:55,923 --> 00:40:57,925 line:-2
你所使用的场景的复杂程度
以及光线反弹的次数


836
00:41:00,727 --> 00:41:02,396 line:-2
那么这就是光线的生命周期
和光线的剔除


837
00:41:04,331 --> 00:41:07,167 line:-2
现在我们要讲使用Xcode
调试app


838
00:41:09,469 --> 00:41:12,072 line:-1
众所周知 在GPU上调试非常困难


839
00:41:12,840 --> 00:41:14,675 line:-1
特别是对于光线追踪来说尤其困难


840
00:41:15,409 --> 00:41:17,945 line:-2
每条光线可能会多次调用
你所做的任何修改


841
00:41:18,545 --> 00:41:21,348 line:-1
并且你可能需要在算法的不同阶段


842
00:41:21,648 --> 00:41:23,584 line:-1
编写大量代码来卸载缓冲区和纹理


843
00:41:23,851 --> 00:41:25,853 line:-1
从而了解哪里产生了报错


844
00:41:26,753 --> 00:41:29,723 line:-1
Xcode的帧捕捉工具


845
00:41:29,790 --> 00:41:31,158 line:-1
对于调试这些问题来说非常好用


846
00:41:31,959 --> 00:41:33,827 line:-2
它是个很强大的工具
并且可以节约很多时间


847
00:41:35,329 --> 00:41:37,865 line:-2
因此我要和你们一起调试
我们遇到的一个实际问题


848
00:41:37,931 --> 00:41:40,968 line:-2
当我们在光线追踪器中实施
超级采样时遇到了这个问题


849
00:41:42,202 --> 00:41:45,539 line:-2
我们对每帧都实施了对单个像素
多次采样的功能


850
00:41:45,939 --> 00:41:48,642 line:-2
然后突然 我们的光线追踪器开始
生产放大图片


851
00:41:50,744 --> 00:41:54,414 line:-1
第一步是在app运行时执行帧捕捉


852
00:41:55,782 --> 00:41:58,552 line:-2
这会记录在一帧的过程中
每个API调用


853
00:41:58,619 --> 00:42:00,053 line:-1
和着色器的GPU状态


854
00:42:01,688 --> 00:42:02,856 line:-1
通过选择任意着色器


855
00:42:02,923 --> 00:42:04,892 line:-1
我们可以检验绑定到它的资源


856
00:42:05,659 --> 00:42:08,462 line:-2
从而我们可以非常快速地减少
着色器漏掉的资源


857
00:42:08,862 --> 00:42:11,431 line:-2
通过选择写入帧缓冲区的
所有着色器来实现


858
00:42:11,498 --> 00:42:13,467 line:-1
并可以直接检验帧缓冲区的内容


859
00:42:14,434 --> 00:42:16,303 line:-1
在这里我们可以看到第一张图片很亮


860
00:42:17,070 --> 00:42:18,572 line:-1
第二张照片褪色很严重


861
00:42:18,639 --> 00:42:19,806 line:-1
第三张照片几乎是白色的


862
00:42:22,509 --> 00:42:25,078 line:-2
但在这里我们要选择输出
最亮的图片的着色器


863
00:42:25,612 --> 00:42:27,848 line:-1
并查看用于计算


864
00:42:27,915 --> 00:42:29,716 line:-1
帧缓冲区的两个输入缓冲区


865
00:42:30,617 --> 00:42:34,621 line:-2
第一个缓冲区仅包含
一条光线所积聚的光的总量


866
00:42:37,191 --> 00:42:38,926 line:-1
第二个缓冲区包含我们的新变量


867
00:42:39,526 --> 00:42:41,895 line:-1
也就是我们对指定像素的采样次数


868
00:42:42,930 --> 00:42:45,032 line:-1
这两个缓冲区看起来都包含有效数据


869
00:42:45,098 --> 00:42:46,767 line:-1
因此我们可以直接进入着色器调试器


870
00:42:46,834 --> 00:42:48,735 line:-2
来检验我们的着色器会如何处理
这个数据


871
00:42:50,737 --> 00:42:52,773 line:-1
我们的颜色计算只是


872
00:42:52,840 --> 00:42:54,942 line:-1
为指定像素发射的全部光线的亮度


873
00:42:56,109 --> 00:42:58,745 line:-2
当每个像素仅有一条光线时
这个计算没有任何问题


874
00:42:59,680 --> 00:43:01,148 line:-1
但现在我们无法补偿这一事实


875
00:43:01,215 --> 00:43:03,584 line:-1
即我们需要对每个像素进行多次采样


876
00:43:04,718 --> 00:43:06,720 line:-2
因此我们要在着色器调试器中
修改相应的代码


877
00:43:06,787 --> 00:43:09,656 line:-1
将总亮度除以输入样本数


878
00:43:10,724 --> 00:43:12,826 line:-2
我们直接在着色器调试器中进行
重新评估


879
00:43:13,427 --> 00:43:16,129 line:-2
我们可以立即看到我们的输出图像
已经被修正了


880
00:43:16,663 --> 00:43:17,664 line:-1
就是那么简单


881
00:43:19,533 --> 00:43:20,467 line:-1
（用Xcode进行性能调整）


882
00:43:20,534 --> 00:43:21,702 line:-1
我们频繁遇到的另一个问题是


883
00:43:21,768 --> 00:43:24,238 line:-2
我们尝试了解我们所做的修改
对性能产生的影响


884
00:43:25,005 --> 00:43:27,774 line:-2
Xcode帧捕捉工具
也把这个问题变简单了


885
00:43:29,209 --> 00:43:31,745 line:-1
这是一个在光线反弹时


886
00:43:31,812 --> 00:43:32,980 line:-1
追踪表面特征的结构的示例


887
00:43:33,881 --> 00:43:36,149 line:-2
在我们的场景中
并不是每个表面都使用透明表面


888
00:43:36,216 --> 00:43:39,186 line:-1
最终的两个值 透射和折射率


889
00:43:39,486 --> 00:43:40,854 line:-1
对于某些光线来说没有用


890
00:43:41,622 --> 00:43:44,458 line:-2
但因为我们把那种数据
整个打包到了单个结构中


891
00:43:45,025 --> 00:43:47,027 line:-1
没有击中透明表面的光线


892
00:43:47,094 --> 00:43:48,795 line:-1
仍需要在迭代中


893
00:43:49,062 --> 00:43:51,465 line:-1
读写那些字段


894
00:43:53,934 --> 00:43:56,870 line:-1
在这里我们把折射变量


895
00:43:56,937 --> 00:43:58,038 line:-1
重构到它们自己的结构中


896
00:43:58,605 --> 00:44:01,575 line:-1
仅在结构中保留击中透明表面的光线


897
00:44:01,642 --> 00:44:03,310 line:-1
这必须存在折射率数据


898
00:44:06,813 --> 00:44:07,915 line:-1
但我们仍可以做得更好


899
00:44:08,649 --> 00:44:11,185 line:-2
现在我们把变量的数据类型
修改为half


900
00:44:11,251 --> 00:44:12,252 line:-1
从而节约更多的空间


901
00:44:13,120 --> 00:44:15,589 line:-2
我们已经把内存占用从40字节
减少到了20字节


902
00:44:15,923 --> 00:44:18,625 line:-2
没有击中透明物体的光线
只需要12字节


903
00:44:20,694 --> 00:44:22,663 line:-2
我们该如何了解对性能所产生的
这种影响呢？


904
00:44:23,430 --> 00:44:26,567 line:-1
在这里我们使用帧捕捉工具


905
00:44:26,633 --> 00:44:28,302 line:-1
分别在修改前后抓取GPU追踪


906
00:44:29,703 --> 00:44:31,872 line:-1
我们可以做的最基本的性能分析


907
00:44:31,939 --> 00:44:33,106 line:-1
就发生在这个阶段


908
00:44:34,074 --> 00:44:35,442 line:-1
通过比较


909
00:44:35,876 --> 00:44:37,578 line:-1
修改前后的着色器计时


910
00:44:37,978 --> 00:44:40,013 line:-1
我们可以隔离性能发生变化的着色器


911
00:44:40,848 --> 00:44:42,583 line:-2
在这里我们可以看到
我们所标记为采样表面的着色器


912
00:44:42,649 --> 00:44:46,620 line:-1
计时从5.5毫秒降低到了4毫秒


913
00:44:47,421 --> 00:44:50,457 line:-2
这对于其中消耗较大的着色器来说
几乎节约了30%


914
00:44:52,259 --> 00:44:55,195 line:-1
如果我们想量化具体为何提升了性能


915
00:44:55,696 --> 00:44:58,498 line:-2
当Xcode执行帧捕捉时
它可以为我们提供


916
00:44:58,565 --> 00:45:00,267 line:-1
它所插入的所有性能计数器的结果


917
00:45:01,134 --> 00:45:03,637 line:-2
因为我们有兴趣了解我们如何影响
内存占用


918
00:45:04,438 --> 00:45:06,707 line:-1
我们可以看一下纹理单位统计


919
00:45:07,107 --> 00:45:10,043 line:-2
我们可以看到我们的纹理单位
平均暂停时间


920
00:45:10,110 --> 00:45:11,845 line:-1
已经从70%降到了54%


921
00:45:12,479 --> 00:45:15,282 line:-2
并且我们已经把L2吞吐量减少了
几乎三分之二


922
00:45:17,518 --> 00:45:20,120 line:-2
更有帮助的是Xcode
将自己做一些分析


923
00:45:20,187 --> 00:45:21,688 line:-1
并把潜在的问题报告给你


924
00:45:22,623 --> 00:45:24,491 line:-1
在这里它告诉我们说我们的初始版本


925
00:45:24,558 --> 00:45:25,993 line:-1
存在很大的内存问题


926
00:45:26,260 --> 00:45:28,228 line:-1
而新版本的性能好多了


927
00:45:30,497 --> 00:45:31,965 line:-1
还有一个技巧你可能会用得上


928
00:45:32,399 --> 00:45:35,335 line:-2
就是计算管道状态也有一些
有意思的遥测


929
00:45:36,370 --> 00:45:38,071 line:-2
请看
MaxTotalThreadsForThreadgroup


930
00:45:38,705 --> 00:45:40,941 line:-1
这是着色器占用情况的指示


931
00:45:41,608 --> 00:45:43,310 line:-1
你应该以1024为最大目标


932
00:45:43,377 --> 00:45:46,313 line:-2
小于1024说明可能存在占用问题
你需要修复


933
00:45:49,016 --> 00:45:50,150 line:-1
那么这就是Xcode中的调试


934
00:45:50,717 --> 00:45:53,554 line:-1
这使在Mac平台上开发光线追踪


935
00:45:53,620 --> 00:45:55,289 line:-1
和全局照明算法变得异常简单


936
00:45:55,956 --> 00:45:58,325 line:-2
现在Wayne会为大家现场演示
我们今天所讲的内容


937
00:46:01,628 --> 00:46:02,696 line:-1
谢谢Matt


938
00:46:04,398 --> 00:46:06,166 line:-1
你可能认出这个场景来了


939
00:46:06,233 --> 00:46:09,703 line:-2
来自我们平台本周稍早些时候的
《极限特工》演讲


940
00:46:10,871 --> 00:46:11,738 line:-1
为了在这里对它进行渲染


941
00:46:11,805 --> 00:46:15,342 line:-2
我要使用MacBook Pro
和四个外部GPU


942
00:46:16,910 --> 00:46:20,547 line:-2
你在屏幕上看到的一切都是
实时的光线追踪


943
00:46:21,248 --> 00:46:24,117 line:-1
我可以拿着摄像头在场景中四处移动


944
00:46:26,353 --> 00:46:27,421 line:-1
让我们从这里开始吧


945
00:46:28,222 --> 00:46:30,824 line:-2
你可以看到我们通过光线追踪
所获得的非常棒的阴影


946
00:46:31,458 --> 00:46:34,461 line:-1
它们在接触点上是硬阴影


947
00:46:34,528 --> 00:46:36,496 line:-2
并随着到地面的距离增加而变得
越来越柔和


948
00:46:38,832 --> 00:46:42,135 line:-2
请记住 对于这些阴影
我们仅对每个像素发射了一条光线


949
00:46:42,469 --> 00:46:44,972 line:-2
然后我们使用了
刚才Sean所讲过的降噪器


950
00:46:45,305 --> 00:46:46,640 line:-2
才最终得到了这个
非常棒的滤过的效果


951
00:46:48,408 --> 00:46:50,010 line:-1
这些都是动态地计算的


952
00:46:50,077 --> 00:46:52,980 line:-1
我可以四处移动灯


953
00:46:54,114 --> 00:46:56,917 line:-1
我可以立即看到这种效果


954
00:46:59,453 --> 00:47:01,188 line:-1
这里也有一个很棒的效果


955
00:47:01,255 --> 00:47:04,191 line:-1
如果我们飞过去从电车窗户向里看


956
00:47:04,258 --> 00:47:06,560 line:-1
你实际上可以看到我们影子的反光


957
00:47:06,960 --> 00:47:10,264 line:-2
再一次 你可以看到
影子跟着灯的移动而移动


958
00:47:13,634 --> 00:47:16,069 line:-1
如果我们现在前往场景的这部分


959
00:47:16,136 --> 00:47:18,639 line:-1
这里也有一个很棒的反射效果


960
00:47:20,741 --> 00:47:22,242 line:-1
如果我们看最左侧的电车


961
00:47:23,043 --> 00:47:25,345 line:-1
你可以看到后面有电车的倒影


962
00:47:26,413 --> 00:47:30,217 line:-2
但你还可以在我们后面的
电车的挡风玻璃上看到反光


963
00:47:30,517 --> 00:47:33,120 line:-1
因此这里的反光内又有反光


964
00:47:33,854 --> 00:47:36,223 line:-2
我们需要对每个像素模拟几次
光线反弹


965
00:47:36,290 --> 00:47:37,491 line:-1
才能达到那种效果


966
00:47:40,360 --> 00:47:41,828 line:-1
我要稍微把这里缩小一些


967
00:47:42,496 --> 00:47:45,199 line:-2
当然了在这个场景中并不是只有
摄像头能移动


968
00:47:45,265 --> 00:47:46,733 line:-1
灯也可以移动


969
00:47:47,568 --> 00:47:50,804 line:-2
Sean之前讲过Metal的
二级加速结构


970
00:47:51,171 --> 00:47:54,141 line:-2
我们在这里使用二级加速结构
使电车在场景中移动


971
00:47:57,010 --> 00:47:58,512 line:-1
然而我现在想给你展示的是


972
00:47:58,579 --> 00:48:01,648 line:-2
我们在房顶上实现的这个极好的
照明效果


973
00:48:03,650 --> 00:48:06,019 line:-1
如果我们注意右侧的墙壁


974
00:48:06,653 --> 00:48:10,190 line:-2
你可以看到目前
它主要由直接的太阳光点亮


975
00:48:11,892 --> 00:48:14,995 line:-1
但随着我控制太阳的旋转


976
00:48:15,062 --> 00:48:17,064 line:-1
你可以看到墙壁陷入了阴影中


977
00:48:17,431 --> 00:48:21,201 line:-2
现在它由这个非常棒的
非直接照明来点亮


978
00:48:22,870 --> 00:48:23,770 line:-1
这里所发生的就是


979
00:48:24,071 --> 00:48:26,540 line:-1
太阳光击中了左侧的屋顶


980
00:48:27,074 --> 00:48:29,510 line:-1
它反弹并照亮了右侧的墙壁


981
00:48:29,576 --> 00:48:31,411 line:-2
从而为我们提供了这个非常棒的
渗色效果


982
00:48:33,714 --> 00:48:35,782 line:-1
如果我继续旋转太阳


983
00:48:35,849 --> 00:48:38,285 line:-2
你可以逐渐看到
这些非常引人注目的阴影


984
00:48:38,352 --> 00:48:40,487 line:-1
它们穿过了屋顶的表面


985
00:48:42,356 --> 00:48:43,790 line:-1
如果我稍微旋转一下摄像头


986
00:48:43,857 --> 00:48:46,693 line:-2
你实际上可以看到
反射同样也击中了左侧的屋顶


987
00:48:48,395 --> 00:48:49,830 line:-1
因此这是——我真的很喜欢这个拍摄


988
00:48:50,564 --> 00:48:53,500 line:-1
同时在这里还有许多光线追踪的效果


989
00:48:53,767 --> 00:48:55,435 line:-1
我们有非直接照明


990
00:48:55,502 --> 00:48:57,337 line:-1
我们有阴影 我们有反射


991
00:48:58,238 --> 00:49:01,909 line:-2
这些都由Metal和多GPU进行
实时的光线追踪


992
00:49:03,544 --> 00:49:04,945 line:-1
现在我们要回到我们的演讲


993
00:49:05,012 --> 00:49:08,215 line:-1
我要稍微讲一下多GPU


994
00:49:17,024 --> 00:49:18,659 line:-1
对于我们刚才看到的演示


995
00:49:19,560 --> 00:49:21,962 line:-1
我们实施多GPU的方式


996
00:49:22,029 --> 00:49:25,732 line:-1
是通过把屏幕分成几个小的平铺


997
00:49:26,567 --> 00:49:29,102 line:-2
然后把这些小平铺映射到
不同的GPU上


998
00:49:31,004 --> 00:49:33,740 line:-1
在这个可视化中 我使用不同的颜色


999
00:49:33,807 --> 00:49:35,642 line:-1
来演示这些平铺是如何分配的


1000
00:49:36,310 --> 00:49:38,545 line:-1
一个GPU渲染红色平铺


1001
00:49:39,346 --> 00:49:40,681 line:-1
另一个渲染黄色平铺


1002
00:49:41,014 --> 00:49:41,882 line:-1
以此类推


1003
00:49:43,050 --> 00:49:46,420 line:-2
在所有GPU完成之后
我们只需要把结果合成到一起


1004
00:49:46,486 --> 00:49:47,588 line:-1
从而构成我们的最终图片


1005
00:49:50,357 --> 00:49:51,625 line:-1
如果我们后退一步


1006
00:49:51,925 --> 00:49:53,193 line:-1
看看这里有什么


1007
00:49:53,260 --> 00:49:54,728 line:-1
有两样东西很显眼


1008
00:49:55,996 --> 00:49:58,232 line:-1
第一 在左侧的图片中


1009
00:49:58,599 --> 00:50:02,803 line:-2
我们给GPU分配平铺的方式
看起来有点奇怪


1010
00:50:03,337 --> 00:50:04,638 line:-1
我们为什么那样做呢？


1011
00:50:04,705 --> 00:50:06,707 line:-1
（交错平铺）


1012
00:50:06,773 --> 00:50:08,709 line:-1
第二 对于那些小平铺


1013
00:50:09,510 --> 00:50:12,913 line:-2
所隐含的是每个GPU将在那里
渲染一个像素块


1014
00:50:12,980 --> 00:50:15,682 line:-1
然后再在别处渲染一个像素块


1015
00:50:16,517 --> 00:50:18,318 line:-1
那感觉就像对光线一致性、


1016
00:50:18,652 --> 00:50:21,255 line:-1
缓存击中率这样的东西不利一样


1017
00:50:21,321 --> 00:50:22,322 line:-1
所有诸如此类的东西


1018
00:50:23,190 --> 00:50:24,491 line:-1
让我们依次来处理这些问题


1019
00:50:25,259 --> 00:50:27,327 line:-1
（负载平衡）


1020
00:50:27,394 --> 00:50:29,229 line:-1
假如我们有四个GPU


1021
00:50:30,230 --> 00:50:33,834 line:-1
执行多GPU的最简单的方式就是


1022
00:50:33,901 --> 00:50:34,968 line:-1
把屏幕分为四块


1023
00:50:36,703 --> 00:50:39,206 line:-1
现在问题是场景中的某些部分


1024
00:50:39,273 --> 00:50:41,275 line:-1
可能比其它部分更容易渲染


1025
00:50:42,442 --> 00:50:45,612 line:-1
如果我们假设左侧的街道和建筑物


1026
00:50:45,679 --> 00:50:48,282 line:-1
比右侧的电车要更容易渲染


1027
00:50:49,383 --> 00:50:51,785 line:-1
这就表明了为什么红色和黄色GPU


1028
00:50:51,852 --> 00:50:54,655 line:-1
会比绿色和紫色GPU早完成的原因


1029
00:50:56,456 --> 00:50:59,826 line:-2
我们可以通过把屏幕分成较小的平铺
来解决这个问题


1030
00:51:01,628 --> 00:51:03,897 line:-2
然后我们可以把每个小平铺再分成
更小的平铺


1031
00:51:04,531 --> 00:51:05,532 line:-1
以此类推


1032
00:51:05,599 --> 00:51:07,267 line:-1
直到我们达到某个最小的平铺尺寸


1033
00:51:09,369 --> 00:51:13,874 line:-2
这就产生了在GPU上
工作分配均匀的效果


1034
00:51:15,008 --> 00:51:18,212 line:-1
如果屏幕的某一部分特别难以渲染


1035
00:51:18,278 --> 00:51:19,613 line:-1
也没有关系


1036
00:51:19,680 --> 00:51:23,417 line:-2
因为将从那部分屏幕中给每个GPU
分配平铺


1037
00:51:25,953 --> 00:51:28,956 line:-2
在实践中你在这里看到的这个常规的
平铺模式


1038
00:51:29,389 --> 00:51:30,624 line:-1
很可能不适用


1039
00:51:31,225 --> 00:51:34,828 line:-2
因为你可能会遇到这种情况
平铺与场景中的几何图形对齐


1040
00:51:36,396 --> 00:51:37,598 line:-1
因此我们稍微随机化一点儿


1041
00:51:38,198 --> 00:51:41,134 line:-2
我马上会与大家分享一些
具体的实现细节


1042
00:51:41,635 --> 00:51:42,970 line:-1
（负载平衡）


1043
00:51:43,971 --> 00:51:46,540 line:-2
关于这个方法
其中一件最有意思的事情是


1044
00:51:46,807 --> 00:51:49,376 line:-1
平铺到GPU的映射


1045
00:51:49,443 --> 00:51:50,611 line:-1
并没有发生改变


1046
00:51:51,979 --> 00:51:55,582 line:-2
同一个GPU将处理每帧中
同样的平铺


1047
00:51:56,850 --> 00:51:57,718 line:-1
这很棒


1048
00:51:58,118 --> 00:52:01,622 line:-1
你只需要在app初始化时


1049
00:52:01,688 --> 00:52:04,157 line:-2
或你重新调整窗口尺寸时
计算那个映射即可 就这么简单


1050
00:52:04,992 --> 00:52:07,895 line:-1
你再也不用考虑多GPU负载平衡了


1051
00:52:07,961 --> 00:52:08,996 line:-1
因为没什么可监控的


1052
00:52:09,062 --> 00:52:11,765 line:-1
在app的主循环中不需要重新计算


1053
00:52:15,736 --> 00:52:19,106 line:-2
如果我们知道小平铺会更均匀地
分配工作


1054
00:52:19,640 --> 00:52:22,276 line:-2
为什么不把它推到极端
让它成为一个像素呢？


1055
00:52:24,778 --> 00:52:27,447 line:-2
那么问题是我们需要为
每个GPU提供


1056
00:52:27,781 --> 00:52:30,083 line:-1
很好的连贯像素块


1057
00:52:31,418 --> 00:52:32,619 line:-1
你需要在


1058
00:52:33,220 --> 00:52:36,657 line:-1
均匀地平衡负载和确保每个GPU


1059
00:52:36,723 --> 00:52:38,158 line:-1
都尽可能高效地运行之间做出权衡


1060
00:52:40,527 --> 00:52:43,864 line:-2
为了更好的了解这个权衡
我们做了一个简单的实验


1061
00:52:44,598 --> 00:52:49,603 line:-2
我们采用了一台新Mac Pro
以及一对Vega II Duo GPU


1062
00:52:49,670 --> 00:52:51,572 line:-1
这样一共有四个GPU了


1063
00:52:52,372 --> 00:52:55,475 line:-2
我们试着以各种平铺尺寸
渲染同一个场景


1064
00:52:55,542 --> 00:52:57,211 line:-1
从而了解平铺尺寸如何影响性能


1065
00:52:59,413 --> 00:53:01,481 line:0
当然了 每个人状况可能不同


1066
00:53:02,015 --> 00:53:06,153 line:0
但我们发现性能窗口实际上很宽


1067
00:53:07,688 --> 00:53:10,791 line:0
因此如果平铺很小


1068
00:53:11,291 --> 00:53:12,860 line:0
或如果平铺非常非常大
效率都会降低


1069
00:53:13,894 --> 00:53:17,164 line:0
但中间的部分非常接近性能峰值


1070
00:53:18,899 --> 00:53:20,200 line:0
（平铺分配）


1071
00:53:21,301 --> 00:53:23,036 line:0
现在我们已经确定了平铺尺寸


1072
00:53:23,437 --> 00:53:26,773 line:0
我们接下来要做的是
把它们分配到不同的GPU上


1073
00:53:28,575 --> 00:53:31,879 line:-1
为此 我们先给每个平铺


1074
00:53:31,945 --> 00:53:33,013 line:-1
生成一个随机编号


1075
00:53:33,547 --> 00:53:36,683 line:-2
然后把这些随机编号与一组临界值
进行比较


1076
00:53:38,051 --> 00:53:40,287 line:-1
随机编号无论处于哪个范围内


1077
00:53:40,554 --> 00:53:42,923 line:-2
该范围就为我们提供
该平铺的GPU使用


1078
00:53:44,858 --> 00:53:46,093 line:-1
举个例子


1079
00:53:46,159 --> 00:53:48,161 line:-1
如果平铺编号是.4


1080
00:53:48,695 --> 00:53:49,796 line:-1
我们把它分配给GPU 1


1081
00:53:50,931 --> 00:53:53,734 line:-2
如果编号是.55
我们把它分配给GPU 2


1082
00:53:54,134 --> 00:53:55,169 line:-1
以此类推


1083
00:53:57,204 --> 00:53:59,139 line:-1
一旦我们分配好每个平铺


1084
00:53:59,206 --> 00:54:02,276 line:-2
所得到的输出就是
每个GPU需要渲染的平铺的列表


1085
00:54:05,512 --> 00:54:07,014 line:0
你可以在底部看到


1086
00:54:07,281 --> 00:54:10,350 line:0
我们为每个GPU所使用的范围
是相等的


1087
00:54:11,752 --> 00:54:15,422 line:0
当向GPU分配平铺时
它们被选中的几率是相等的


1088
00:54:17,991 --> 00:54:20,727 line:0
但在实践中 你当然不希望这样


1089
00:54:22,029 --> 00:54:25,699 line:0
比如你可能需要在其中一个GPU上


1090
00:54:25,766 --> 00:54:27,301 line:0
为非光线追踪任务保留容量


1091
00:54:27,935 --> 00:54:30,137 line:-1
比如诊断或色调映射


1092
00:54:32,005 --> 00:54:34,408 line:-1
或你可能使用具有不同性能的GPU


1093
00:54:34,908 --> 00:54:38,245 line:-2
在那种情况下 你可能希望
给更强大的GPU分配更多的平铺


1094
00:54:40,280 --> 00:54:42,015 line:-1
你可以非常轻松地解决这个问题


1095
00:54:42,316 --> 00:54:43,684 line:-1
只需要调整范围即可


1096
00:54:45,052 --> 00:54:48,422 line:-2
现在如果我们继续并重新分配
我们之前用过的同样的平铺


1097
00:54:49,122 --> 00:54:52,759 line:-2
你可以看到GPU 2
现在分担了更多的工作


1098
00:54:56,530 --> 00:54:58,432 line:-1
对于实际实施


1099
00:54:59,166 --> 00:55:00,934 line:-2
在本周稍早些时候Pro app中
的Metal演讲中


1100
00:55:01,001 --> 00:55:03,437 line:-1
有许多非常有用的信息


1101
00:55:03,937 --> 00:55:05,506 line:-1
因此我就不再这里赘述了


1102
00:55:07,207 --> 00:55:10,043 line:-1
但强调几个


1103
00:55:10,110 --> 00:55:12,279 line:-2
对性能有很大影响的方面
是非常有用的


1104
00:55:14,715 --> 00:55:17,918 line:-2
首先你很可能想
在驱动显示屏的GPU上


1105
00:55:17,985 --> 00:55:19,853 line:-1
把平铺合成到一起


1106
00:55:21,221 --> 00:55:24,024 line:-1
重要的是找到具体是哪个GPU


1107
00:55:24,291 --> 00:55:28,328 line:-2
然后反向找到高效地把数据
放到该GPU上的方式


1108
00:55:30,063 --> 00:55:31,965 line:-1
如果GPU属于同一个对等组


1109
00:55:32,533 --> 00:55:36,203 line:-2
你可以使用我们的新对等组APIs
直接进行复制


1110
00:55:37,337 --> 00:55:39,206 line:-1
否则你就需要通过CPU实现


1111
00:55:42,309 --> 00:55:43,477 line:-1
其次


1112
00:55:43,544 --> 00:55:47,114 line:-2
在GPU之间复制数据通常需要
数毫秒


1113
00:55:47,381 --> 00:55:51,118 line:-2
我们一定不希望停滞并等待
完成数据迁移


1114
00:55:53,420 --> 00:55:55,622 line:-2
这里有一个例子展示了
我们处理这个问题的方式


1115
00:55:56,390 --> 00:55:57,858 line:-1
我们在这里有两个GPU


1116
00:55:57,925 --> 00:56:00,661 line:-1
并且我们使用了我刚谈到的平铺机制


1117
00:56:00,727 --> 00:56:02,930 line:-1
用于在两个GPU上展开渲染


1118
00:56:05,032 --> 00:56:07,901 line:-1
在GPU 0中 在顶部有两个队列


1119
00:56:08,836 --> 00:56:11,138 line:-2
其中一个只是简单地进行
背对背的光线追踪


1120
00:56:11,872 --> 00:56:13,106 line:-1
然后第二个队列


1121
00:56:13,607 --> 00:56:16,977 line:-2
异步地把已完成的平铺
复制到GPU 1上


1122
00:56:20,280 --> 00:56:22,583 line:-1
现在我们假设底部的GPU 1


1123
00:56:22,649 --> 00:56:24,218 line:-1
是驱动显示屏的那个GPU


1124
00:56:24,885 --> 00:56:26,587 line:-1
这里的情况有点不同


1125
00:56:28,455 --> 00:56:31,725 line:-2
这个GPU也分担了一部分
帧0的光线追踪


1126
00:56:32,559 --> 00:56:34,628 line:-1
但我们不能继续并呈现那个帧


1127
00:56:35,095 --> 00:56:38,465 line:-2
除非其余的平铺都已经
从其它GPU上复制过来了


1128
00:56:40,267 --> 00:56:41,435 line:-1
因此与其等待


1129
00:56:41,935 --> 00:56:43,237 line:-1
我们不如开始处理下一帧


1130
00:56:44,905 --> 00:56:47,975 line:-2
稍后当我们收到来自其它GPU的
全部平铺之后


1131
00:56:48,909 --> 00:56:51,311 line:-2
我们就可以继续
并把一切合成在一起了


1132
00:56:53,080 --> 00:56:54,281 line:-1
我再给你们看一次


1133
00:56:56,450 --> 00:56:58,619 line:-2
你可以看到我们最终处于这种
稳定状态


1134
00:56:59,019 --> 00:57:02,890 line:-2
我们正在渲染帧N
然后我们合成了帧N减一


1135
00:57:04,791 --> 00:57:07,661 line:-2
因此从根本上说
我们正在这里实现的是延迟隐藏


1136
00:57:08,862 --> 00:57:11,698 line:-1
这与我刚展示给你们的平铺一起


1137
00:57:11,765 --> 00:57:13,367 line:-1
在GPU之间负载平衡


1138
00:57:14,268 --> 00:57:16,803 line:-1
这就在多GPU系统上针对光线追踪


1139
00:57:16,870 --> 00:57:19,773 line:-1
为我们提供了非常棒的性能


1140
00:57:22,042 --> 00:57:23,677 line:-1
就这样了 我们的演讲结束了


1141
00:57:24,978 --> 00:57:28,715 line:-2
我们开始先快速回顾了光线追踪
是如何在Metal中运作的


1142
00:57:29,750 --> 00:57:33,053 line:-2
然后我们介绍了
MPSRayIntersector的几个功能


1143
00:57:33,120 --> 00:57:35,289 line:-1
可以帮助我们处理动态场景


1144
00:57:35,923 --> 00:57:38,125 line:-1
也就是二级加速结构


1145
00:57:38,725 --> 00:57:41,762 line:-1
以及由GPU加速的重建和再安置


1146
00:57:43,830 --> 00:57:45,866 line:-1
我们还介绍了新Metal降噪器


1147
00:57:46,633 --> 00:57:49,136 line:-1
然后我们讲了几个光线追踪的用例


1148
00:57:49,436 --> 00:57:52,573 line:-1
比如阴影、环境光遮蔽和全局照明


1149
00:57:54,908 --> 00:57:58,212 line:-2
然后演示了如何使用Xcode
调试并分析


1150
00:57:58,278 --> 00:57:59,279 line:-1
光线追踪


1151
00:57:59,680 --> 00:58:01,281 line:-1
最后我们又稍微提了一下


1152
00:58:01,348 --> 00:58:06,019 line:-2
如何在你的光线追踪app中
利用多GPU


1153
00:58:06,920 --> 00:58:09,857 line:0
要获取更多信息 请访问
developer.apple.com


1154
00:58:10,757 --> 00:58:12,626 line:0
你还可以在网站上找到一些新样本


1155
00:58:12,693 --> 00:58:15,195 line:0
演示我们今天所讲到的功能


1156
00:58:16,763 --> 00:58:17,865 line:0
如果你不熟悉光线追踪


1157
00:58:18,265 --> 00:58:20,100 line:0
请一定要参看我们去年的演讲


1158
00:58:20,667 --> 00:58:23,303 line:-2
最后 接下来中午12点
有我们的实验室活动


1159
00:58:23,570 --> 00:58:24,872 line:-1
希望大家能加入我们


1160
00:58:26,440 --> 00:58:28,842 line:-2
非常感谢你们的参与
稍后在实验室见

